{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def remove_space(string_list):\n",
    "    k = [i.replace(' ', '') for i in string_list]\n",
    "    return k\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "#     text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "#     text = text.replace(\",\", \" ,\")\n",
    "    \n",
    "\n",
    "#     text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "#     text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    return text\n",
    "\n",
    "def to_list(inp):\n",
    "    return \"['\"+inp+\"']\"\n",
    "# Pass the matched technology column that we got\n",
    "def convert_data_format(df,column_name):\n",
    "    \n",
    "    for i in range(0, len(df)):\n",
    "        \n",
    "        if df[column_name][i][0] == '[':\n",
    "            res = ast.literal_eval(df[column_name][i])\n",
    "            df[column_name][i] = res\n",
    "            \n",
    "        else:\n",
    "            x = []\n",
    "            x.insert(0, df[column_name][i])\n",
    "            df[column_name][i] = x\n",
    "            \n",
    "    return df\n",
    "\n",
    "def get_TP(df,manual_tagged_string,op_string):\n",
    "    \n",
    "    for ind in df.index:\n",
    "        TP = FP = 0\n",
    "        \n",
    "        for i in range(0, len(df[op_string][ind])):\n",
    "            \n",
    "            if df[op_string][ind][i] in df[manual_tagged_string][ind]:\n",
    "                TP = TP + 1\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "        tp.append(TP)\n",
    "\n",
    "    return tp\n",
    "\n",
    "def get_FP(df,manual_tagged_string, op_string):\n",
    "    \n",
    "    for ind in df.index:\n",
    "        main_list = np.setdiff1d(df[op_string][ind],df[manual_tagged_string][ind])\n",
    "        fp.append(len(main_list))\n",
    "        fp_entry.append(main_list)\n",
    "        \n",
    "        \n",
    "    return fp, fp_entry\n",
    "\n",
    "def get_FN(df,manual_tagged_string, op_string):\n",
    "    \n",
    "    for ind in df.index:\n",
    "        \n",
    "        main_list = np.setdiff1d(df[manual_tagged_string][ind], df[op_string][ind])\n",
    "        if df[manual_tagged_string][ind]=='[]':\n",
    "            fn.append(0)\n",
    "        else:\n",
    "            fn.append(len(main_list))\n",
    "        \n",
    "    return fn\n",
    "\n",
    "\n",
    "def get_tech_tagged_data(manually_tagged, tech_list):\n",
    "    keep=[]\n",
    "    for word in manually_tagged:\n",
    "        if word in tech_list:\n",
    "            keep.append(word)\n",
    "    return keep\n",
    "def combine(lis1, lis2):\n",
    "    return list(set(lis1 + lis2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/mohitbagaria/Downloads/Job_data_BERT_2_Jul_wc_FINALIZING.csv\" #ENTER DATA PATH\n",
    "ID = 'job_id'# ID column name\n",
    "summaries = 'summaries_matching'#summaries column name\n",
    "manually_tagged = 'Manually Tagged' #manual tag column name\n",
    "bert_tags = 'BERT_Tags'#column name\n",
    "\n",
    "data=pd.read_csv(data_path)\n",
    "data=data[[ID,summaries,manually_tagged,bert_tags]]\n",
    "\n",
    "\n",
    "data[bert_tags] = data[bert_tags].apply(eval)\n",
    "data[bert_tags] = data[bert_tags].apply(remove_space)\n",
    "\n",
    "tech_data = pd.read_csv(\"Tech_pydictionary_2.csv\")\n",
    "tech_data[\"Tech_word\"]=tech_data[\"Tech_word\"].apply(clean_text)\n",
    "tech_list = list(set(tech_data[\"Tech_word\"]))\n",
    "eng_data = pd.read_csv(\"Eng_pydictionary_2.csv\")\n",
    "eng_data[\"English_word\"]=eng_data[\"English_word\"].apply(clean_text)\n",
    "eng_list= list(set(eng_data[\"English_word\"]))\n",
    "\n",
    "\n",
    "# (all entries which are in eng dictionary)\n",
    "eng_bert_tags=[]\n",
    "removed=0\n",
    "kept=0\n",
    "for i in range(0,len(data)):\n",
    "    eng_bert_1sen=[]\n",
    "    tags= data[bert_tags][i]\n",
    "    for j in tags:\n",
    "        if j in eng_list:\n",
    "            kept+=1\n",
    "            eng_bert_1sen.append(j)\n",
    "        else:\n",
    "            removed+=1\n",
    "            \n",
    "    eng_bert_tags.append(eng_bert_1sen)\n",
    "data[bert_tags]=eng_bert_tags\n",
    "\n",
    "\n",
    "data.to_csv(\"BERT_preds_JOB_id_ENG_ONLY2july.csv\",index=False)\n",
    "'''SAME FILE WRITE AND READ'''\n",
    "summary = pd.read_csv(\"BERT_preds_JOB_id_ENG_ONLY2july.csv\")\n",
    "\n",
    "ID = 'job_id'# ID column name\n",
    "summaries = 'summaries_matching'#summaries column name\n",
    "manually_tagged = 'Manually Tagged' #manual tag column name\n",
    "bert_tags = 'BERT_Tags'#column name\n",
    "\n",
    "summary = summary[[ID,summaries,manually_tagged,bert_tags]]\n",
    "\n",
    "summary = summary.sort_values(by=[ID], ascending=False)\n",
    "summary.reset_index(inplace = True, drop = True)\n",
    "col_name_op = \"BERT_Tags\"\n",
    "\n",
    "df_cm = summary\n",
    "\n",
    "df_cm = convert_data_format(df_cm, col_name_op)\n",
    "df_cm = convert_data_format(df_cm, manually_tagged)\n",
    "\n",
    "count_context_technologies = []\n",
    "\n",
    "for i in range(0, len(df_cm)):\n",
    "    count_context_technologies.extend(df_cm[manually_tagged][i])\n",
    "d = list(set(count_context_technologies))\n",
    "\n",
    "tp = []\n",
    "tn = []\n",
    "fp = []\n",
    "fn = []\n",
    "\n",
    "TP = TN = FP = FN = 0\n",
    "df_cm[manually_tagged] = df_cm[manually_tagged].fillna('[]')\n",
    "\n",
    "\n",
    "df_cm['Eng_Label']=df_cm[manually_tagged].copy()\n",
    "\n",
    "tech_tag_list = []\n",
    "\n",
    "\n",
    "\n",
    "df_cm['Eng_Label'] = df_cm.apply(\n",
    "    lambda x: get_tech_tagged_data(x[\"Eng_Label\"], eng_list),\n",
    "    axis = 1)\n",
    "\n",
    "list_tech_dataset = []\n",
    "\n",
    "# fill with \n",
    "for i in range(0, len(df_cm)):\n",
    "    list_tech_dataset.extend(df_cm[\"Eng_Label\"][i])\n",
    "\n",
    "set_tech = set(list_tech_dataset)\n",
    "\n",
    "for i in range(0, len(df_cm)):\n",
    "    l = df_cm[col_name_op][i]\n",
    "    df_cm[col_name_op][i] = [0 if element == '0' else element for element in l]\n",
    "\n",
    "for i in range(0, len(df_cm)):\n",
    "  words = df_cm[col_name_op][i]\n",
    "  stopwords = [0]\n",
    "  for word in list(words):\n",
    "    if word in stopwords:\n",
    "      words.remove(word)\n",
    "\n",
    "    \n",
    "def get_precision(tp,fp):\n",
    "    \n",
    "    if tp+fp ==0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = tp/(tp+fp)\n",
    "    \n",
    "    return precision\n",
    "\n",
    "def get_recall(tp,fn):\n",
    "    \n",
    "    if tp+fn ==0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = tp/(tp+fn)\n",
    "    \n",
    "    return recall\n",
    "\n",
    "def get_f_score(precision, recall):\n",
    "    if precision+recall == 0:\n",
    "        f_score = 0\n",
    "    else:\n",
    "        f_score = 2*(precision*recall)/(precision+recall)\n",
    "        \n",
    "    return f_score\n",
    "\n",
    "def Diff(li1, li2): #FP entries\n",
    "    return list(set(li2)-set(li1))\n",
    "\n",
    "def Same(lis1,lis2): #TP entries\n",
    "    return list(set(lis1).intersection(lis2))\n",
    "\n",
    "def Common(lis1,lis2):\n",
    "    return list(set(lis1)-(set(lis2)))\n",
    "\n",
    "# list of technologies which are not in extracted list but are in tagged list i.e. FN entries\n",
    "df_cm['FP_entries_eng'] = df_cm.apply(lambda x: Diff(x[\"Eng_Label\"], x[col_name_op]), axis = 1)\n",
    "\n",
    "# list of technologies which are in extracted list and are in tagged list i.e. TP entries\n",
    "df_cm['TP_entries_eng'] = df_cm.apply(lambda x: Same(x[\"Eng_Label\"], x[col_name_op]), axis = 1)\n",
    "\n",
    "# list of technologies which are NOT extracted list and are in tagged list i.e. FN entries\n",
    "df_cm['FN_entries_eng'] = df_cm.apply(lambda x: Common(x[\"Eng_Label\"], x[col_name_op]), axis = 1)\n",
    "\n",
    "fp_entry =[]\n",
    "tp = get_TP(df_cm, \"Eng_Label\", col_name_op)\n",
    "fp, fp_entry_names = get_FP(df_cm, \"Eng_Label\", col_name_op)\n",
    "fn = get_FN(df_cm, \"Eng_Label\", col_name_op)\n",
    "# print(len(tp), len(fp), len(fn))\n",
    "dict_fp = {}\n",
    "\n",
    "for i in range(0, len(fp_entry_names)):\n",
    "    fp_entry_names[i] = fp_entry_names[i].tolist()\n",
    "    dict_fp[i] = fp_entry_names[i]\n",
    "\n",
    "# creating a dataframe\n",
    "df_matrix = pd.DataFrame(list(zip(tp, fp, fn)), \n",
    "               columns =['TP', 'FP', \"FN\"])\n",
    "df_matrix['Precision'] = df_matrix.apply(lambda x: get_precision(x[\"TP\"], x[\"FP\"]), axis = 1)\n",
    "\n",
    "df_matrix[\"Recall\"] = df_matrix.apply(lambda x: get_recall(x[\"TP\"], x[\"FN\"]), axis = 1)\n",
    "\n",
    "df_matrix[\"f_score\"] = df_matrix.apply(lambda x: get_f_score(x[\"Precision\"], x[\"Recall\"]), axis = 1)\n",
    "\n",
    "final_data = df_cm.join(df_matrix)\n",
    "final_data.to_csv(\"ACC-BERT_preds_JOB_id_ENG_ONLY2july.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TECH Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_csv(data_path)\n",
    "ID = 'job_id'# ID column name\n",
    "summaries = 'summaries_matching'#summaries column name\n",
    "manually_tagged = 'Manually Tagged' #manual tag column name\n",
    "bert_tags = 'BERT_Tags'#column nameA\n",
    "\n",
    "summary = summary[[ID,summaries,manually_tagged]]\n",
    "summary = summary.sort_values(by=[ID], ascending=False)\n",
    "summary.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# reading \n",
    "tech = pd.read_csv(\"Tech_pydictionary_2.csv\")\n",
    "col_name=tech.columns[-1]\n",
    "tech[col_name] = tech[col_name].astype(str)\n",
    "all_tech_words = list(tech[col_name].str.lower())\n",
    "summary[summaries]=summary[summaries].astype(str)\n",
    "all_strings = list(summary[summaries].str.lower())\n",
    "\n",
    "i=1\n",
    "tech_keys=[]\n",
    "for item in all_strings:\n",
    "#     print(\"***\",\"TEST No,\",i,\"***\")\n",
    "    i=i+1\n",
    "    tech_row=[]\n",
    "    for k in all_tech_words:\n",
    "        if k in item and len(k)>2:\n",
    "           tech_row.append(k)\n",
    "    tech_keys.append(tech_row)\n",
    "\n",
    "summary['keywords']=tech_keys\n",
    "\n",
    "def reg_match(txt, keyw):\n",
    "    sep='|'\n",
    "    temp = sep.join(['\\\\b' + i+'\\\\b' for i in keyw])\n",
    "    matches = re.findall(temp,txt)\n",
    "    return list(set(matches))\n",
    "\n",
    "summary['Tech_matched'] = summary.apply(\n",
    "    lambda x: reg_match(x[summaries], x[\"keywords\"]),\n",
    "    axis = 1)\n",
    "\n",
    "col_name_op = \"Tech_matched\"\n",
    "\n",
    "df_cm = summary\n",
    "df_cm = convert_data_format(df_cm, manually_tagged)\n",
    "df_cm[manually_tagged] = df_cm[manually_tagged].fillna('[]')\n",
    "count_context_technologies = []\n",
    "for i in range(0, len(df_cm)):\n",
    "    count_context_technologies.extend(df_cm[manually_tagged][i])\n",
    "d = list(set(count_context_technologies))\n",
    "\n",
    "tp = []\n",
    "tn = []\n",
    "fp = []\n",
    "fn = []\n",
    "\n",
    "TP = TN = FP = FN = 0\n",
    "\n",
    "df_cm['Tech_Label'] = df_cm.apply(\n",
    "    lambda x: get_tech_tagged_data(x[manually_tagged],tech_list), axis = 1)\n",
    "string_match_tech_col = df_cm['Tech_Label']\n",
    "list_tech_dataset = []\n",
    "\n",
    "for i in range(0, len(df_cm)):\n",
    "    list_tech_dataset.extend(df_cm[\"Tech_Label\"][i])\n",
    "\n",
    "set_tech = set(list_tech_dataset)\n",
    "\n",
    "for i in range(0, len(df_cm)):\n",
    "    l = df_cm[col_name_op][i]\n",
    "    df_cm[col_name_op][i] = [0 if element == '0' else element for element in l]\n",
    "\n",
    "for i in range(0, len(df_cm)):\n",
    "  words = df_cm[col_name_op][i]\n",
    "  stopwords = [0]\n",
    "  for word in list(words):\n",
    "    if word in stopwords:\n",
    "      words.remove(word)\n",
    "    \n",
    "    \n",
    "# list of technologies which are not in extracted list but are in tagged list i.e. FN entries\n",
    "df_cm['FP_entries_TECH'] = df_cm.apply(lambda x: Diff(x[\"Tech_Label\"], x[col_name_op]), axis = 1)\n",
    "\n",
    "# list of technologies which are in extracted list and are in tagged list i.e. TP entries\n",
    "df_cm['TP_entries_TECH'] = df_cm.apply(lambda x: Same(x[\"Tech_Label\"], x[col_name_op]), axis = 1)\n",
    "\n",
    "# list of technologies which are NOT extracted list and are in tagged list i.e. FN entries\n",
    "df_cm['FN_entries_TECH'] = df_cm.apply(lambda x: Common(x[\"Tech_Label\"], x[col_name_op]), axis = 1)\n",
    "# function call\n",
    "fp_entry =[]\n",
    "tp = get_TP(df_cm, \"Tech_Label\", col_name_op)\n",
    "fp, fp_entry_names = get_FP(df_cm, \"Tech_Label\", col_name_op)\n",
    "fn = get_FN(df_cm, \"Tech_Label\", col_name_op)\n",
    "\n",
    "# for i in range(0, len(fp_entry_names)):\n",
    "#     fp_entry_names[i] = fp_entry_names[i].tolist()\n",
    "#     dict_fp[i] = fp_entry_names[i]\n",
    "\n",
    "# creating a dataframe\n",
    "df_matrix = pd.DataFrame(list(zip(tp, fp, fn)), \n",
    "               columns =['TP', 'FP', \"FN\"])\n",
    "\n",
    "df_matrix['Precision'] = df_matrix.apply(lambda x: get_precision(x[\"TP\"], x[\"FP\"]), axis = 1)\n",
    "\n",
    "df_matrix[\"Recall\"] = df_matrix.apply(lambda x: get_recall(x[\"TP\"], x[\"FN\"]), axis = 1)\n",
    "\n",
    "df_matrix[\"f_score\"] = df_matrix.apply(lambda x: get_f_score(x[\"Precision\"], x[\"Recall\"]), axis = 1)\n",
    "\n",
    "df_cm=df_cm.drop(columns=\"keywords\")\n",
    "final_data = df_cm.join(df_matrix)\n",
    "final_data.to_csv(\"ACC-TECH_BERT_preds_JOB_id2july.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENG+TECH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohitbagaria/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/mohitbagaria/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"BERT_preds_JOB_id_ENG_ONLY2july.csv\")#only eng\n",
    "ID='job_id'\n",
    "manually_tagged = 'Manually Tagged'\n",
    "summaries = 'summaries_matching'\n",
    "col_name_op=\"BERT_ENG+string_matched\"\n",
    "\n",
    "\n",
    "data[bert_tags] = data[bert_tags].apply(str)\n",
    "data[bert_tags] = data[bert_tags].apply(eval)\n",
    "data[bert_tags] = data[bert_tags].apply(remove_space)\n",
    "tech = pd.read_csv(\"Tech_pydictionary_2.csv\")\n",
    "col_name=tech.columns[-1]\n",
    "summary=data\n",
    "tech[col_name] = tech[col_name].astype(str)\n",
    "all_tech_words = list(tech[col_name].str.lower())\n",
    "summary[summaries]=summary[summaries].astype(str)\n",
    "all_strings = list(summary[summaries].str.lower())\n",
    "i=1\n",
    "tech_keys=[]\n",
    "for item in all_strings:\n",
    "#     print(\"***\",\"TEST No,\",i,\"***\")\n",
    "    i=i+1\n",
    "    tech_row=[]\n",
    "    for k in all_tech_words:\n",
    "        if k in item and len(k)>2:\n",
    "           tech_row.append(k)\n",
    "    tech_keys.append(tech_row)\n",
    "summary['keywords']=tech_keys\n",
    "\n",
    "summary['string_matched'] = summary.apply(lambda x: reg_match(x[summaries], x[\"keywords\"]), axis = 1)\n",
    "summary['BERT_ENG+string_matched'] = summary.apply(\n",
    "    lambda x: combine(x[bert_tags], x[\"string_matched\"]), \n",
    "    axis = 1)\n",
    "\n",
    "data=summary[[ID,summaries,manually_tagged,'BERT_ENG+string_matched']]\n",
    "data.to_csv(\"BERT_preds_JOB_id_ENG+TECH2july.csv\")\n",
    "\n",
    "summary = pd.read_csv(\"BERT_preds_JOB_id_ENG+TECH2july.csv\")\n",
    "ID = 'job_id'# ID column name\n",
    "summaries = 'summaries_matching'#summaries column name\n",
    "manually_tagged = 'Manually Tagged' #manual tag column name\n",
    "col_name_op =\"BERT_ENG+string_matched\"#column name\n",
    "\n",
    "summary = summary.sort_values(by=[ID], ascending=False)\n",
    "summary.reset_index(inplace = True, drop = True)\n",
    "\n",
    "df_cm = summary\n",
    "df_cm = convert_data_format(df_cm, col_name_op)\n",
    "\n",
    "df_cm = convert_data_format(df_cm,manually_tagged)\n",
    "\n",
    "count_context_technologies = []\n",
    "\n",
    "for i in range(0, len(df_cm)):\n",
    "    count_context_technologies.extend(df_cm[manually_tagged][i])\n",
    "d = list(set(count_context_technologies))\n",
    "\n",
    "tp = []\n",
    "tn = []\n",
    "fp = []\n",
    "fn = []\n",
    "\n",
    "TP = TN = FP = FN = 0\n",
    "\n",
    "df_cm[manually_tagged] = df_cm[manually_tagged].fillna('[]')\n",
    "\n",
    "for i in range(0, len(df_cm)):\n",
    "    l = df_cm[col_name_op][i]\n",
    "    df_cm[col_name_op][i] = [0 if element == '0' else element for element in l]\n",
    "\n",
    "for i in range(0, len(df_cm)):\n",
    "  words = df_cm[col_name_op][i]\n",
    "  stopwords = [0]\n",
    "  for word in list(words):\n",
    "    if word in stopwords:\n",
    "      words.remove(word)\n",
    "    \n",
    "\n",
    "# list of technologies which are not in extracted list but are in tagged list i.e. FN entries\n",
    "df_cm['FP_entries'] = df_cm.apply(lambda x: Diff(x[manually_tagged], x[col_name_op]), axis = 1)\n",
    "\n",
    "# list of technologies which are in extracted list and are in tagged list i.e. TP entries\n",
    "df_cm['TP_entries'] = df_cm.apply(lambda x: Same(x[manually_tagged], x[col_name_op]), axis = 1)\n",
    "\n",
    "# list of technologies which are NOT extracted list and are in tagged list i.e. FN entries\n",
    "df_cm['FN_entries'] = df_cm.apply(lambda x: Common(x[manually_tagged], x[col_name_op]), axis = 1)\n",
    "fp_entry =[]\n",
    "\n",
    "tp = get_TP(df_cm, manually_tagged, col_name_op)\n",
    "fp, fp_entry_names = get_FP(df_cm, manually_tagged, col_name_op)\n",
    "fn = get_FN(df_cm, manually_tagged, col_name_op)\n",
    "\n",
    "dict_fp = {}\n",
    "\n",
    "for i in range(0, len(fp_entry_names)):\n",
    "    fp_entry_names[i] = fp_entry_names[i].tolist()\n",
    "    dict_fp[i] = fp_entry_names[i]\n",
    "\n",
    "# creating a dataframe\n",
    "df_matrix = pd.DataFrame(list(zip(tp, fp, fn)), \n",
    "               columns =['TP', 'FP', \"FN\"])\n",
    "\n",
    "df_matrix['Precision'] = df_matrix.apply(lambda x: get_precision(x[\"TP\"], x[\"FP\"]), axis = 1)\n",
    "\n",
    "df_matrix[\"Recall\"] = df_matrix.apply(lambda x: get_recall(x[\"TP\"], x[\"FN\"]), axis = 1)\n",
    "\n",
    "df_matrix[\"f_score\"] = df_matrix.apply(lambda x: get_f_score(x[\"Precision\"], x[\"Recall\"]), axis = 1)\n",
    "\n",
    "final_data = df_cm.join(df_matrix)\n",
    "final_data.to_csv(\"ACC-ENG+TECH_BERT_preds_JOB_id2july.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
