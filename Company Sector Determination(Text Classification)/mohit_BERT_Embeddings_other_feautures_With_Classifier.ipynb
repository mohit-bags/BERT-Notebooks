{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17dfb698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import re\n",
    "import codecs\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "n_jobs=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec844f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  clean_text(df, text_field, new_text_field_name):\n",
    "    df[new_text_field_name] = df[text_field].str.lower()\n",
    "    df[new_text_field_name] = df[new_text_field_name].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
    "    df[new_text_field_name] = df[new_text_field_name].apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24da82d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(df.company_description, \n",
    "#                                                   df.category_id, \n",
    "#                                                   test_size=0.15, \n",
    "#                                                   random_state=42, \n",
    "#                                                   stratify=df.category_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f095d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.read_csv('../data/X_train.csv')\n",
    "X_test=pd.read_csv('../data/X_test.csv')\n",
    "y_train=pd.read_csv('../data/y_train.csv')\n",
    "y_test=pd.read_csv('../data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dba91f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean = clean_text(X_train, 'company_description', 'text_clean')\n",
    "X_train['company_description'] = X_train_clean['text_clean']\n",
    "del X_train_clean\n",
    "\n",
    "X_test_clean = clean_text(X_test, 'company_description', 'text_clean')\n",
    "X_test['company_description'] = X_test_clean['text_clean']\n",
    "del X_test_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "547e83c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.drop(['company_address_encoded','company_name','_id','text_clean'],axis=1)\n",
    "X_test=X_test.drop(['company_address_encoded','company_name','_id','text_clean'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b33b3c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['company_sector_encoded','company_description'],axis=1)\n",
    "X_test = X_test.drop(['company_sector_encoded','company_description'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b6bd89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train = MinMaxScaler().fit_transform(X_train)\n",
    "X_test = MinMaxScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "029cf4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # roc curve and auc\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import roc_curve\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "# from matplotlib import pyplot\n",
    "# # generate 2 class dataset\n",
    "# X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
    "# # split into train/test sets\n",
    "# trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2)\n",
    "# # generate a no skill prediction (majority class)\n",
    "# ns_probs = [0 for _ in range(len(testy))]\n",
    "# # fit a model\n",
    "# model = LogisticRegression(solver='lbfgs')\n",
    "# model.fit(trainX, trainy)\n",
    "# # predict probabilities\n",
    "# lr_probs = model.predict_proba(testX)\n",
    "# # keep probabilities for the positive outcome only\n",
    "# lr_probs = lr_probs[:, 1]\n",
    "# # calculate scores\n",
    "# ns_auc = roc_auc_score(testy, ns_probs)\n",
    "# lr_auc = roc_auc_score(testy, lr_probs)\n",
    "# # summarize scores\n",
    "# print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "# print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# # calculate roc curves\n",
    "# ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)\n",
    "# lr_fpr, lr_tpr, _ = roc_curve(testy, lr_probs)\n",
    "# # plot the roc curve for the model\n",
    "# pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "# pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# # axis labels\n",
    "# pyplot.xlabel('False Positive Rate')\n",
    "# pyplot.ylabel('True Positive Rate')\n",
    "# # show the legend\n",
    "# pyplot.legend()\n",
    "# # show the plot\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dc7befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "# bert = SentenceTransformer('stsb-roberta-large') #RoBERTa, an optimized version of BERT by Facebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10d37a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # vectorize the data\n",
    "# X_train_vec = pd.DataFrame(np.vstack(X_train.company_description.apply(bert.encode)))\n",
    "# X_test_vec = pd.DataFrame(np.vstack(X_test.company_description.apply(bert.encode)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5be51e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_vec.to_csv('../data/bert_encoded_train.csv',index=False)\n",
    "# X_test_vec.to_csv('../data/bert_encoded_test.csv',index=False)\n",
    "# y_train.to_csv('../data/for_bert_emb_Y_train.csv',index=False)\n",
    "# y_test.to_csv('../data/for_bert_emb_Y_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1be10fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading bert encoded company description\n",
    "X_train_vec=pd.read_csv('../data/bert_encoded_train.csv')\n",
    "X_test_vec=pd.read_csv('../data/bert_encoded_test.csv')\n",
    "y_train=pd.read_csv('../data/for_bert_emb_Y_train.csv')\n",
    "y_test=pd.read_csv('../data/for_bert_emb_Y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adce0a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = np.concatenate((X_train_vec, X_train),axis = 1)\n",
    "X_test_vec = np.concatenate((X_test_vec, X_test),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9c4bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalar = MinMaxScaler()\n",
    "# # fitting\n",
    "# scalar.fit(X_train)\n",
    "# scaled_data = scalar.transform(X_train)\n",
    "\n",
    "# # Importing PCA\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components = 10)\n",
    "# pca.fit(scaled_data)\n",
    "# x_pca_train = pca.transform(scaled_data)\n",
    "\n",
    "# x_pca_train.shape\n",
    "\n",
    "# scalar.fit(X_test)\n",
    "# scaled_data_x_test = scalar.transform(X_test)\n",
    "\n",
    "# pca = PCA(n_components = 10)\n",
    "# pca.fit(scaled_data_x_test)\n",
    "# x_pca_test = pca.transform(scaled_data_x_test)\n",
    "\n",
    "# x_pca_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95c2d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalar.fit(X_train_vec)\n",
    "# scaled_data_bert_train = scalar.transform(X_train_vec)\n",
    "\n",
    "# pca = PCA(n_components = 100)\n",
    "# pca.fit(scaled_data_bert_train)\n",
    "# x_pca_bert_train = pca.transform(scaled_data_bert_train)\n",
    "\n",
    "# x_pca_bert_train.shape\n",
    "\n",
    "\n",
    "# scalar.fit(X_test_vec)\n",
    "# scaled_data_bert_test = scalar.transform(X_test_vec)\n",
    "\n",
    "# pca = PCA(n_components = 100)\n",
    "# pca.fit(scaled_data_bert_test)\n",
    "# x_pca_bert_test = pca.transform(scaled_data_bert_test)\n",
    "\n",
    "# x_pca_bert_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5bfd1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.values.ravel()\n",
    "y_test=y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c41d71d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 438 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, n_jobs=-1, verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''RANDOM FOREST '''\n",
    "model = RandomForestClassifier(n_estimators=500, n_jobs=-1,verbose=1)\n",
    "model.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4b6d917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=6)]: Done 500 out of 500 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3081901717938474"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test_vec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b06272b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=6)]: Done 500 out of 500 | elapsed:    2.1s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b95f9506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_vec = np.concatenate((x_pca_bert_train, x_pca_train),axis = 1)\n",
    "# X_test_vec = np.concatenate((x_pca_bert_test, x_pca_test),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6317fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #BERT doesn't have feature names, \n",
    "# #use your classifier\n",
    "# '''RANDOM FOREST '''\n",
    "# model = RandomForestClassifier(n_estimators=200, n_jobs=8,verbose=1)\n",
    "# model.fit(X_train_vec, y_train)\n",
    "\n",
    "# # model.score(X_test_vec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16b6c7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.78      0.33      1523\n",
      "           1       0.86      0.41      0.55       135\n",
      "           2       0.42      0.65      0.51       720\n",
      "           3       0.57      0.11      0.19       107\n",
      "           4       0.00      0.00      0.00        85\n",
      "           5       0.32      0.56      0.41       131\n",
      "           6       0.42      0.11      0.17       157\n",
      "           7       0.00      0.00      0.00        87\n",
      "           8       0.00      0.00      0.00        26\n",
      "           9       0.25      0.28      0.27      1036\n",
      "          10       0.43      0.62      0.51       224\n",
      "          11       0.40      0.71      0.51       486\n",
      "          12       1.00      0.04      0.08        48\n",
      "          13       0.00      0.00      0.00         5\n",
      "          14       0.21      0.32      0.25       789\n",
      "          15       0.00      0.00      0.00        56\n",
      "          16       0.43      0.06      0.10        53\n",
      "          17       0.00      0.00      0.00       117\n",
      "          18       0.00      0.00      0.00        37\n",
      "          19       0.61      0.45      0.52       232\n",
      "          20       0.00      0.00      0.00        76\n",
      "          21       0.67      0.01      0.02       196\n",
      "          22       0.00      0.00      0.00       145\n",
      "          23       0.00      0.00      0.00        24\n",
      "          24       0.00      0.00      0.00        13\n",
      "          25       0.59      0.10      0.17        98\n",
      "          26       0.67      0.09      0.15       117\n",
      "          27       0.00      0.00      0.00        31\n",
      "          28       0.00      0.00      0.00        28\n",
      "          29       1.00      0.03      0.06       185\n",
      "          30       1.00      0.11      0.20        36\n",
      "          31       0.65      0.25      0.36       146\n",
      "          32       0.00      0.00      0.00        38\n",
      "          33       0.67      0.06      0.11        68\n",
      "          34       1.00      0.02      0.04        48\n",
      "          35       0.50      0.01      0.03        75\n",
      "          36       0.00      0.00      0.00         9\n",
      "          37       0.91      0.11      0.20        89\n",
      "          38       0.65      0.12      0.20        92\n",
      "          39       0.47      0.51      0.49       126\n",
      "          40       0.75      0.22      0.34        82\n",
      "          41       0.87      0.55      0.67        62\n",
      "          42       0.00      0.00      0.00        66\n",
      "          43       0.49      0.71      0.58       169\n",
      "          44       0.64      0.46      0.54       141\n",
      "          45       0.48      0.25      0.33       127\n",
      "          46       0.67      0.05      0.10        75\n",
      "          47       0.75      0.09      0.16        69\n",
      "          48       0.49      0.52      0.50       124\n",
      "          49       0.00      0.00      0.00         5\n",
      "          50       0.00      0.00      0.00         9\n",
      "          51       0.00      0.00      0.00        22\n",
      "          52       0.00      0.00      0.00        39\n",
      "          53       0.00      0.00      0.00        53\n",
      "          54       0.00      0.00      0.00        77\n",
      "          55       0.00      0.00      0.00        58\n",
      "          56       0.00      0.00      0.00        75\n",
      "          57       1.00      0.01      0.02        86\n",
      "          58       1.00      0.01      0.02       115\n",
      "          59       0.35      0.16      0.22       177\n",
      "          60       0.00      0.00      0.00        15\n",
      "          61       0.31      0.05      0.08       102\n",
      "          62       0.59      0.27      0.37       188\n",
      "          63       0.00      0.00      0.00        46\n",
      "          64       0.00      0.00      0.00        68\n",
      "          65       0.00      0.00      0.00        38\n",
      "          66       0.00      0.00      0.00        37\n",
      "          67       0.59      0.50      0.54       191\n",
      "          68       0.00      0.00      0.00        19\n",
      "          69       0.00      0.00      0.00        57\n",
      "          70       0.00      0.00      0.00         9\n",
      "          71       0.00      0.00      0.00        33\n",
      "          72       1.00      0.04      0.08        24\n",
      "          73       0.70      0.23      0.35        81\n",
      "          74       0.43      0.48      0.45       194\n",
      "          75       0.00      0.00      0.00        45\n",
      "          76       1.00      0.02      0.03        65\n",
      "          77       0.56      0.34      0.42       107\n",
      "          78       1.00      0.03      0.06        32\n",
      "          79       0.00      0.00      0.00        23\n",
      "          80       0.00      0.00      0.00        28\n",
      "          81       0.44      0.24      0.31       146\n",
      "          82       0.00      0.00      0.00        46\n",
      "          83       0.00      0.00      0.00        30\n",
      "          84       0.00      0.00      0.00        36\n",
      "          85       0.00      0.00      0.00        20\n",
      "          86       0.00      0.00      0.00        27\n",
      "          87       0.00      0.00      0.00         9\n",
      "          88       0.65      0.26      0.37        99\n",
      "          89       0.00      0.00      0.00        15\n",
      "          90       0.00      0.00      0.00        18\n",
      "          91       0.00      0.00      0.00        28\n",
      "          92       0.00      0.00      0.00        81\n",
      "          93       0.15      0.02      0.03       123\n",
      "          94       0.00      0.00      0.00        81\n",
      "          95       0.00      0.00      0.00        46\n",
      "          96       0.00      0.00      0.00        51\n",
      "          97       0.00      0.00      0.00        22\n",
      "          98       0.00      0.00      0.00        58\n",
      "          99       0.67      0.07      0.13        82\n",
      "         100       0.00      0.00      0.00        11\n",
      "         101       0.00      0.00      0.00        21\n",
      "         102       0.00      0.00      0.00        33\n",
      "         103       0.00      0.00      0.00        91\n",
      "         104       1.00      0.04      0.07        26\n",
      "         105       0.00      0.00      0.00        40\n",
      "         106       0.00      0.00      0.00        37\n",
      "         107       0.00      0.00      0.00        14\n",
      "         108       0.00      0.00      0.00         5\n",
      "         109       0.00      0.00      0.00         6\n",
      "         110       1.00      0.02      0.04        53\n",
      "         111       0.00      0.00      0.00        15\n",
      "         112       0.00      0.00      0.00        23\n",
      "         113       0.00      0.00      0.00        11\n",
      "         114       0.00      0.00      0.00         6\n",
      "         115       0.00      0.00      0.00        10\n",
      "         116       0.00      0.00      0.00        36\n",
      "         117       0.00      0.00      0.00        25\n",
      "         118       0.00      0.00      0.00        12\n",
      "         119       0.00      0.00      0.00         4\n",
      "         120       0.00      0.00      0.00        31\n",
      "         121       0.00      0.00      0.00         2\n",
      "         122       0.00      0.00      0.00        15\n",
      "         123       0.00      0.00      0.00        15\n",
      "         124       0.00      0.00      0.00         4\n",
      "         125       0.00      0.00      0.00        13\n",
      "         126       0.00      0.00      0.00        11\n",
      "         127       0.00      0.00      0.00        19\n",
      "         128       0.00      0.00      0.00        16\n",
      "         129       0.00      0.00      0.00        41\n",
      "         130       0.00      0.00      0.00        25\n",
      "         131       0.00      0.00      0.00        14\n",
      "         132       0.00      0.00      0.00        26\n",
      "         133       0.00      0.00      0.00         7\n",
      "         134       0.00      0.00      0.00         9\n",
      "         135       0.00      0.00      0.00         6\n",
      "         136       0.00      0.00      0.00        10\n",
      "         137       0.00      0.00      0.00         2\n",
      "         139       0.00      0.00      0.00         1\n",
      "         140       0.00      0.00      0.00         4\n",
      "         141       0.00      0.00      0.00        11\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         3\n",
      "         144       0.00      0.00      0.00         3\n",
      "         145       0.00      0.00      0.00         1\n",
      "         146       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.31     12515\n",
      "   macro avg       0.22      0.08      0.09     12515\n",
      "weighted avg       0.35      0.31      0.25     12515\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slintel/bert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/slintel/bert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/slintel/bert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fb45b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4619256891729924\n"
     ]
    }
   ],
   "source": [
    "LR_model = LogisticRegression(n_jobs=-1,verbose=True)\n",
    "LR_model.fit(X_train_vec, y_train)\n",
    "y_pred = LR_model.predict(X_test_vec)\n",
    "acc_score = LR_model.score(X_test_vec, y_test)\n",
    "print(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c663b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.49      0.47      1523\n",
      "           1       0.80      0.76      0.78       135\n",
      "           2       0.55      0.67      0.61       720\n",
      "           3       0.38      0.49      0.43       107\n",
      "           4       0.24      0.16      0.20        85\n",
      "           5       0.42      0.48      0.45       131\n",
      "           6       0.41      0.43      0.42       157\n",
      "           7       0.29      0.22      0.25        87\n",
      "           8       0.23      0.12      0.15        26\n",
      "           9       0.41      0.41      0.41      1036\n",
      "          10       0.48      0.61      0.54       224\n",
      "          11       0.57      0.64      0.60       486\n",
      "          12       0.58      0.54      0.56        48\n",
      "          13       0.17      0.20      0.18         5\n",
      "          14       0.34      0.32      0.33       789\n",
      "          15       0.18      0.12      0.15        56\n",
      "          16       0.45      0.49      0.47        53\n",
      "          17       0.49      0.28      0.36       117\n",
      "          18       0.42      0.38      0.40        37\n",
      "          19       0.65      0.69      0.67       232\n",
      "          20       0.36      0.39      0.38        76\n",
      "          21       0.36      0.36      0.36       196\n",
      "          22       0.30      0.28      0.29       145\n",
      "          23       0.35      0.29      0.32        24\n",
      "          24       0.00      0.00      0.00        13\n",
      "          25       0.58      0.43      0.49        98\n",
      "          26       0.54      0.65      0.59       117\n",
      "          27       0.12      0.10      0.11        31\n",
      "          28       0.40      0.14      0.21        28\n",
      "          29       0.56      0.61      0.59       185\n",
      "          30       0.49      0.72      0.58        36\n",
      "          31       0.58      0.57      0.57       146\n",
      "          32       0.38      0.39      0.39        38\n",
      "          33       0.31      0.26      0.29        68\n",
      "          34       0.34      0.44      0.38        48\n",
      "          35       0.40      0.44      0.42        75\n",
      "          36       0.50      0.56      0.53         9\n",
      "          37       0.71      0.54      0.61        89\n",
      "          38       0.43      0.48      0.45        92\n",
      "          39       0.56      0.64      0.60       126\n",
      "          40       0.44      0.51      0.47        82\n",
      "          41       0.70      0.76      0.73        62\n",
      "          42       0.43      0.41      0.42        66\n",
      "          43       0.61      0.68      0.64       169\n",
      "          44       0.66      0.75      0.70       141\n",
      "          45       0.38      0.42      0.40       127\n",
      "          46       0.56      0.48      0.52        75\n",
      "          47       0.36      0.43      0.39        69\n",
      "          48       0.61      0.52      0.56       124\n",
      "          49       0.00      0.00      0.00         5\n",
      "          50       0.00      0.00      0.00         9\n",
      "          51       0.43      0.41      0.42        22\n",
      "          52       0.47      0.44      0.45        39\n",
      "          53       0.47      0.53      0.50        53\n",
      "          54       0.71      0.68      0.69        77\n",
      "          55       0.16      0.05      0.08        58\n",
      "          56       0.41      0.33      0.37        75\n",
      "          57       0.21      0.17      0.19        86\n",
      "          58       0.28      0.24      0.26       115\n",
      "          59       0.33      0.31      0.31       177\n",
      "          60       0.50      0.20      0.29        15\n",
      "          61       0.35      0.34      0.34       102\n",
      "          62       0.53      0.47      0.50       188\n",
      "          63       0.45      0.30      0.36        46\n",
      "          64       0.42      0.44      0.43        68\n",
      "          65       0.33      0.42      0.37        38\n",
      "          66       0.31      0.32      0.32        37\n",
      "          67       0.59      0.69      0.64       191\n",
      "          68       0.43      0.32      0.36        19\n",
      "          69       0.62      0.40      0.49        57\n",
      "          70       0.22      0.22      0.22         9\n",
      "          71       0.30      0.27      0.29        33\n",
      "          72       0.55      0.50      0.52        24\n",
      "          73       0.66      0.63      0.65        81\n",
      "          74       0.53      0.60      0.56       194\n",
      "          75       0.21      0.13      0.16        45\n",
      "          76       0.48      0.62      0.54        65\n",
      "          77       0.55      0.65      0.60       107\n",
      "          78       0.44      0.34      0.39        32\n",
      "          79       0.50      0.22      0.30        23\n",
      "          80       0.60      0.43      0.50        28\n",
      "          81       0.40      0.50      0.44       146\n",
      "          82       0.68      0.46      0.55        46\n",
      "          83       0.41      0.53      0.46        30\n",
      "          84       0.30      0.22      0.25        36\n",
      "          85       0.71      0.75      0.73        20\n",
      "          86       0.50      0.52      0.51        27\n",
      "          87       0.00      0.00      0.00         9\n",
      "          88       0.55      0.52      0.53        99\n",
      "          89       0.11      0.07      0.08        15\n",
      "          90       0.36      0.22      0.28        18\n",
      "          91       0.35      0.25      0.29        28\n",
      "          92       0.39      0.42      0.40        81\n",
      "          93       0.29      0.27      0.28       123\n",
      "          94       0.34      0.32      0.33        81\n",
      "          95       0.46      0.48      0.47        46\n",
      "          96       0.47      0.45      0.46        51\n",
      "          97       0.33      0.23      0.27        22\n",
      "          98       0.33      0.22      0.27        58\n",
      "          99       0.56      0.61      0.58        82\n",
      "         100       0.86      0.55      0.67        11\n",
      "         101       0.37      0.52      0.43        21\n",
      "         102       0.35      0.24      0.29        33\n",
      "         103       0.31      0.18      0.23        91\n",
      "         104       0.35      0.50      0.41        26\n",
      "         105       0.47      0.40      0.43        40\n",
      "         106       0.68      0.51      0.58        37\n",
      "         107       0.00      0.00      0.00        14\n",
      "         108       0.40      0.40      0.40         5\n",
      "         109       0.40      0.33      0.36         6\n",
      "         110       0.51      0.42      0.46        53\n",
      "         111       0.29      0.13      0.18        15\n",
      "         112       0.46      0.52      0.49        23\n",
      "         113       0.20      0.09      0.13        11\n",
      "         114       0.00      0.00      0.00         6\n",
      "         115       0.33      0.10      0.15        10\n",
      "         116       0.19      0.08      0.12        36\n",
      "         117       0.46      0.24      0.32        25\n",
      "         118       0.25      0.17      0.20        12\n",
      "         119       0.40      0.50      0.44         4\n",
      "         120       0.00      0.00      0.00        31\n",
      "         121       0.00      0.00      0.00         2\n",
      "         122       0.00      0.00      0.00        15\n",
      "         123       0.57      0.53      0.55        15\n",
      "         124       0.00      0.00      0.00         4\n",
      "         125       0.33      0.31      0.32        13\n",
      "         126       0.17      0.09      0.12        11\n",
      "         127       0.67      0.63      0.65        19\n",
      "         128       0.20      0.19      0.19        16\n",
      "         129       0.35      0.39      0.37        41\n",
      "         130       0.27      0.32      0.29        25\n",
      "         131       0.32      0.43      0.36        14\n",
      "         132       0.35      0.31      0.33        26\n",
      "         133       0.20      0.14      0.17         7\n",
      "         134       0.33      0.33      0.33         9\n",
      "         135       0.00      0.00      0.00         6\n",
      "         136       0.50      0.10      0.17        10\n",
      "         137       0.00      0.00      0.00         2\n",
      "         139       0.00      0.00      0.00         1\n",
      "         140       0.33      0.25      0.29         4\n",
      "         141       0.83      0.45      0.59        11\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         3\n",
      "         144       0.00      0.00      0.00         3\n",
      "         145       0.00      0.00      0.00         1\n",
      "         146       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.46     12515\n",
      "   macro avg       0.38      0.35      0.35     12515\n",
      "weighted avg       0.45      0.46      0.45     12515\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slintel/bert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/slintel/bert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/slintel/bert/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d685b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ef589f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43531761885737114\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='linear', C = 1.0)\n",
    "clf.fit(X_train_vec,y_train)\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9906e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''SVM'''\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "clf = OneVsRestClassifier(SVC(kernel='linear', probability=True,verbose=True), n_jobs=-1)\n",
    "# model = LinearSVC(verbose=1,n_jobs=-1)\n",
    "clf.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94db4df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test_vec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e51cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_vec)\n",
    "print(metrics.classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ee85f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "            xticklabels=df.company_industry.values, yticklabels=df.company_industry.values)\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa846b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.values.ravel()\n",
    "y_test=y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b8b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X=X_train\n",
    "y=y_train\n",
    "\n",
    "start = time.time()\n",
    "clf = OneVsRestClassifier(SVC(kernel='linear', probability=True, class_weight='auto'.n_jobs=-1,verbose=1))\n",
    "clf.fit(X, y)\n",
    "end = time.time()\n",
    "print \"Single SVC\", end - start, clf.score(X,y)\n",
    "proba = clf.predict_proba(X)\n",
    "\n",
    "n_estimators = 10\n",
    "start = time.time()\n",
    "clf = OneVsRestClassifier(BaggingClassifier(SVC(kernel='linear', probability=True, class_weight='auto',n_jobs=-1,verbose=1), max_samples=1.0 / n_estimators, n_estimators=n_estimators))\n",
    "clf.fit(X, y)\n",
    "end = time.time()\n",
    "print \"Bagging SVC\", end - start, clf.score(X,y)\n",
    "proba = clf.predict_proba(X)\n",
    "\n",
    "start = time.time()\n",
    "clf = RandomForestClassifier(min_samples_leaf=20,n_jobs=-1,verbose=True)\n",
    "clf.fit(X, y)\n",
    "end = time.time()\n",
    "print \"Random Forest\", end - start, clf.score(X,y)\n",
    "proba = clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec6d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "disp = plot_precision_recall_curve(classifier, X_test, y_test)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
