{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18527e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "data=pd.read_excel(\"BERT 1114 corr.xlsx\")\n",
    "curated = pd.read_csv(\"CURATED-Data_Science_Team - Curated_BA_Team (Intersection) DS Team-English_Wor.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf15ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import nltk\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aef31f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=data.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca2af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_list = list(set(curated['technology_match'].str.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b24fe19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>Manually Tagged</th>\n",
       "      <th>BERT_Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000b6932-faea-4d13-ae67-2b4f592fc4d2</td>\n",
       "      <td>' technical product manager \\n\\nremote or uk r...</td>\n",
       "      <td>['roadmap', 'python', 'tensorflow', 'lifecycle...</td>\n",
       "      <td>['tensorflow', 'wluper', 'pytorch\\\\\\\\n', 'life...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0190f755-2b7c-42ac-8885-40a4b8fe3014</td>\n",
       "      <td>\" engineering development and design director ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01dd5cd9-5b68-4b16-bac5-a0c43baa7fc1</td>\n",
       "      <td>' kr11899 - bpm developer 12 month contract - ...</td>\n",
       "      <td>['salesforce crm', 'alteryx', 'uipath', 'share...</td>\n",
       "      <td>['sharepoint', 'alteryx', 'microsoft']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0215ccfb-15db-4777-9866-cef94c954f89</td>\n",
       "      <td>' location \\n\\neden prairie minnesota\\n\\nstart...</td>\n",
       "      <td>['claims', 'jenkins']</td>\n",
       "      <td>['jenkins', 'claims']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03150b33-54ba-4303-9857-d509f9ee11f8</td>\n",
       "      <td>casualnn posted 4 days agonnnmedical assistant...</td>\n",
       "      <td>['microsoft office']</td>\n",
       "      <td>['microsoft office', 'microsoft']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>zXx6TvRNOrufaoVWLzBYXA_0000</td>\n",
       "      <td>'an enthusiastic sales professional with a pro...</td>\n",
       "      <td>['compass', 'rr donnelley']</td>\n",
       "      <td>['rr', 'rr donnelley', 'compass']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>Zz1GBd9QSXjH9HaG3cpe3w_0000</td>\n",
       "      <td>'honours graduate of the office administration...</td>\n",
       "      <td>['quickbooks']</td>\n",
       "      <td>['microsoft', ' office', 'destaron', 'quickboo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>Zzgul1Rz-vv64w6I1M6ybQ_0000</td>\n",
       "      <td>'specialist experience in workplace diversity ...</td>\n",
       "      <td>['lifeworks']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>\"i am interested in making new connections and...</td>\n",
       "      <td>['smaato']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID  \\\n",
       "0     000b6932-faea-4d13-ae67-2b4f592fc4d2   \n",
       "1     0190f755-2b7c-42ac-8885-40a4b8fe3014   \n",
       "2     01dd5cd9-5b68-4b16-bac5-a0c43baa7fc1   \n",
       "3     0215ccfb-15db-4777-9866-cef94c954f89   \n",
       "4     03150b33-54ba-4303-9857-d509f9ee11f8   \n",
       "...                                    ...   \n",
       "1110           zXx6TvRNOrufaoVWLzBYXA_0000   \n",
       "1111           Zz1GBd9QSXjH9HaG3cpe3w_0000   \n",
       "1112           Zzgul1Rz-vv64w6I1M6ybQ_0000   \n",
       "1113                                #NAME?   \n",
       "1114                                   NaN   \n",
       "\n",
       "                                                   text  \\\n",
       "0     ' technical product manager \\n\\nremote or uk r...   \n",
       "1     \" engineering development and design director ...   \n",
       "2     ' kr11899 - bpm developer 12 month contract - ...   \n",
       "3     ' location \\n\\neden prairie minnesota\\n\\nstart...   \n",
       "4     casualnn posted 4 days agonnnmedical assistant...   \n",
       "...                                                 ...   \n",
       "1110  'an enthusiastic sales professional with a pro...   \n",
       "1111  'honours graduate of the office administration...   \n",
       "1112  'specialist experience in workplace diversity ...   \n",
       "1113  \"i am interested in making new connections and...   \n",
       "1114                                                NaN   \n",
       "\n",
       "                                        Manually Tagged  \\\n",
       "0     ['roadmap', 'python', 'tensorflow', 'lifecycle...   \n",
       "1                                                    []   \n",
       "2     ['salesforce crm', 'alteryx', 'uipath', 'share...   \n",
       "3                                 ['claims', 'jenkins']   \n",
       "4                                  ['microsoft office']   \n",
       "...                                                 ...   \n",
       "1110                        ['compass', 'rr donnelley']   \n",
       "1111                                     ['quickbooks']   \n",
       "1112                                      ['lifeworks']   \n",
       "1113                                         ['smaato']   \n",
       "1114                                                 []   \n",
       "\n",
       "                                              BERT_Tags  \n",
       "0     ['tensorflow', 'wluper', 'pytorch\\\\\\\\n', 'life...  \n",
       "1                                                    []  \n",
       "2                ['sharepoint', 'alteryx', 'microsoft']  \n",
       "3                                 ['jenkins', 'claims']  \n",
       "4                     ['microsoft office', 'microsoft']  \n",
       "...                                                 ...  \n",
       "1110                  ['rr', 'rr donnelley', 'compass']  \n",
       "1111  ['microsoft', ' office', 'destaron', 'quickboo...  \n",
       "1112                                                 []  \n",
       "1113                                                 []  \n",
       "1114                                                NaN  \n",
       "\n",
       "[1115 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a5f68a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "manually_tagged = \"Manually Tagged\" #manual tag column name\n",
    "# data = dump_format_change(data, manually_tagged)\n",
    "data[manually_tagged]=data[manually_tagged].astype(str)\n",
    "data[manually_tagged]=data[manually_tagged].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78124020",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BERT_Tags'] = [ [] if x is np.NaN else x for x in data['BERT_Tags'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecb10cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tag = \"BERT_Tags\" #manual tag column name\n",
    "# data = dump_format_change(data, bert_tag)\n",
    "data[bert_tag]=data[bert_tag].astype(str)\n",
    "data[bert_tag]=data[bert_tag].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "180d394c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Source'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-11cdbcc1a91a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Source'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Manually Tagged'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'BERT_Tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/my_env/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3030\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_env/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my_env/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Source'] not in index\""
     ]
    }
   ],
   "source": [
    "data=data[['ID','Source','text','Manually Tagged','BERT_Tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24986cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>Manually Tagged</th>\n",
       "      <th>BERT_Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000b6932-faea-4d13-ae67-2b4f592fc4d2</td>\n",
       "      <td>' technical product manager \\n\\nremote or uk r...</td>\n",
       "      <td>[roadmap, python, tensorflow, lifecycle, pytor...</td>\n",
       "      <td>[tensorflow, wluper, pytorch\\\\n, lifecycle, ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0190f755-2b7c-42ac-8885-40a4b8fe3014</td>\n",
       "      <td>\" engineering development and design director ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01dd5cd9-5b68-4b16-bac5-a0c43baa7fc1</td>\n",
       "      <td>' kr11899 - bpm developer 12 month contract - ...</td>\n",
       "      <td>[salesforce crm, alteryx, uipath, sharepoint]</td>\n",
       "      <td>[sharepoint, alteryx, microsoft]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0215ccfb-15db-4777-9866-cef94c954f89</td>\n",
       "      <td>' location \\n\\neden prairie minnesota\\n\\nstart...</td>\n",
       "      <td>[claims, jenkins]</td>\n",
       "      <td>[jenkins, claims]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03150b33-54ba-4303-9857-d509f9ee11f8</td>\n",
       "      <td>casualnn posted 4 days agonnnmedical assistant...</td>\n",
       "      <td>[microsoft office]</td>\n",
       "      <td>[microsoft office, microsoft]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>zXx6TvRNOrufaoVWLzBYXA_0000</td>\n",
       "      <td>'an enthusiastic sales professional with a pro...</td>\n",
       "      <td>[compass, rr donnelley]</td>\n",
       "      <td>[rr, rr donnelley, compass]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>Zz1GBd9QSXjH9HaG3cpe3w_0000</td>\n",
       "      <td>'honours graduate of the office administration...</td>\n",
       "      <td>[quickbooks]</td>\n",
       "      <td>[microsoft,  office, destaron, quickbooks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>Zzgul1Rz-vv64w6I1M6ybQ_0000</td>\n",
       "      <td>'specialist experience in workplace diversity ...</td>\n",
       "      <td>[lifeworks]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>#NAME?</td>\n",
       "      <td>\"i am interested in making new connections and...</td>\n",
       "      <td>[smaato]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID  \\\n",
       "0     000b6932-faea-4d13-ae67-2b4f592fc4d2   \n",
       "1     0190f755-2b7c-42ac-8885-40a4b8fe3014   \n",
       "2     01dd5cd9-5b68-4b16-bac5-a0c43baa7fc1   \n",
       "3     0215ccfb-15db-4777-9866-cef94c954f89   \n",
       "4     03150b33-54ba-4303-9857-d509f9ee11f8   \n",
       "...                                    ...   \n",
       "1110           zXx6TvRNOrufaoVWLzBYXA_0000   \n",
       "1111           Zz1GBd9QSXjH9HaG3cpe3w_0000   \n",
       "1112           Zzgul1Rz-vv64w6I1M6ybQ_0000   \n",
       "1113                                #NAME?   \n",
       "1114                                   NaN   \n",
       "\n",
       "                                                   text  \\\n",
       "0     ' technical product manager \\n\\nremote or uk r...   \n",
       "1     \" engineering development and design director ...   \n",
       "2     ' kr11899 - bpm developer 12 month contract - ...   \n",
       "3     ' location \\n\\neden prairie minnesota\\n\\nstart...   \n",
       "4     casualnn posted 4 days agonnnmedical assistant...   \n",
       "...                                                 ...   \n",
       "1110  'an enthusiastic sales professional with a pro...   \n",
       "1111  'honours graduate of the office administration...   \n",
       "1112  'specialist experience in workplace diversity ...   \n",
       "1113  \"i am interested in making new connections and...   \n",
       "1114                                                NaN   \n",
       "\n",
       "                                        Manually Tagged  \\\n",
       "0     [roadmap, python, tensorflow, lifecycle, pytor...   \n",
       "1                                                    []   \n",
       "2         [salesforce crm, alteryx, uipath, sharepoint]   \n",
       "3                                     [claims, jenkins]   \n",
       "4                                    [microsoft office]   \n",
       "...                                                 ...   \n",
       "1110                            [compass, rr donnelley]   \n",
       "1111                                       [quickbooks]   \n",
       "1112                                        [lifeworks]   \n",
       "1113                                           [smaato]   \n",
       "1114                                                 []   \n",
       "\n",
       "                                              BERT_Tags  \n",
       "0     [tensorflow, wluper, pytorch\\\\n, lifecycle, ja...  \n",
       "1                                                    []  \n",
       "2                      [sharepoint, alteryx, microsoft]  \n",
       "3                                     [jenkins, claims]  \n",
       "4                         [microsoft office, microsoft]  \n",
       "...                                                 ...  \n",
       "1110                        [rr, rr donnelley, compass]  \n",
       "1111         [microsoft,  office, destaron, quickbooks]  \n",
       "1112                                                 []  \n",
       "1113                                                 []  \n",
       "1114                                                 []  \n",
       "\n",
       "[1115 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25ba879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Acc_Sheet():\n",
    "    '''\n",
    "__init__ : INPUT: Data_Path, Technology Dictionary path, English Dictionary path\n",
    "                  4 Column Names-- ID, text, Correct Tags(MANUAL), BERT Tags\n",
    "                  \n",
    "clean_text: Can modify this according to requirement\n",
    "            INPUT: Text\n",
    "            RETURNS: Cleaned Text\n",
    "            \n",
    "ENG_SHEET: INPUT: None\n",
    "           RETURNS:English Accuracy DataFrame (From BERT)\n",
    "           \n",
    "TECH_SHEET: INPUT: None\n",
    "            RETURNS:Technology Accuracy DataFrame (From String Match)\n",
    "            \n",
    "ENG_TECH_SHEET: INPUT: None \n",
    "                RETURNS: English & Technology Combines Accuracy DataFrame \n",
    "                \n",
    "There are other in-built functions in this class which is required for the above functions to return,\n",
    "It is advisable to not to modify them\n",
    "\n",
    "***GENERATE SHEETS IN FOLLOWING ORDER - ENG->TECH->ENG_TECH [Due to inbuilt dependencies]***\n",
    "    '''\n",
    "    def __init__(self,data_path,tech_path,eng_path,ID,summaries,manually_tagged,bert_tags):\n",
    "        self.data=pd.read_csv(data_path)\n",
    "        self.tech_data=pd.read_csv(tech_path)\n",
    "        self.eng_data=pd.read_csv(eng_path)\n",
    "        self.data_path=data_path\n",
    "        self.ID=ID\n",
    "        self.summaries=summaries\n",
    "        self.manually_tagged=manually_tagged\n",
    "        self.bert_tags=bert_tags\n",
    "        self.data[manually_tagged]=self.data[manually_tagged].apply(self.clean_text)\n",
    "        self.data[manually_tagged]=self.data[manually_tagged].apply(eval)\n",
    "\n",
    "        self.data[bert_tags] = self.data[bert_tags].apply(eval)\n",
    "        self.data[bert_tags] = self.data[bert_tags].apply(self.remove_space)\n",
    "\n",
    "        col_name_tech=self.tech_data.columns[-1]\n",
    "        self.tech_data[col_name_tech]=self.tech_data[col_name_tech].astype(str)\n",
    "        self.tech_data[col_name_tech]=self.tech_data[col_name_tech].apply(self.clean_text)\n",
    "        self.tech_list = list(set(self.tech_data[col_name_tech]))\n",
    "\n",
    "        col_name_eng=self.eng_data.columns[-1]\n",
    "        self.eng_data[col_name_eng]=self.eng_data[col_name_eng].astype(str)\n",
    "        self.eng_data[col_name_eng]=self.eng_data[col_name_eng].apply(self.clean_text)\n",
    "        self.eng_list= list(set(self.eng_data[col_name_eng]))\n",
    "        \n",
    "    def remove_space(self,string_list):\n",
    "        k = [\" \".join(i.split()) for i in string_list]\n",
    "        return k\n",
    "\n",
    "    def clean_text(self,text):\n",
    "        text = text.lower() # lowercase text\n",
    "        REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "        BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "    #     text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    #     text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "        return text\n",
    "\n",
    "    def to_list(self,inp):\n",
    "        return \"['\"+inp+\"']\"\n",
    "\n",
    "    # Pass the matched technology column that we got\n",
    "    def convert_data_format(self,df,column_name):\n",
    "        for i in range(0, len(df)):\n",
    "            if df[column_name][i][0] == '[':\n",
    "                res = ast.literal_eval(df[column_name][i])\n",
    "                df[column_name][i] = res\n",
    "            else:\n",
    "                x = []\n",
    "                x.insert(0, df[column_name][i])\n",
    "                df[column_name][i] = x\n",
    "        return df\n",
    "\n",
    "    def get_TP(self,df,manual_tagged_string,op_string):\n",
    "        tp=[]\n",
    "        for ind in df.index:\n",
    "            TP = FP = 0\n",
    "            for i in range(0, len(df[op_string][ind])):\n",
    "                if df[op_string][ind][i] in df[manual_tagged_string][ind]:\n",
    "                    TP = TP + 1\n",
    "                else:\n",
    "                    pass\n",
    "            tp.append(TP)\n",
    "        return tp\n",
    "\n",
    "    def get_FP(self,df,manual_tagged_string, op_string):\n",
    "        fp=[]\n",
    "        fp_entry=[]\n",
    "        for ind in df.index:\n",
    "            main_list = np.setdiff1d(df[op_string][ind],df[manual_tagged_string][ind])\n",
    "            fp.append(len(main_list))\n",
    "            fp_entry.append(main_list)\n",
    "        return fp, fp_entry\n",
    "\n",
    "    def get_FN(self,df,manual_tagged_string, op_string):\n",
    "        fn=[]\n",
    "        for ind in df.index:\n",
    "            main_list = np.setdiff1d(df[manual_tagged_string][ind], df[op_string][ind])\n",
    "            if df[manual_tagged_string][ind]=='[]':\n",
    "                fn.append(0)\n",
    "            else:\n",
    "                fn.append(len(main_list))\n",
    "        return fn\n",
    "\n",
    "    def get_tech_tagged_data(self,manually_tagged, tech_list):\n",
    "        keep=[]\n",
    "        for word in manually_tagged:\n",
    "            if word in tech_list:\n",
    "                keep.append(word)\n",
    "        return keep\n",
    "\n",
    "    def combine(self,lis1, lis2):\n",
    "        return list(set(lis1 + lis2))\n",
    "\n",
    "    def get_precision(self,tp,fp):    \n",
    "        if tp+fp ==0:\n",
    "            precision = 0\n",
    "        else:\n",
    "            precision = tp/(tp+fp)\n",
    "        return precision\n",
    "\n",
    "    def get_recall(self,tp,fn):\n",
    "        if tp+fn ==0:\n",
    "            recall = 0\n",
    "        else:\n",
    "            recall = tp/(tp+fn)\n",
    "        return recall\n",
    "\n",
    "    def get_f_score(self,precision, recall):\n",
    "        if precision+recall == 0:\n",
    "            f_score = 0\n",
    "        else:\n",
    "            f_score = 2*(precision*recall)/(precision+recall)\n",
    "        return f_score\n",
    "    \n",
    "    def reg_match(self,txt, keyw):\n",
    "            sep='|'\n",
    "            temp = sep.join(['\\\\b' + i+'\\\\b' for i in keyw])\n",
    "            matches = re.findall(temp,txt)\n",
    "            if len(''.join(list(set(matches))))==0:\n",
    "                return []\n",
    "            else:\n",
    "                return list(set(matches))\n",
    "\n",
    "    def Diff(self,li1, li2): #FP entries\n",
    "        return list(set(li2)-set(li1))\n",
    "\n",
    "    def Same(self,lis1,lis2): #TP entries\n",
    "        return list(set(lis1).intersection(lis2))\n",
    "\n",
    "    def Common(self,lis1,lis2): #merging same entries\n",
    "        return list(set(lis1)-(set(lis2)))\n",
    "    \n",
    "    def ENG_SHEET(self):\n",
    "    # (all entries which are in eng dictionary)\n",
    "        eng_bert_tags=[]\n",
    "        removed=0\n",
    "        kept=0\n",
    "        for i in range(0,len(self.data)):\n",
    "            eng_bert_1sen=[]\n",
    "            tags= self.data[self.bert_tags][i]\n",
    "            for j in tags:\n",
    "                if j in self.eng_list:\n",
    "                    kept+=1\n",
    "                    eng_bert_1sen.append(j)\n",
    "                else:\n",
    "                    removed+=1\n",
    "            eng_bert_tags.append(eng_bert_1sen)\n",
    "        self.data[bert_tags+\"_ENG\"]=eng_bert_tags\n",
    "        ##############################################################################################\n",
    "        self.data.to_csv(\"BERT_ENG_ONLY_TEMP_DATA.csv\",index=False)\n",
    "        '''SAME FILE WRITE AND READ'''\n",
    "        summary = pd.read_csv(\"BERT_ENG_ONLY_TEMP_DATA.csv\")\n",
    "        ##############################################################################################\n",
    "\n",
    "        summary = summary.sort_values(by=[self.ID], ascending=False)\n",
    "        summary.reset_index(inplace = True, drop = True)\n",
    "        col_name_op = bert_tags+\"_ENG\"\n",
    "\n",
    "        df_cm = summary\n",
    "        df_cm = self.convert_data_format(df_cm, col_name_op)\n",
    "        df_cm = self.convert_data_format(df_cm, manually_tagged)\n",
    "\n",
    "        count_context_technologies = []\n",
    "\n",
    "        for i in range(0, len(df_cm)):\n",
    "            count_context_technologies.extend(df_cm[manually_tagged][i])\n",
    "        d = list(set(count_context_technologies))\n",
    "\n",
    "        tp = []\n",
    "        tn = []\n",
    "        fp = []\n",
    "        fn = []\n",
    "        TP = TN = FP = FN = 0\n",
    "        df_cm[manually_tagged] = df_cm[manually_tagged].fillna('[]')\n",
    "\n",
    "        df_cm['Eng_Label']=df_cm[manually_tagged].copy()\n",
    "\n",
    "        tech_tag_list = []\n",
    "\n",
    "        df_cm['Eng_Label'] = df_cm.apply(\n",
    "            lambda x: self.get_tech_tagged_data(x[\"Eng_Label\"], self.eng_list),\n",
    "            axis = 1)\n",
    "        list_tech_dataset = []\n",
    "\n",
    "        # fill with \n",
    "        for i in range(0, len(df_cm)):\n",
    "            list_tech_dataset.extend(df_cm[\"Eng_Label\"][i])\n",
    "\n",
    "        set_tech = set(list_tech_dataset)\n",
    "\n",
    "        for i in range(0, len(df_cm)):\n",
    "            l = df_cm[col_name_op][i]\n",
    "            df_cm[col_name_op][i] = [0 if element == '0' else element for element in l]\n",
    "\n",
    "        for i in range(0, len(df_cm)):\n",
    "            words = df_cm[col_name_op][i]\n",
    "            stopwords = [0]\n",
    "            for word in list(words):\n",
    "                if word in stopwords:\n",
    "                    words.remove(word)\n",
    "\n",
    "        # list of technologies which are not in extracted list but are in tagged list i.e. FN entries\n",
    "        df_cm['FP_entries_eng'] = df_cm.apply(lambda x: self.Diff(x[\"Eng_Label\"], x[col_name_op]), axis = 1)\n",
    "\n",
    "        # list of technologies which are in extracted list and are in tagged list i.e. TP entries\n",
    "        df_cm['TP_entries_eng'] = df_cm.apply(lambda x: self.Same(x[\"Eng_Label\"], x[col_name_op]), axis = 1)\n",
    "\n",
    "        # list of technologies which are NOT extracted list and are in tagged list i.e. FN entries\n",
    "        df_cm['FN_entries_eng'] = df_cm.apply(lambda x: self.Common(x[\"Eng_Label\"], x[col_name_op]), axis = 1)\n",
    "\n",
    "        fp_entry =[]\n",
    "        tp = self.get_TP(df_cm, \"Eng_Label\", col_name_op)\n",
    "        fp, fp_entry_names = self.get_FP(df_cm, \"Eng_Label\", col_name_op)\n",
    "        fn = self.get_FN(df_cm, \"Eng_Label\", col_name_op)\n",
    "        # print(len(tp), len(fp), len(fn))\n",
    "        dict_fp = {}\n",
    "\n",
    "        for i in range(0, len(fp_entry_names)):\n",
    "            fp_entry_names[i] = fp_entry_names[i].tolist()\n",
    "            dict_fp[i] = fp_entry_names[i]\n",
    "\n",
    "        # creating a dataframe\n",
    "        df_matrix = pd.DataFrame(list(zip(tp, fp, fn)), \n",
    "                       columns =['TP', 'FP', \"FN\"])\n",
    "        df_matrix['Precision'] = df_matrix.apply(lambda x: self.get_precision(x[\"TP\"], x[\"FP\"]), axis = 1)\n",
    "\n",
    "        df_matrix[\"Recall\"] = df_matrix.apply(lambda x: self.get_recall(x[\"TP\"], x[\"FN\"]), axis = 1)\n",
    "\n",
    "        df_matrix[\"f_score\"] = df_matrix.apply(lambda x: self.get_f_score(x[\"Precision\"], x[\"Recall\"]), axis = 1)\n",
    "\n",
    "        final_data = df_cm.join(df_matrix)\n",
    "        return final_data\n",
    "\n",
    "    def TECH_SHEET(self):\n",
    "        summary = pd.read_csv(self.data_path)\n",
    "        summary[self.manually_tagged]=summary[self.manually_tagged].apply(self.clean_text)\n",
    "        summary = summary.sort_values(by=[self.ID], ascending=False)\n",
    "        summary.reset_index(inplace = True, drop = True)\n",
    "        summary[self.summaries]=summary[self.summaries].astype(str)\n",
    "        all_strings = list(summary[self.summaries].str.lower())\n",
    "        col_name_op = \"Tech_matched\"\n",
    "        i=1\n",
    "        tech_keys=[]\n",
    "        for item in all_strings:\n",
    "        #     print(\"***\",\"TEST No,\",i,\"***\")\n",
    "            i=i+1\n",
    "            tech_row=[]\n",
    "            for k in self.tech_list:\n",
    "                if k in item and len(k)>2:\n",
    "                    tech_row.append(k)\n",
    "            tech_keys.append(tech_row)\n",
    "\n",
    "        summary['keywords']=tech_keys\n",
    "\n",
    "        summary[col_name_op] = summary.apply(\n",
    "            lambda x: self.reg_match(x[self.summaries], x[\"keywords\"]),\n",
    "            axis = 1)\n",
    "        df_cm = summary\n",
    "        df_cm = self.convert_data_format(df_cm, manually_tagged)\n",
    "        df_cm[manually_tagged] = df_cm[manually_tagged].fillna('[]')\n",
    "        count_context_technologies = []\n",
    "        for i in range(0, len(df_cm)):\n",
    "            count_context_technologies.extend(df_cm[manually_tagged][i])\n",
    "        d = list(set(count_context_technologies))\n",
    "\n",
    "        tp = []\n",
    "        tn = []\n",
    "        fp = []\n",
    "        fn = []\n",
    "\n",
    "        TP = TN = FP = FN = 0\n",
    "\n",
    "        df_cm['Tech_Label'] = df_cm.apply(\n",
    "            lambda x: self.get_tech_tagged_data(x[manually_tagged],self.tech_list), axis = 1)\n",
    "        string_match_tech_col = df_cm['Tech_Label']\n",
    "        list_tech_dataset = []\n",
    "\n",
    "        for i in range(0, len(df_cm)):\n",
    "            list_tech_dataset.extend(df_cm[\"Tech_Label\"][i])\n",
    "\n",
    "        set_tech = set(list_tech_dataset)\n",
    "\n",
    "        for i in range(0, len(df_cm)):\n",
    "            l = df_cm[col_name_op][i]\n",
    "            df_cm[col_name_op][i] = [0 if element == '0' else element for element in l]\n",
    "\n",
    "        for i in range(0, len(df_cm)):\n",
    "            words = df_cm[col_name_op][i]\n",
    "            stopwords = [0]\n",
    "            for word in list(words):\n",
    "                if word in stopwords:\n",
    "                    words.remove(word)\n",
    "\n",
    "        # list of technologies which are not in extracted list but are in tagged list i.e. FN entries\n",
    "        df_cm['FP_entries_TECH'] = df_cm.apply(lambda x: self.Diff(x[\"Tech_Label\"], x[col_name_op]), axis = 1)\n",
    "\n",
    "        # list of technologies which are in extracted list and are in tagged list i.e. TP entries\n",
    "        df_cm['TP_entries_TECH'] = df_cm.apply(lambda x: self.Same(x[\"Tech_Label\"], x[col_name_op]), axis = 1)\n",
    "\n",
    "        # list of technologies which are NOT extracted list and are in tagged list i.e. FN entries\n",
    "        df_cm['FN_entries_TECH'] = df_cm.apply(lambda x: self.Common(x[\"Tech_Label\"], x[col_name_op]), axis = 1)\n",
    "        # function call\n",
    "        fp_entry =[]\n",
    "        tp = self.get_TP(df_cm, \"Tech_Label\", col_name_op)\n",
    "        fp, fp_entry_names = self.get_FP(df_cm, \"Tech_Label\", col_name_op)\n",
    "        fn = self.get_FN(df_cm, \"Tech_Label\", col_name_op)\n",
    "\n",
    "        # creating a dataframe\n",
    "        df_matrix = pd.DataFrame(list(zip(tp, fp, fn)), \n",
    "                       columns =['TP', 'FP', \"FN\"])\n",
    "\n",
    "        df_matrix['Precision'] = df_matrix.apply(lambda x: self.get_precision(x[\"TP\"], x[\"FP\"]), axis = 1)\n",
    "\n",
    "        df_matrix[\"Recall\"] = df_matrix.apply(lambda x: self.get_recall(x[\"TP\"], x[\"FN\"]), axis = 1)\n",
    "\n",
    "        df_matrix[\"f_score\"] = df_matrix.apply(lambda x: self.get_f_score(x[\"Precision\"], x[\"Recall\"]), axis = 1)\n",
    "\n",
    "        df_cm=df_cm.drop(columns=\"keywords\")\n",
    "        final_data = df_cm.join(df_matrix)\n",
    "        return final_data\n",
    "    \n",
    "    def ENG_TECH_SHEET(self):\n",
    "        data=pd.read_csv(\"BERT_ENG_ONLY_TEMP_DATA.csv\")#####READ ENG SHEET GENERATED from ENG_SHEET########\n",
    "        bert_tags=\"BERT_Tags_ENG\"\n",
    "        col_name_op=\"BERT_ENG+string_matched\"\n",
    "\n",
    "        data[bert_tags] = data[bert_tags].apply(str)\n",
    "        data[bert_tags] = data[bert_tags].apply(eval)\n",
    "        data[bert_tags] = data[bert_tags].apply(self.remove_space)\n",
    "        summary=data\n",
    "        summary[self.summaries]=summary[self.summaries].astype(str)\n",
    "        all_strings = list(summary[self.summaries].str.lower())\n",
    "\n",
    "        tech_keys=[]\n",
    "        for item in all_strings:\n",
    "            tech_row=[]\n",
    "            for k in self.tech_list:\n",
    "                if k in item and len(k)>2:\n",
    "                    tech_row.append(k)\n",
    "            tech_keys.append(tech_row)\n",
    "        summary['keywords']=tech_keys\n",
    "        summary['string_matched'] = summary.apply(lambda x: self.reg_match(x[self.summaries], x[\"keywords\"]), axis = 1)\n",
    "        summary['BERT_ENG+string_matched'] = summary.apply(\n",
    "            lambda x: self.combine(x[bert_tags], x[\"string_matched\"]), \n",
    "            axis = 1)\n",
    "        data=summary\n",
    "        ########CHANGE NAME ##################\n",
    "        data.to_csv(\"BERT_ENG_ONLY_TEMP_DATA+TECH.csv\")\n",
    "        ###########READ SAME FILE####################\n",
    "        summary = pd.read_csv(\"BERT_ENG_ONLY_TEMP_DATA+TECH.csv\")\n",
    "        col_name_op =\"BERT_ENG+string_matched\"#column name\n",
    "        summary = summary.sort_values(by=[self.ID], ascending=False)\n",
    "        summary.reset_index(inplace = True, drop = True)\n",
    "\n",
    "        df_cm = summary\n",
    "        df_cm = self.convert_data_format(df_cm, col_name_op)\n",
    "        df_cm = self.convert_data_format(df_cm,manually_tagged)\n",
    "        count_context_technologies = []\n",
    "        for i in range(0, len(df_cm)):\n",
    "            count_context_technologies.extend(df_cm[manually_tagged][i])\n",
    "        d = list(set(count_context_technologies))\n",
    "        tp = []\n",
    "        tn = []\n",
    "        fp = []\n",
    "        fn = []\n",
    "\n",
    "        TP = TN = FP = FN = 0\n",
    "        df_cm[manually_tagged] = df_cm[manually_tagged].fillna('[]')\n",
    "        for i in range(0, len(df_cm)):\n",
    "            l = df_cm[col_name_op][i]\n",
    "            df_cm[col_name_op][i] = [0 if element == '0' else element for element in l]\n",
    "\n",
    "        for i in range(0, len(df_cm)):\n",
    "            words = df_cm[col_name_op][i]\n",
    "            stopwords = [0]\n",
    "            for word in list(words):\n",
    "                if word in stopwords:\n",
    "                    words.remove(word)\n",
    "\n",
    "        # list of technologies which are not in extracted list but are in tagged list i.e. FN entries\n",
    "        df_cm['FP_entries'] = df_cm.apply(lambda x: self.Diff(x[manually_tagged], x[col_name_op]), axis = 1)\n",
    "\n",
    "        # list of technologies which are in extracted list and are in tagged list i.e. TP entries\n",
    "        df_cm['TP_entries'] = df_cm.apply(lambda x: self.Same(x[manually_tagged], x[col_name_op]), axis = 1)\n",
    "\n",
    "        # list of technologies which are NOT extracted list and are in tagged list i.e. FN entries\n",
    "        df_cm['FN_entries'] = df_cm.apply(lambda x: self.Common(x[manually_tagged], x[col_name_op]), axis = 1)\n",
    "        \n",
    "        fp_entry =[]\n",
    "        tp = self.get_TP(df_cm, manually_tagged, col_name_op)\n",
    "        fp, fp_entry_names = self.get_FP(df_cm, manually_tagged, col_name_op)\n",
    "        fn = self.get_FN(df_cm, manually_tagged, col_name_op)\n",
    "\n",
    "        dict_fp = {}\n",
    "\n",
    "        for i in range(0, len(fp_entry_names)):\n",
    "            fp_entry_names[i] = fp_entry_names[i].tolist()\n",
    "            dict_fp[i] = fp_entry_names[i]\n",
    "\n",
    "        # creating a dataframe\n",
    "        df_matrix = pd.DataFrame(list(zip(tp, fp, fn)), \n",
    "                       columns =['TP', 'FP', \"FN\"])\n",
    "\n",
    "        df_matrix['Precision'] = df_matrix.apply(lambda x: self.get_precision(x[\"TP\"], x[\"FP\"]), axis = 1)\n",
    "\n",
    "        df_matrix[\"Recall\"] = df_matrix.apply(lambda x: self.get_recall(x[\"TP\"], x[\"FN\"]), axis = 1)\n",
    "\n",
    "        df_matrix[\"f_score\"] = df_matrix.apply(lambda x: self.get_f_score(x[\"Precision\"], x[\"Recall\"]), axis = 1)\n",
    "\n",
    "        final_data = df_cm.join(df_matrix)\n",
    "        return final_data\n",
    "    \n",
    "    \n",
    "    def CURATED_SHEET(self):\n",
    "        summary = self.data\n",
    "        summary = summary.sort_values(by=[self.ID], ascending=False)\n",
    "        summary.reset_index(inplace = True, drop = True)\n",
    "        col_name_op = bert_tags\n",
    "\n",
    "        df_cm = summary\n",
    "#         df_cm = self.convert_data_format(df_cm, col_name_op)\n",
    "#         df_cm = self.convert_data_format(df_cm, manually_tagged)\n",
    "\n",
    "        count_context_technologies = []\n",
    "\n",
    "        for i in range(0, len(df_cm)):\n",
    "            count_context_technologies.extend(df_cm[manually_tagged][i])\n",
    "        d = list(set(count_context_technologies))\n",
    "\n",
    "        tp = []\n",
    "        tn = []\n",
    "        fp = []\n",
    "        fn = []\n",
    "        TP = TN = FP = FN = 0\n",
    "        df_cm[manually_tagged] = df_cm[manually_tagged].fillna('[]')\n",
    "\n",
    "        df_cm['Eng_Label']=df_cm[manually_tagged].copy()\n",
    "\n",
    "        tech_tag_list = []\n",
    "\n",
    "        df_cm['Eng_Label'] = df_cm.apply(\n",
    "            lambda x: self.get_tech_tagged_data(x[\"Eng_Label\"], self.eng_list),\n",
    "            axis = 1)\n",
    "        list_tech_dataset = []\n",
    "\n",
    "        # fill with \n",
    "        for i in range(0, len(df_cm)):\n",
    "            list_tech_dataset.extend(df_cm[\"Eng_Label\"][i])\n",
    "\n",
    "        set_tech = set(list_tech_dataset)\n",
    "\n",
    "        for i in range(0, len(df_cm)):\n",
    "            l = df_cm[col_name_op][i]\n",
    "            df_cm[col_name_op][i] = [0 if element == '0' else element for element in l]\n",
    "\n",
    "        for i in range(0, len(df_cm)):\n",
    "            words = df_cm[col_name_op][i]\n",
    "            stopwords = [0]\n",
    "            for word in list(words):\n",
    "                if word in stopwords:\n",
    "                    words.remove(word)\n",
    "\n",
    "        # list of technologies which are not in extracted list but are in tagged list i.e. FN entries\n",
    "        df_cm['FP_entries_eng'] = df_cm.apply(lambda x: self.Diff(x[\"Eng_Label\"], x[col_name_op]), axis = 1)\n",
    "\n",
    "        # list of technologies which are in extracted list and are in tagged list i.e. TP entries\n",
    "        df_cm['TP_entries_eng'] = df_cm.apply(lambda x: self.Same(x[\"Eng_Label\"], x[col_name_op]), axis = 1)\n",
    "\n",
    "        # list of technologies which are NOT extracted list and are in tagged list i.e. FN entries\n",
    "        df_cm['FN_entries_eng'] = df_cm.apply(lambda x: self.Common(x[\"Eng_Label\"], x[col_name_op]), axis = 1)\n",
    "\n",
    "        fp_entry =[]\n",
    "        tp = self.get_TP(df_cm, \"Eng_Label\", col_name_op)\n",
    "        fp, fp_entry_names = self.get_FP(df_cm, \"Eng_Label\", col_name_op)\n",
    "        fn = self.get_FN(df_cm, \"Eng_Label\", col_name_op)\n",
    "        # print(len(tp), len(fp), len(fn))\n",
    "        dict_fp = {}\n",
    "\n",
    "        for i in range(0, len(fp_entry_names)):\n",
    "            fp_entry_names[i] = fp_entry_names[i].tolist()\n",
    "            dict_fp[i] = fp_entry_names[i]\n",
    "\n",
    "        # creating a dataframe\n",
    "        df_matrix = pd.DataFrame(list(zip(tp, fp, fn)), \n",
    "                       columns =['TP', 'FP', \"FN\"])\n",
    "        df_matrix['Precision'] = df_matrix.apply(lambda x: self.get_precision(x[\"TP\"], x[\"FP\"]), axis = 1)\n",
    "\n",
    "        df_matrix[\"Recall\"] = df_matrix.apply(lambda x: self.get_recall(x[\"TP\"], x[\"FN\"]), axis = 1)\n",
    "\n",
    "        df_matrix[\"f_score\"] = df_matrix.apply(lambda x: self.get_f_score(x[\"Precision\"], x[\"Recall\"]), axis = 1)\n",
    "\n",
    "        final_data = df_cm.join(df_matrix)\n",
    "        return final_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0753680e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENG_SHEET_NAME 383 15 145\n"
     ]
    }
   ],
   "source": [
    "data_path = \"ALL_MANUAL_PREDS_CURATED.csv\" #ENTER DATA PATH\n",
    "tech_path = \"Tech_pydictionary_2.csv\"\n",
    "eng_path = \"Eng_pydictionary_2.csv\"\n",
    "ID = 'ID'                                # ID column name\n",
    "text_col = 'text'                       # column name on which predictions are made\n",
    "manually_tagged = 'Manually Tagged'                 #manual tag column name\n",
    "bert_tags = 'BERT_Tags'                      #column name\n",
    "\n",
    "obj_name = Acc_Sheet(data_path,tech_path,eng_path,ID,text_col,manually_tagged,bert_tags)\n",
    "\n",
    "temp = obj_name.ENG_SHEET()    ##########GIVE ENG ACC NAME############\n",
    "print(\"ENG_SHEET_NAME\", temp['TP'].sum(), temp['FP'].sum(), temp['FN'].sum())\n",
    "ENG_SHEET_NAME = \"ACC-BERT_CURATED_ENG_ONLY_DATE.csv\"\n",
    "temp.to_csv(ENG_SHEET_NAME,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e91dad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC-TECH_SM_CURATED_DATE.csv 2068 37 36\n"
     ]
    }
   ],
   "source": [
    "temp = obj_name.TECH_SHEET()\n",
    "TECH_SHEET_NAME = \"ACC-TECH_SM_CURATED_DATE.csv\"  ##########GIVE TECH ACC NAME############\n",
    "\n",
    "print(TECH_SHEET_NAME, temp['TP'].sum(), temp['FP'].sum(), temp['FN'].sum())\n",
    "# temp.to_csv(TECH_SHEET_NAME,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e799fd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_csv(TECH_SHEET_NAME,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5ea9584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-ccbe4671ad68>:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name][i] = res\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC-ENG_TECH_SM_CURATED_DATE.csv 2450 51 203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-ccbe4671ad68>:394: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cm[col_name_op][i] = [0 if element == '0' else element for element in l]\n"
     ]
    }
   ],
   "source": [
    "temp = obj_name.ENG_TECH_SHEET()\n",
    "ENG_TECH_SHEET_NAME = \"ACC-ENG_TECH_SM_CURATED_DATE.csv\"  ##########GIVE ENG+TECH ACC NAME############\n",
    "\n",
    "print(ENG_TECH_SHEET_NAME, temp['TP'].sum(), temp['FP'].sum(), temp['FN'].sum())\n",
    "# temp.to_csv(ENG_TECH_SHEET_NAME,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aae2c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_csv(ENG_TECH_SHEET_NAME,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec2be5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_curated(manually_tagged):\n",
    "    curated_manual_list = []\n",
    "    for i in range(0,len(data[manually_tagged])):\n",
    "        k = data[manually_tagged][i]\n",
    "        one_sen_list = []\n",
    "        for j in k:\n",
    "            if j in match_list:\n",
    "                one_sen_list.append(j)\n",
    "        curated_manual_list.append(one_sen_list)\n",
    "    return curated_manual_list\n",
    "\n",
    "data['Common_Match_BERT']=get_curated('BERT_Tags')\n",
    "data['Common_Match_Manual']=get_curated('Manually Tagged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d67d8efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"ALL_MANUAL_PREDS_CURATED.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f39fa097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURATED_SHEET_NAME 249 1 49\n"
     ]
    }
   ],
   "source": [
    "data_path = \"ALL_MANUAL_PREDS_CURATED.csv\" #ENTER DATA PATH\n",
    "tech_path = \"Tech_pydictionary_2.csv\"\n",
    "eng_path = \"Eng_pydictionary_2.csv\"\n",
    "ID = 'ID'                                # ID column name\n",
    "text_col = 'text'                \n",
    "manually_tagged = 'Common_Match_Manual'                 #manual tag column name\n",
    "bert_tags = 'Common_Match_BERT'                      #column name\n",
    "\n",
    "obj_name = Acc_Sheet(data_path,tech_path,eng_path,ID,text_col,manually_tagged,bert_tags)\n",
    "\n",
    "temp = obj_name.CURATED_SHEET()    ##########GIVE ENG ACC NAME############\n",
    "print(\"CURATED_SHEET_NAME\", temp['TP'].sum(), temp['FP'].sum(), temp['FN'].sum())\n",
    "CURATED_SHEET_NAME = \"ACC-BERT_CURATED_.csv\"\n",
    "temp.to_csv(CURATED_SHEET_NAME,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aa0bab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
