{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"../Datas/tech_sort1k.csv\") #DATA PATH\n",
    "\n",
    "manual_tag_col = 'exact_matched_patt_contextual' #ENTER MANUAL TAGS COLUMN NAME\n",
    "text_col = 'summaries'  #ENTER PREDICTION COLUMN NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download(\"punkt\") #if required then download\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "\n",
    "'''MODIFY IF REQUIRED'''\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    \n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_tags(manual_tags): #give a list of strings then returns all tags as single & multi words\n",
    "    tech_dict = {}\n",
    "    for j in manual_tags:\n",
    "        if j not in tech_dict:\n",
    "            tech_dict[j] = 1\n",
    "        else:\n",
    "            tech_dict[j] += 1\n",
    "\n",
    "    tech_list=[]\n",
    "    tech_multi_words=[]\n",
    "    for i in tech_dict:\n",
    "        if ((' ' in i) == True):\n",
    "            tech_multi_words.append(i)\n",
    "        else:\n",
    "            tech_list.append(i)\n",
    "#     if(len(tech_multi_words)>0):\n",
    "#         print(tech_multi_words)\n",
    "    return tech_list,tech_multi_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[manual_tag_col] = [ [] if x is np.NaN else x for x in data[manual_tag_col] ]\n",
    "data[manual_tag_col]=data[manual_tag_col].astype(str)\n",
    "data[manual_tag_col] = data[manual_tag_col].apply(eval) #to convert string to list of strings\n",
    "\n",
    "data[text_col]=data[text_col].apply(clean_text)\n",
    "data[text_col] = data[text_col].replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all(a_str, sub):\n",
    "    '''\n",
    "    To Get all occurences(index) of a string\n",
    "    '''\n",
    "    start = 0\n",
    "    while True:\n",
    "        start = a_str.find(sub, start)\n",
    "        if start == -1: return\n",
    "        yield start\n",
    "        start += len(sub) # use start += 1 to find overlapping matches\n",
    "\n",
    "def convert(lst):\n",
    "    #break words\n",
    "    return ' '.join(lst).split()\n",
    "\n",
    "def BIO_conversion(sentence,manual_tags):\n",
    "    '''\n",
    "    First get Single and Multi-words tags\n",
    "    Searching for all occurences of the Multi-words tags and storing those indexes \n",
    "    '''\n",
    "    tech_list,tech_multi_words = give_tags(manual_tags)\n",
    "    ind_dict = {}\n",
    "    for i in tech_multi_words:\n",
    "        if i in sentence:\n",
    "            #ind_dict[sentence.index(i)]=i #\n",
    "            all_occ = list(find_all(sentence,i)) # [0, 5, 10, 15]\n",
    "            for ind in all_occ:\n",
    "                ind_dict[ind]=i #word as value, key as index\n",
    "\n",
    "    temp_word=\"\"\n",
    "    final_word_sen=[]\n",
    "    final_tag_sen = []\n",
    "    start=-1\n",
    "    end=-1\n",
    "    for i in range(0, len(sentence)):\n",
    "        if(i in range(start,end)): #if the index right now is within a multi word TAG, we dont need to check it\n",
    "            continue\n",
    "        if sentence[i].isspace()==True and len(temp_word)>0: #on encountering a SPACE push to word\n",
    "            final_word_sen.append(temp_word)\n",
    "            if temp_word in tech_list: #checking if word is in a single word TAG\n",
    "                final_tag_sen.append(\"B\")\n",
    "            else:                      #since word is not a Single word TAG, give it O (OUSTIDE) tag\n",
    "                final_tag_sen.append(\"O\") \n",
    "            temp_word=\"\" #resetting the word\n",
    "        else: #not space\n",
    "            try: #do we have multiword at this index\n",
    "                temp_word=ind_dict[i] #GET THE MULTI WORD TAG\n",
    "                start=i+1              #storing the starting index\n",
    "                end=i+len(temp_word) #here tag these multiwords and update new i\n",
    "                listofwords = convert([temp_word]) #get those words splitted\n",
    "                f=True\n",
    "                for word in listofwords:\n",
    "                    final_word_sen.append(word) #pushing the word\n",
    "                    if f:\n",
    "                        final_tag_sen.append(\"B\") #Starting of Multi WORD (appending the TAG)\n",
    "                        f=False                   #MARK FLAG as false, rest of the multi words are I(INSIDE TAG)\n",
    "                    else: \n",
    "                        final_tag_sen.append(\"I\") # appending the TAG\n",
    "                temp_word=\"\"\n",
    "            except: #not a space and not a multiword TAG, so just concatenate the string\n",
    "                if(sentence[i]!=' '):\n",
    "                    temp_word+=sentence[i]\n",
    "    return pd.DataFrame(list(zip(final_word_sen, final_tag_sen)),columns =['Word', 'Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=pd.DataFrame()\n",
    "for i in range(0,len(data)):\n",
    "    temp = BIO_conversion(data[text_col][i],data[manual_tag_col][i])\n",
    "    length = len(temp)\n",
    "    wordd=\"Sentence :\"+str(i+1) #sentence no.\n",
    "    a=[wordd]*length\n",
    "    temp.insert(0,\"Sentence #\",a)\n",
    "    final_data = final_data.append(temp, ignore_index=True) #appending sentences in the required format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=final_data\n",
    "df.loc[(df['Tag'] == 'B'), 'Tag'] = 'B-ORG'\n",
    "df.loc[(df['Tag'] == 'I'), 'Tag'] = 'I-ORG'\n",
    "df.to_csv(\"output.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
