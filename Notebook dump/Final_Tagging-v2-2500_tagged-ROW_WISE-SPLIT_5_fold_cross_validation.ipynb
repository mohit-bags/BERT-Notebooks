{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel(\"Manually_Tagged_Sheet.xlsx\",sheet_name=\"Valid Entries_updated_15_06_202\")\n",
    "# data.head()\n",
    "data=data.drop(columns=[\"exact_matched_patt\",\"spacy_format_v1\",\"spacy_format_v1\",\"summaries_matching\"])\n",
    "data.columns=[\"id\",\"summaries\",\"exact_matched_patt_contextual\",\"Tech_from_string_match\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.loc[:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2501"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.sort_values(by=['id'])\n",
    "data=data.reset_index(drop=True)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data.loc[:499]\n",
    "data2=data.loc[500:999]\n",
    "data3=data.loc[1000:1499]\n",
    "data4=data.loc[1500:1999]\n",
    "data5=data.loc[2000:2499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500, 500, 500, 500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data1),len(data2),len(data3),len(data4),len(data5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data5 ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"SPLIT5_DATA_FOR_PREDICTION.csv\") ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mohitbagaria/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#replacing null vals with empty list\n",
    "data['exact_matched_patt_contextual'] = [ [] if x is np.NaN else x for x in data['exact_matched_patt_contextual'] ]\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, l in enumerate(data[\"exact_matched_patt_contextual\"]):\n",
    "#  print(\"list\",i,\"is\",type(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['exact_matched_patt_contextual']=data['exact_matched_patt_contextual'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, l in enumerate(data[\"exact_matched_patt_contextual\"]):\n",
    "#  print(\"list\",i,\"is\",type(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_alt_list(list_):\n",
    "#     list_ = list_.replace(', ', \"','\")\n",
    "#     list_ = list_.replace('[', \"['\")\n",
    "#     list_ = list_.replace(']', \"']\")\n",
    "    \n",
    "    if(list_[0]!='['):\n",
    "        list_='['+list_\n",
    "    if(list_[len(list_)-1]!=']'):\n",
    "        list_+=']'\n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"exact_matched_patt_contextual\"] = data[\"exact_matched_patt_contextual\"].apply(clean_alt_list)\n",
    "\n",
    "data[\"exact_matched_patt_contextual\"] = data[\"exact_matched_patt_contextual\"].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_tags(manual_tags): #a list\n",
    "    tech_dict = {}\n",
    "    for j in manual_tags:\n",
    "        if j not in tech_dict:\n",
    "            tech_dict[j] = 1\n",
    "        else:\n",
    "            tech_dict[j] += 1\n",
    "\n",
    "    # tech_dict\n",
    "\n",
    "    tech_list=[]\n",
    "    tech_multi_words=[]\n",
    "    for i in tech_dict:\n",
    "        if ((' ' in i) == True):\n",
    "            tech_multi_words.append(i)\n",
    "        else:\n",
    "            tech_list.append(i)\n",
    "#     if(len(tech_multi_words)>0):\n",
    "#         print(tech_multi_words)\n",
    "    return tech_list,tech_multi_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"summaries\"]=data[\"summaries\"].apply(clean_text)\n",
    "data.summaries = data.summaries.replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all(a_str, sub):\n",
    "    start = 0\n",
    "    while True:\n",
    "        start = a_str.find(sub, start)\n",
    "        if start == -1: return\n",
    "        yield start\n",
    "        start += len(sub) # use start += 1 to find overlapping matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(lst):\n",
    "    return ' '.join(lst).split()\n",
    "\n",
    "\n",
    "def BIO_conversion(sentence,manual_tags):\n",
    "    tech_list,tech_multi_words = give_tags(manual_tags)\n",
    "    ind_dict = {}\n",
    "    for i in tech_multi_words:\n",
    "        if i in sentence:\n",
    "#             ind_dict[sentence.index(i)]=i #word as val, key as index\n",
    "            all_occ = list(find_all(sentence,i)) # [0, 5, 10, 15]\n",
    "            for ind in all_occ:\n",
    "                ind_dict[ind]=i\n",
    "\n",
    "            \n",
    "    temp_word=\"\"\n",
    "    final_word_sen=[]\n",
    "    final_tag_sen = []\n",
    "    start=-1\n",
    "    end=-1\n",
    "    for i in range(0, len(sentence)):\n",
    "        if(i in range(start,end)):\n",
    "#             print(\"break hua\")\n",
    "            continue\n",
    "#         print(i)\n",
    "        if sentence[i].isspace()==True and len(temp_word)>0:\n",
    "            final_word_sen.append(temp_word)\n",
    "            if temp_word in tech_list:\n",
    "#                 print(temp_word)\n",
    "                final_tag_sen.append(\"B\")\n",
    "            else:\n",
    "                final_tag_sen.append(\"O\")\n",
    "            temp_word=\"\"\n",
    "        else: #not space\n",
    "            try: #do we have multiword at this index\n",
    "                temp_word=ind_dict[i]\n",
    "#                 print(\"****\")\n",
    "                start=i+1\n",
    "                end=i+len(temp_word) #here tag these multiwords and update new i\n",
    "#                 print(i)\n",
    "#                 print(\"****\")\n",
    "#                 print(temp_word)\n",
    "                listofwords = convert([temp_word])\n",
    "                f=True\n",
    "                for word in listofwords:\n",
    "                    final_word_sen.append(word)\n",
    "                    if f:\n",
    "                        final_tag_sen.append(\"B\")\n",
    "                        f=False\n",
    "                    else:\n",
    "                        final_tag_sen.append(\"I\")\n",
    "                temp_word=\"\"\n",
    "            except:\n",
    "                if(sentence[i]!=' '):\n",
    "                    temp_word+=sentence[i]\n",
    "                \n",
    "    return pd.DataFrame(list(zip(final_word_sen, final_tag_sen)),columns =['Word', 'Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=pd.DataFrame()\n",
    "split=2000 ##########\n",
    "for i in range(0,len(data)):\n",
    "    temp = BIO_conversion(data[\"summaries\"][i],data[\"exact_matched_patt_contextual\"][i])\n",
    "    length = len(temp)\n",
    "    wordd=\"Sentence :\"+str(i+1+split) #sentence no.\n",
    "    a=[wordd]*length\n",
    "    temp.insert(0,\"Sentence #\",a)\n",
    "    final_data = final_data.append(temp, ignore_index=True) #appending sentences in the required format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O    97417\n",
       "B     2591\n",
       "I      568\n",
       "Name: Tag, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['Tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=final_data\n",
    "df.loc[(df['Tag'] == 'B'), 'Tag'] = 'B-ORG'\n",
    "df.loc[(df['Tag'] == 'I'), 'Tag'] = 'I-ORG'\n",
    "df.to_csv(\"SPLIT5_BIO_tagged_data.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
