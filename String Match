# -*- coding: utf-8 -*-
"""String Match.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mG3YtHzr0EZz4f7Z1-BYc7CIxXTb7sr9
"""

#libraries for preprocessing
import nltk
import pandas as pd
import numpy as np
import ast
import json
import re
from bs4 import BeautifulSoup
nltk.download("punkt")
REPLACE_BY_SPACE_RE = re.compile('[/(){}\[\]\|@,;]')
BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')
#libraries for string match
from tqdm import tqdm
import time
from nltk.stem.wordnet import WordNetLemmatizer
from PyDictionary import PyDictionary
from collections import OrderedDict 
#for parallel processing
from joblib import Parallel, delayed
from joblib import Memory
backend = 'multiprocessing'

def get_exact_match(txt, techt):
    try:
        patt = '|'.join(['\\b'+elem+'\\b' for elem in techt])
        matched_patt = re.findall(patt,txt)
    except Exception as e:
        print(e)
        matched_patt = []
    return matched_patt

def save_file(df, name):
    df.to_csv(name , index = False)

class preprocessing():
        
    def read_input_file(self, tech_file_path):
        data = pd.read_csv(tech_file_path)
        data.reset_index(inplace = True, drop = True)
        self.data = data
        return data
    
    def read_tech_list(self, tech_file_path):
        tech = pd.read_csv(tech_file_path)
        col_name = list(tech.columns)[-1]
        for i in range(len(tech[col_name])):
            tech[col_name][i] = self.clean_text(tech[col_name][i])
        return tech
    
    def read_remove_list(self, remove_file_path):
        r = pd.read_csv(remove_file_path)
        for i in range(0, len(r)):
            r["Remove"][i] = r["Remove"][i].lower()
            remove_list = r["Remove"].tolist()
        return remove_list
    
    def dump_format_change(self, df, col_name):
        for i in range(0, len(df)):
            if df[col_name][i] is not np.nan:
                demo = df[col_name][i]
                res = demo.strip('][')
                resl = []
                resl.append(res)
                df[col_name][i] = resl

            else:
                df[col_name][i] = '[]'
                demo = df[col_name][i]
                res = demo.strip('][')
                resl = []
                resl.append(res)
                df[col_name][i] = resl
        return df 
    
    def clean_text(self, text):
        text = text.lower()
        text = re.sub(r'^\s*$', " ",text)
        text = re.sub('\s+', " ", text)
        text = re.sub('\n', ' ', text)
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub('[^a-zA-Z0-9]',' ',text)
        text = re.sub('\s+',' ',text)
        text = BeautifulSoup(text, "lxml").text # HTML decoding
        text = text.lower() # lowercase text
        text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text
        text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text
        return text   
    
    def start_cleaning(self, df, col_name):
        df = df.loc[:, df.notnull().any(axis = 0)]
        df['text_clean'] = df[col_name].apply(str).apply(lambda x: self.clean_text(x))
        df = self.dump_format_change(df, 'text_clean')
        
        print()
        print("Sample Preprocessed Data:")
        print("Before:")
        print(df[col_name][10])
        print()
        print("After:")
        print(df['text_clean'][10])
        
        df.reset_index(inplace = True, drop = True)
        return df

class string_match():
    def create_tech_keys(self, tech, tech_col_name, df , df_col_name ):
        tech[tech_col_name] = tech[tech_col_name].astype(str)
        all_tech_words = list(tech[tech_col_name].str.lower())
        df["summaries_matching"] = df[df_col_name].astype(str)
        all_strings = list(df["summaries_matching"].str.lower())

        i=1
        tech_keys=[]

        for item in all_strings:
            #print("***","TEST No,",i,"***")
            i=i+1
            tech_row=[]
            for k in all_tech_words:
                if k in item and len(k)>2:
                    tech_row.append(k)
            tech_keys.append(tech_row)
        df['Tech_from_string_match'] = tech_keys
        return df
    
    def start_string_match(self, tech, tech_col_name, df , df_col_name , remove_list):
        df = self.create_tech_keys(tech, tech_col_name, df , df_col_name)
        
        for ind in df.index:
            res = list(OrderedDict.fromkeys(df["Tech_from_string_match"][ind]))
            df["Tech_from_string_match"][ind] = res
            
        for i in range(0, len(df)):
            for word in list(df["Tech_from_string_match"][i]):
                if word in remove_list:
                    df["Tech_from_string_match"][i].remove(word)
        
        df['exact_matched_patt'] = df.apply(lambda x: get_exact_match(x[df_col_name][0], x["Tech_from_string_match"]), axis = 1)                   
        print("Creation Of Tags is Over. Saving the file.")
        return df

print("Please Enter the path to summary file.")
summary_file_path = input()

print("Please Enter the path to remove list file.")
remove_list_path = input()

print("Please input the file path to master dictionary (Tech + Eng with entries > 30,000)")
tech_file_path = input()

x = preprocessing()

remove_list = x.read_remove_list(remove_list_path)
test = x.read_input_file(summary_file_path)
test.head()

tech = x.read_tech_list(tech_file_path)

tech.head(20)

test = x.start_cleaning(test, 'summaries')

y = string_match()

test = y.start_string_match(tech, 'Tech_word', test , 'text_clean' , remove_list)

print("The result of string match is:")
test['exact_matched_patt']

save_file(test, 'String_Match.csv')

