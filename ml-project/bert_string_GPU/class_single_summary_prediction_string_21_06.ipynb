{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2724f03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PyDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "local-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import json\n",
    "import re\n",
    "# import swifter\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# from PyDictionary import PyDictionary # for dictionary splitting\n",
    "from collections import OrderedDict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "chronic-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_prediction_single_summary():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.summary = input()\n",
    "        if self.summary[0] == '[':\n",
    "            res = ast.literal_eval(self.summary)\n",
    "            self.summary = res\n",
    "        else:\n",
    "            x = []\n",
    "            x.insert(0, self.summary)\n",
    "            self.summary = x\n",
    "        \n",
    "        \n",
    "        \n",
    "    def read_file(self, tech_file_path):\n",
    "        tech = pd.read_csv(tech_file_path)\n",
    "        tech.columns = [\"index\", \"title\"]\n",
    "        tech.drop(columns = [\"index\"], axis =1 , inplace = True)\n",
    "        tech.reset_index(inplace = True, drop = True)\n",
    "        self.tech = tech\n",
    "        \n",
    "        return tech\n",
    "        \n",
    "    def high_freq_eng_words(self, tech_file_path):\n",
    "        \n",
    "        r = pd.read_csv(tech_file_path)\n",
    "        self.r = r\n",
    "        for i in range(0, len(r)):\n",
    "            r[\"Remove\"][i] = r[\"Remove\"][i].lower()\n",
    "            remove_list = r[\"Remove\"].tolist()\n",
    "            remove_list.append(\"ve\")\n",
    "            self.remove_list = remove_list\n",
    "            \n",
    "        return remove_list\n",
    "            \n",
    "    def string_match(self):\n",
    "        \n",
    "        tech_list = []\n",
    "        summary_list = []\n",
    "        id_list = []\n",
    "        \n",
    "        self.tech['title'] = self.tech['title'].astype(str)\n",
    "        all_tech_words = list(self.tech['title'].str.lower())\n",
    "        \n",
    "        tech_keys=[]\n",
    "        tech_row=[]\n",
    "        \n",
    "        for k in all_tech_words:\n",
    "            if k in self.summary[0] and len(k)>2:\n",
    "                tech_row.append(k)\n",
    "        \n",
    "        def get_exact_match(txt, tech):\n",
    "            try:\n",
    "                patt = '|'.join(['\\\\b'+elem+'\\\\b' for elem in tech])\n",
    "                matched_patt = re.findall(patt,txt)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                matched_patt = []\n",
    "            return matched_patt\n",
    "        \n",
    "        txt = self.summary[0]\n",
    "        exact_matched_patt = get_exact_match(txt, tech_row)\n",
    "        \n",
    "        res = list(OrderedDict.fromkeys(exact_matched_patt))\n",
    "        exact_matched_patt = res\n",
    "        \n",
    "        for word in list(exact_matched_patt):\n",
    "            if word in self.remove_list:\n",
    "                exact_matched_patt.remove(word)\n",
    "                \n",
    "        op = exact_matched_patt\n",
    "        if len(op)==0:\n",
    "            print(\"/n/n***No Match Found | You Gave an Empty Summary***\\n\\n\")\n",
    "        if len(op)!=0:\n",
    "            print(\"\\n\\n*** Yes, We have a Match !! ***\\n\\n\",op)\n",
    "    \n",
    "        return op\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "electoral-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_ip = ['full stack developer 9+ years of experience leading small (5-10) development teams in large-scale projects. proficient in java & javascript; backend frameworks such as spring, struts, hibernate; frontend frameworks angular js, protractor, jasmine. db mainly oracle but also mysql, sqlserver; wide variety of bussiness domains working for companies like cars.com, credit suisse, qualcomm, hewlett-packard, inter-american development bank, bank of america & monsanto. experience in agile methodologies kanban & scrum; test driven development. always looking for new challenges and learn new technologies., architect at globant - credit suisse, tech lead at globant - cars.com, scjp 6 certified programmer, tech lead at softtek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-antique",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "restricted-vienna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['full stack developer 9+ years of experience leading small (5-10) development teams in large-scale projects. proficient in java & javascript; backend frameworks such as spring, struts, hibernate; frontend frameworks angular js, protractor, jasmine. db mainly oracle but also mysql, sqlserver; wide variety of bussiness domains working for companies like cars.com, credit suisse, qualcomm, hewlett-packard, inter-american development bank, bank of america & monsanto. experience in agile methodologies kanban & scrum; test driven development. always looking for new challenges and learn new technologies., architect at globant - credit suisse, tech lead at globant - cars.com, scjp 6 certified programmer, tech lead at softtek']\n"
     ]
    }
   ],
   "source": [
    "x = BERT_prediction_single_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "medium-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech = x.read_file(\"../dataset/Tech_pydictionary_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dramatic-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = x.high_freq_eng_words(\"../dataset/Remove.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "welcome-relative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Yes, We have a Match !! ***\n",
      "\n",
      " ['javascript', 'mysql']\n"
     ]
    }
   ],
   "source": [
    "string_match_op = x.string_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "pressed-vault",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(string_match_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-birth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
