{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1EE4g2bRHJNW"
   },
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install PyDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3AqmWw0zX0CG"
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gtDebCj8X3Bh"
   },
   "outputs": [],
   "source": [
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2cmRDXqDHJNY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import json\n",
    "import re\n",
    "# import swifter\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VEL6yZCaIOnd"
   },
   "outputs": [],
   "source": [
    "from PyDictionary import PyDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fOc21GBMSSqv"
   },
   "outputs": [],
   "source": [
    "# dictionary=PyDictionary()\n",
    "# print(dictionary.meaning(\"CymbalStream\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZzBHezmzHJNZ"
   },
   "outputs": [],
   "source": [
    "# tech = pd.read_csv(\"Dataset/Technology Summary Matching Project - technologies.csv\")\n",
    "# tech = pd.read_csv(\"Technology Summary Matching Project - technologies-post-removing.csv\")\n",
    "# tech = pd.read_csv(\"New_Technology_Sheet.csv\")\n",
    "# tech = pd.read_csv(\"Tech_pydictionary.csv\")\n",
    "\n",
    "summary = pd.read_csv(\"Train_Data/Accuracy_Data/Dataset_to_run_on_all/tagged_simanchala_900.csv\")\n",
    "\n",
    "# summary = pd.read_csv(\"Dataset/10000_profiles_summary.csv\")\n",
    "# summary = pd.read_csv(\"Dataset/Test-NewV3 - Testing-Sheet(23_02) - Sheet1.csv\")\n",
    "# summary = pd.read_csv(\"a4f32761-65b8-45e8-99ed-fb8ad4a63f8d.csv\")\n",
    "# summary = pd.read_csv(\"Dataset/10000_profiles_summary.csv\")\n",
    "summary_copy = summary.copy()\n",
    "# tech_copy = tech.copy()\n",
    "\n",
    "\n",
    "# tech = pd.read_csv(\"Dataset/Technology Summary Matching Project - technologies.csv\")\n",
    "tech = pd.read_csv(\"Tech_pydictionary_2.csv\")\n",
    "\n",
    "# tech = pd.read_csv(\"New_Technology_Sheet.csv\")\n",
    "# summary = pd.read_csv(\"a4f32761-65b8-45e8-99ed-fb8ad4a63f8d.csv\")\n",
    "# summary = pd.read_csv(\"testing_drawback - Sheet1.csv\")\n",
    "# summary = pd.read_csv(\"train_data_original_untagged.csv\")\n",
    "# summary = pd.read_csv(\"train_data_original_untagged.csv\")\n",
    "\n",
    "# a4f32761-65b8-45e8-99ed-fb8ad4a63f8d.csv\n",
    "# summary = pd.read_csv(\"Train_Data/Accuracy_Data/Dataset_to_run_on_all/tagged_simanchala_100.csv\")\n",
    "\n",
    "\n",
    "# summary = pd.read_csv(\"Train_Data/String_Match_non_duplicates - String_Match_non_duplicates.csv\")\n",
    "output = pd.read_csv(\"Dataset/output - output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zyhHPsgDH-bn"
   },
   "outputs": [],
   "source": [
    "summary.columns = [\"id\", \"summaries\", \"exact_matched_patt\", \"Unnamed: 3\", \"Technology\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fg0Yg8HxIDJ1"
   },
   "source": [
    "* PyDictionary *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPQ0094HKiSs"
   },
   "outputs": [],
   "source": [
    "# k = [\"Customer Relationship Management\", \"Lattice\", \"Java\", \"Oyez Forms\", \"outsourcing\", \"sigma\", \"built in\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvbQcvauJZLt"
   },
   "outputs": [],
   "source": [
    "\n",
    "def contains_multiple_words(s):\n",
    "  return len(re.compile('\\W').split(s)) > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aM1qNDhiT8T3"
   },
   "outputs": [],
   "source": [
    "\n",
    "def contains_single_words(s):\n",
    "  v = len(re.compile('\\W').split(s))\n",
    "  print(v)\n",
    "  if (v)==1:\n",
    "    return True\n",
    "  else:\n",
    "    return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pXRwnd4ndtKu"
   },
   "outputs": [],
   "source": [
    "# x = contains_single_words(\"Customer Relationship Management\")\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZEph884-KTJJ"
   },
   "outputs": [],
   "source": [
    "def convert_single_word(string_tech):\n",
    "    return (string_tech.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PBjpY6PBYC_v"
   },
   "outputs": [],
   "source": [
    "def give_base_form(word):\n",
    "  for word in words:\n",
    "    h = WordNetLemmatizer().lemmatize(word,'v')\n",
    "  return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yow2Ny36RfEl"
   },
   "outputs": [],
   "source": [
    "# # dictionary=PyDictionary(\"hotel\",\"ambush\",\"nonchalant\",\"perceptive\")\n",
    "# # 'There can be any number of words in the Instance'\n",
    "\n",
    "# # print(dictionary.printMeanings()) \n",
    "# # print(dictionary.getMeanings()) \n",
    "# # print (dictionary.getSynonyms())\n",
    "\n",
    "# # print (dictionary.translateTo(\"hi\"))\n",
    "\n",
    "# dict_eng = {}\n",
    "# dict_tech = {}\n",
    "# none_set = set([None])\n",
    "# for i in range(0, len(k)):\n",
    "#   print(i)\n",
    "#   check = []\n",
    "#   word = k[i]\n",
    "#   dictionary=PyDictionary(word)\n",
    "#   f = dictionary.getMeanings()\n",
    "#   if f[word] is None and contains_single_words(word):\n",
    "#     print(\"\\n 1. Single Word and not in Dictionary\\n\")\n",
    "#     print(\"\\n\\n Searching Base Form \\n\\n\")\n",
    "#     dict_tech[i] = word\n",
    "#   elif f[word] is None and contains_multiple_words(word):\n",
    "#     print(\"\\n 2. Multiple Words and in one go not in dictionary, so split them individualy and check \\n\")\n",
    "#     a = convert_single_word(word)\n",
    "#     for j in range(0, len(a)):\n",
    "#       dictionary_2 = PyDictionary(a[j])\n",
    "#       g = dictionary_2.getMeanings()\n",
    "#       check.append(g[a[j]])\n",
    "\n",
    "#     if None in check:\n",
    "#       print(\"\\n 2.1 All words in Multi Words are not English, put in Technology List\\n\")\n",
    "#       dict_tech[i] = word\n",
    "\n",
    "#     else:\n",
    "#       print(\"\\n 2.2 All words in Multi Words are English, put in English List\\n\")\n",
    "#       dict_eng[i] = word\n",
    "#   else:\n",
    "#     print(\"\\n 3 Single words and present in dictionary\\n\")\n",
    "#     dict_eng[i] = word\n",
    "\n",
    "# dictionary=PyDictionary(\"hotel\",\"ambush\",\"nonchalant\",\"perceptive\")\n",
    "# 'There can be any number of words in the Instance'\n",
    "\n",
    "# print(dictionary.printMeanings()) \n",
    "# print(dictionary.getMeanings()) \n",
    "# print (dictionary.getSynonyms())\n",
    "\n",
    "# print (dictionary.translateTo(\"hi\"))\n",
    "def dictionary_splitting(tech):\n",
    "\n",
    "  dict_eng = {}\n",
    "  dict_tech = {}\n",
    "  none_set = set([None])\n",
    "  for i in range(0, len(tech)):\n",
    "    print(\"\\n Currently at Index :\\n\",i)\n",
    "    check = []\n",
    "    word = tech[\"title\"][i]\n",
    "    dictionary=PyDictionary(word)\n",
    "    f = dictionary.getMeanings()\n",
    "    if f[word] is None and contains_single_words(word):\n",
    "      dict_tech[i] = word\n",
    "    elif f[word] is None and contains_multiple_words(word):\n",
    "      a = convert_single_word(word)\n",
    "      for j in range(0, len(a)):\n",
    "        dictionary_2 = PyDictionary(a[j])\n",
    "        g = dictionary_2.getMeanings()\n",
    "        check.append(g[a[j]])\n",
    "\n",
    "      if None in check:\n",
    "        dict_tech[i] = word\n",
    "\n",
    "      else:\n",
    "        dict_eng[i] = word\n",
    "    else:\n",
    "      dict_eng[i] = word\n",
    "\n",
    "  return dict_eng, dict_tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2TRHSMzeNpp",
    "outputId": "65522d55-06f7-4332-ded5-2d303322aac7"
   },
   "outputs": [],
   "source": [
    "dict_eng, dict_tech = dictionary_splitting(tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of English dictionary\", len(dict_eng), \"Length of Tech dictionary\", len(dict_tech))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YC1nxUwBmi7o"
   },
   "outputs": [],
   "source": [
    "df_eng = pd.DataFrame.from_dict(dict_eng, orient ='index') \n",
    "df_tech = pd.DataFrame.from_dict(dict_tech, orient ='index') \n",
    "df_eng.columns = [\"English_word\"]\n",
    "df_tech.columns = [\"Tech_word\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "7dOVb35Mmy7F",
    "outputId": "e05985da-db83-44fb-8574-37611611fdbb"
   },
   "outputs": [],
   "source": [
    "df_eng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "oqOkzztkm11B",
    "outputId": "44ec3b8a-1fa3-419a-e33b-635e3aed8efb"
   },
   "outputs": [],
   "source": [
    "df_tech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tech.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZpH6P80jeR8u",
    "outputId": "21fda673-31ec-4741-d6f7-d7bddbdb9402"
   },
   "outputs": [],
   "source": [
    "df_eng.to_csv(\"Eng_pydictionary.csv\", index = True)\n",
    "df_tech.to_csv(\"Tech_pydictionary.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-H36xkhjscG"
   },
   "outputs": [],
   "source": [
    "df_eng.to_csv(\"Eng_pydictionary_2.csv\", index = True)\n",
    "df_tech.to_csv(\"Tech_pydictionary_2.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PcsKPEm7H-n_"
   },
   "outputs": [],
   "source": [
    "# eng_dictionary.columns = [\"index\", \"title\"]\n",
    "# eng_dictionary.drop(columns = [\"index\"], axis =1 , inplace = True)\n",
    "# # eng_dictionary.set_index(\"index\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9MkktojzHJNa"
   },
   "outputs": [],
   "source": [
    "summary_copy = summary_copy.sort_values(by=\"summaries\",ascending = False, key = lambda x: x.str.len())\n",
    "summary_copy.reset_index(inplace = True, drop = True)\n",
    "# summary_copy = summary.iloc[2000:10000]\n",
    "# summary_copy.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summaries</th>\n",
       "      <th>exact_matched_patt</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Technology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-18msGiQiE2XLdy6XWGAEQ_0000</td>\n",
       "      <td>10+ years of leveraged finance and investment ...</td>\n",
       "      <td>['asset']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['asset']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4ldAQ53se0hp9GU5FgnIQ_0000</td>\n",
       "      <td>an extremely driven professional within the bi...</td>\n",
       "      <td>['attend', 'batch', 'daily']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-BSYFSH4GWqbTH-JhxVExA_0000</td>\n",
       "      <td>i am currently a junior at cal poly san luis o...</td>\n",
       "      <td>['honestly', 'astro', 'gain']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-EJPzKCOhrcLUKsIiC35Ow_0000</td>\n",
       "      <td>team manager with 8 years of experience enabli...</td>\n",
       "      <td>['later', 'stay', 'lob']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-EQeYEq-03cWVCkfnsUgow_0000</td>\n",
       "      <td>eric is an experienced risk, insurance, and pr...</td>\n",
       "      <td>['communicator', 'big picture']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  \\\n",
       "0  -18msGiQiE2XLdy6XWGAEQ_0000   \n",
       "1  -4ldAQ53se0hp9GU5FgnIQ_0000   \n",
       "2  -BSYFSH4GWqbTH-JhxVExA_0000   \n",
       "3  -EJPzKCOhrcLUKsIiC35Ow_0000   \n",
       "4  -EQeYEq-03cWVCkfnsUgow_0000   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  10+ years of leveraged finance and investment ...   \n",
       "1  an extremely driven professional within the bi...   \n",
       "2  i am currently a junior at cal poly san luis o...   \n",
       "3  team manager with 8 years of experience enabli...   \n",
       "4  eric is an experienced risk, insurance, and pr...   \n",
       "\n",
       "                exact_matched_patt  Unnamed: 3 Technology  \n",
       "0                        ['asset']         NaN  ['asset']  \n",
       "1     ['attend', 'batch', 'daily']         NaN        NaN  \n",
       "2    ['honestly', 'astro', 'gain']         NaN        NaN  \n",
       "3         ['later', 'stay', 'lob']         NaN        NaN  \n",
       "4  ['communicator', 'big picture']         NaN        NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summaries</th>\n",
       "      <th>exact_matched_patt</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>exact_matched_patt_contextual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186K6K0uQDU9BuWfCe6gSg_0000</td>\n",
       "      <td>2020 meeting professionals international board...</td>\n",
       "      <td>['engage']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PGRWYvPSJR7-hZUD68G2iA_0000</td>\n",
       "      <td>a dynamic professional with a total experience...</td>\n",
       "      <td>['factiva']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['factiva']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7fdL3V2BcVNYAtJ37PFCxw_0000</td>\n",
       "      <td>moorku investments, llc: owner offerup: princi...</td>\n",
       "      <td>['reply']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U7cEgDrDMkrOdjrvaBO6kg_0000</td>\n",
       "      <td>my main interests regarding research involve d...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JOIFnGwQuPqltgtWyMdegg_0000</td>\n",
       "      <td>quality &amp; continuous improvement executive wit...</td>\n",
       "      <td>['assembly', 'copper', 'sigma']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  \\\n",
       "0  186K6K0uQDU9BuWfCe6gSg_0000   \n",
       "1  PGRWYvPSJR7-hZUD68G2iA_0000   \n",
       "2  7fdL3V2BcVNYAtJ37PFCxw_0000   \n",
       "3  U7cEgDrDMkrOdjrvaBO6kg_0000   \n",
       "4  JOIFnGwQuPqltgtWyMdegg_0000   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  2020 meeting professionals international board...   \n",
       "1  a dynamic professional with a total experience...   \n",
       "2  moorku investments, llc: owner offerup: princi...   \n",
       "3  my main interests regarding research involve d...   \n",
       "4  quality & continuous improvement executive wit...   \n",
       "\n",
       "                exact_matched_patt  Unnamed: 3 exact_matched_patt_contextual  \n",
       "0                       ['engage']         NaN                           NaN  \n",
       "1                      ['factiva']         NaN                   ['factiva']  \n",
       "2                        ['reply']         NaN                           NaN  \n",
       "3                               []         NaN                           NaN  \n",
       "4  ['assembly', 'copper', 'sigma']         NaN                           NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ziOjDRMQnABl"
   },
   "outputs": [],
   "source": [
    "tech =df_tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24057"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "57uvoEsfHJNa",
    "outputId": "3772fc88-899a-4b98-e843-5042d21a6688"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tech_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>WorkflowMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>InGenius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>DealHub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Ebsta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Repsly Mobile CRM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          Tech_word\n",
       "0           1        WorkflowMax\n",
       "1           2           InGenius\n",
       "2           3            DealHub\n",
       "3           4              Ebsta\n",
       "4           5  Repsly Mobile CRM"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech.columns = [\"index\", \"title\"]\n",
    "tech.drop(columns = [\"index\"], axis =1 , inplace = True)\n",
    "tech.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_tech' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4824c66b7946>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_tech\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_tech' is not defined"
     ]
    }
   ],
   "source": [
    "df_tech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwkD1wGJHJNb"
   },
   "outputs": [],
   "source": [
    "# tech.columns = [\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e18_C15tHJNb"
   },
   "outputs": [],
   "source": [
    "# tech.drop(columns = [\"index\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "d8QKlbwFHJNc",
    "outputId": "088563d1-be5e-4321-8dab-b7a39d36ee5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24057"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-OMUqYU8HJNc",
    "outputId": "f93b6435-1805-4789-fbf7-b90d1fd1ffc5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summaries</th>\n",
       "      <th>exact_matched_patt</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>exact_matched_patt_contextual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186K6K0uQDU9BuWfCe6gSg_0000</td>\n",
       "      <td>2020 meeting professionals international board...</td>\n",
       "      <td>['engage']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PGRWYvPSJR7-hZUD68G2iA_0000</td>\n",
       "      <td>a dynamic professional with a total experience...</td>\n",
       "      <td>['factiva']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['factiva']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7fdL3V2BcVNYAtJ37PFCxw_0000</td>\n",
       "      <td>moorku investments, llc: owner offerup: princi...</td>\n",
       "      <td>['reply']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U7cEgDrDMkrOdjrvaBO6kg_0000</td>\n",
       "      <td>my main interests regarding research involve d...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JOIFnGwQuPqltgtWyMdegg_0000</td>\n",
       "      <td>quality &amp; continuous improvement executive wit...</td>\n",
       "      <td>['assembly', 'copper', 'sigma']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  \\\n",
       "0  186K6K0uQDU9BuWfCe6gSg_0000   \n",
       "1  PGRWYvPSJR7-hZUD68G2iA_0000   \n",
       "2  7fdL3V2BcVNYAtJ37PFCxw_0000   \n",
       "3  U7cEgDrDMkrOdjrvaBO6kg_0000   \n",
       "4  JOIFnGwQuPqltgtWyMdegg_0000   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  2020 meeting professionals international board...   \n",
       "1  a dynamic professional with a total experience...   \n",
       "2  moorku investments, llc: owner offerup: princi...   \n",
       "3  my main interests regarding research involve d...   \n",
       "4  quality & continuous improvement executive wit...   \n",
       "\n",
       "                exact_matched_patt  Unnamed: 3 exact_matched_patt_contextual  \n",
       "0                       ['engage']         NaN                           NaN  \n",
       "1                      ['factiva']         NaN                   ['factiva']  \n",
       "2                        ['reply']         NaN                           NaN  \n",
       "3                               []         NaN                           NaN  \n",
       "4  ['assembly', 'copper', 'sigma']         NaN                           NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gRJO0Ru1HJNd",
    "outputId": "30a5e1de-f660-42df-f46f-239626da7c15"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>summaries</th>\n",
       "      <th>exact_matched_patt</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Technology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-18msGiQiE2XLdy6XWGAEQ_0000</td>\n",
       "      <td>10+ years of leveraged finance and investment ...</td>\n",
       "      <td>['asset']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['asset']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4ldAQ53se0hp9GU5FgnIQ_0000</td>\n",
       "      <td>an extremely driven professional within the bi...</td>\n",
       "      <td>['attend', 'batch', 'daily']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-BSYFSH4GWqbTH-JhxVExA_0000</td>\n",
       "      <td>i am currently a junior at cal poly san luis o...</td>\n",
       "      <td>['honestly', 'astro', 'gain']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-EJPzKCOhrcLUKsIiC35Ow_0000</td>\n",
       "      <td>team manager with 8 years of experience enabli...</td>\n",
       "      <td>['later', 'stay', 'lob']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-EQeYEq-03cWVCkfnsUgow_0000</td>\n",
       "      <td>eric is an experienced risk, insurance, and pr...</td>\n",
       "      <td>['communicator', 'big picture']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  \\\n",
       "0  -18msGiQiE2XLdy6XWGAEQ_0000   \n",
       "1  -4ldAQ53se0hp9GU5FgnIQ_0000   \n",
       "2  -BSYFSH4GWqbTH-JhxVExA_0000   \n",
       "3  -EJPzKCOhrcLUKsIiC35Ow_0000   \n",
       "4  -EQeYEq-03cWVCkfnsUgow_0000   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  10+ years of leveraged finance and investment ...   \n",
       "1  an extremely driven professional within the bi...   \n",
       "2  i am currently a junior at cal poly san luis o...   \n",
       "3  team manager with 8 years of experience enabli...   \n",
       "4  eric is an experienced risk, insurance, and pr...   \n",
       "\n",
       "                exact_matched_patt  Unnamed: 3 Technology  \n",
       "0                        ['asset']         NaN  ['asset']  \n",
       "1     ['attend', 'batch', 'daily']         NaN        NaN  \n",
       "2    ['honestly', 'astro', 'gain']         NaN        NaN  \n",
       "3         ['later', 'stay', 'lob']         NaN        NaN  \n",
       "4  ['communicator', 'big picture']         NaN        NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "j6lgpXWkHJNe"
   },
   "outputs": [],
   "source": [
    "# tech.rename(columns = {\"List of Technologies\":\"title\"}, inplace = True)\n",
    "# removve comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "OBq0zJDSHJNf"
   },
   "outputs": [],
   "source": [
    "# # print(\"data types summaries\",type(summary[\"summaries\"][0]))\n",
    "\n",
    "# # converting string of list data that is being dumped from sourcehere to list properly to iterate easily later on\n",
    "# for i in range(0, len(summary)):\n",
    "#     demo = summary[\"summaries\"][i]\n",
    "#     res = demo.strip('][')\n",
    "#     resl = []\n",
    "#     resl.append(res)\n",
    "#     summary[\"summaries\"][i] = resl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "8RKweodPHJNf"
   },
   "outputs": [],
   "source": [
    "# taking 500 entries from sheet\n",
    "# summary_copy = summary_copy.iloc[0:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "RR_KosylHJNf"
   },
   "outputs": [],
   "source": [
    "tech_list = []\n",
    "summary_list = []\n",
    "id_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "i4XtYQfhHJNg"
   },
   "outputs": [],
   "source": [
    "def KMP_String(pattern, text):\n",
    "    a = len(text)\n",
    "    b = len(pattern)\n",
    "\n",
    "    prefix_arr = get_prefix_arr(pattern, b)\n",
    "\n",
    "  \n",
    "    initial_point = []\n",
    "\n",
    "    m = 0\n",
    "    n = 0\n",
    "\n",
    "  \n",
    "    while m != a:\n",
    "       \n",
    "        if text[m] == pattern[n]:\n",
    "            m += 1\n",
    "            n += 1\n",
    "      \n",
    "        else:\n",
    "            n = prefix_arr[n-1]\n",
    "\n",
    "       \n",
    "        if n == b:\n",
    "            initial_point.append(m-n)\n",
    "            n = prefix_arr[n-1]\n",
    "        elif n == 0:\n",
    "            m += 1\n",
    "            \n",
    "    return initial_point\n",
    "\n",
    "\n",
    "\n",
    "def get_prefix_arr(pattern, b):\n",
    "    prefix_arr = [0] * b\n",
    "    n = 0\n",
    "    m = 1\n",
    "\n",
    "    while m != b:\n",
    "        if pattern[m] == pattern[n]:\n",
    "            n += 1\n",
    "            prefix_arr[m] = n\n",
    "            m += 1\n",
    "        elif n != 0:\n",
    "                n = prefix_arr[n-1]\n",
    "        else:\n",
    "            prefix_arr[m] = 0\n",
    "            m += 1\n",
    "\n",
    "    return prefix_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "HvY1NE-KHJNg",
    "outputId": "e25c064d-866d-432b-8ac2-0bb7db498c05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-df3d56489f0e>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  summary_copy[\"summaries\"][i] = resl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "# print(\"data types summaries\",type(summary[\"summaries\"][0]))\n",
    "\n",
    "# converting string of list data that is being dumped from sourcehere to list properly to iterate easily later on\n",
    "# for i in range(0, len(summary_copy)):\n",
    "#     demo = summary_copy[\"summaries\"][i]\n",
    "#     res = demo.strip('][')\n",
    "#     resl = []\n",
    "#     resl.append(res)\n",
    "#     summary_copy[\"summaries\"][i] = resl\n",
    "\n",
    "for i in range(0, len(summary_copy)):\n",
    "    print(i)\n",
    "    if summary_copy[\"summaries\"][i] is not np.nan:\n",
    "        demo = summary_copy[\"summaries\"][i]\n",
    "        res = demo.strip('][')\n",
    "        resl = []\n",
    "        resl.append(res)\n",
    "        summary_copy[\"summaries\"][i] = resl\n",
    "        \n",
    "    else:\n",
    "        summary_copy[\"summaries\"][i] = '[]'\n",
    "        demo = summary_copy[\"summaries\"][i]\n",
    "        res = demo.strip('][')\n",
    "        resl = []\n",
    "        resl.append(res)\n",
    "        summary_copy[\"summaries\"][i] = resl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "3xoOLMJfHJNh",
    "outputId": "2df9712e-f7ee-4454-8ee8-3d3e38c20acf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WorkflowMax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>InGenius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DealHub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ebsta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Repsly Mobile CRM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title\n",
       "0        WorkflowMax\n",
       "1           InGenius\n",
       "2            DealHub\n",
       "3              Ebsta\n",
       "4  Repsly Mobile CRM"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying joblib for paraller processing\n",
    "#Import package\n",
    "from joblib import Parallel, delayed\n",
    "from joblib import Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = 'multiprocessing'\n",
    "# random_vector = Parallel(n_jobs=2, backend=backend)(delayed(\n",
    "#     stochastic_function)(10) for _ in range(n_vectors))\n",
    "# print_vector(random_vector, backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "uFAWAaBmHJNh",
    "outputId": "0d970aea-9d58-4d38-f319-177f730f5d0d"
   },
   "outputs": [],
   "source": [
    "def final_run_string(summary_copy, tech):\n",
    "    \n",
    "    tech_list = []\n",
    "    summary_list = []\n",
    "    id_list = []\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    for i in range(0, len(summary_copy)):\n",
    "        print(i)\n",
    "        string = summary_copy.loc[i, \"summaries\"][0]\n",
    "        string = string.lower()\n",
    "\n",
    "        for j in range(0, len(tech)):\n",
    "            pat = tech.loc[j,\"title\"]\n",
    "            pat = pat.lower()\n",
    "\n",
    "\n",
    "            initial_index = KMP_String(pat, string)\n",
    "            if len(initial_index)!=0:\n",
    "\n",
    "                tech_list.append(pat)    \n",
    "                summary_list.append(string)\n",
    "                id_list.append(summary_copy.loc[i,\"id\"])\n",
    "\n",
    "    end = time.time() - start\n",
    "    print(\"\\n TImE TAken\", end)\n",
    "    return tech_list, summary_list, id_list\n",
    "\n",
    "\n",
    "# #             for k in range(0, len(initial_index)-2):\n",
    "\n",
    "# #                 if (initial_index[k]==0) and (string[initial_index[k]+len(pat)-1+1].isalpha()==True):\n",
    "# #                     print(\"C1\")\n",
    "# #                     initial_index.pop(k)\n",
    "# #                     match_dict.update({i:[initial_index, len(pat)]})\n",
    "# #                     print(\"Dictionary C1\", match_dict)\n",
    "                    \n",
    "                    \n",
    "\n",
    "# #                 elif (string[initial_index[k]-1].isalpha()==True) or (string[initial_index[k]+len(pat)-1+1].isalpha()==True):\n",
    "# #                     print(\"C2\")\n",
    "# #                     initial_index.pop(k)\n",
    "# #                     match_dict.update({i:[initial_index, len(pat)]})\n",
    "# #                     print(\"Dictionary C2\", match_dict)\n",
    "\n",
    "# #                 else:\n",
    "# #                     pass\n",
    "\n",
    "# #             tech_list.append(pat)    \n",
    "# #             summary_list.append(string)\n",
    "# #             id_list.append(summary.loc[i,\"id\"])\n",
    "                \n",
    "# #         else:\n",
    "# #             pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n"
     ]
    }
   ],
   "source": [
    "tech_list, summary_list, id_list = Parallel(n_jobs=-1, backend=backend)(delayed(\n",
    "    final_run_string(summary_copy, tech)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "YbIjEkuTHJNh"
   },
   "outputs": [],
   "source": [
    "tech_list_copy = tech_list\n",
    "id_list_copy = id_list\n",
    "summary_list_copy = summary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_w6LNW7HJNi"
   },
   "outputs": [],
   "source": [
    "def getDuplicatesWithInfo(listOfElems):\n",
    "    ''' Get duplicate element in a list along with thier indices in list\n",
    "     and frequency count'''\n",
    "    dictOfElems = dict()\n",
    "    index = 0\n",
    "    # Iterate over each element in list and keep track of index\n",
    "    for elem in listOfElems:\n",
    "        # If element exists in dict then keep its index in list & increment its frequency\n",
    "        if elem in dictOfElems:\n",
    "            dictOfElems[elem][0] += 1\n",
    "            dictOfElems[elem][1].append(index)\n",
    "        else:\n",
    "            # Add a new entry in dictionary \n",
    "            dictOfElems[elem] = [1, [index]]\n",
    "        index += 1    \n",
    " \n",
    "    dictOfElems = { key:value for key, value in dictOfElems.items() if value[0] > 1}\n",
    "    return dictOfElems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQFGu8BLHJNi"
   },
   "outputs": [],
   "source": [
    "# List of strings\n",
    "listOfElems = id_list\n",
    "dictOfElems = getDuplicatesWithInfo(listOfElems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4-rXFkBHJNj"
   },
   "outputs": [],
   "source": [
    "# tech_list_demo = tech_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yk2K5Kg9HJNj",
    "outputId": "fd14e745-6111-4ace-e08e-8dccaa05151b"
   },
   "outputs": [],
   "source": [
    "type(listOfElems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUINCyB5HJNk"
   },
   "outputs": [],
   "source": [
    "# for key, value in dictOfElems.items():\n",
    "#         print('Element = ', key , ' :: Repeated Count = ', value[0] , ' :: Index Positions =  ', value[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYuSGpEHHJNk"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(id_list, summary_list, tech_list)), \n",
    "               columns =['id', 'summaries', \"Technology\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6_r6PyAHJNk",
    "outputId": "61ac5833-bbcd-4d31-bb01-d5e046a0eb95"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XQLjXOfVHJNl"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"string_match_copy_Save17k.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s8o5-G8LHJNl"
   },
   "outputs": [],
   "source": [
    "for key, value in dictOfElems.items():\n",
    "#     print(\"******************\")\n",
    "#     print(\"\\n ID is..\", key )\n",
    "    a = df[\"Technology\"][value[1][0]] #this needs to be changed\n",
    "    b = []\n",
    "    b.insert(0,a)\n",
    "#     print(\"List at first index\", b)\n",
    "    for i in range(0, len(value[1])-1):\n",
    "        b.append(df[\"Technology\"][value[1][i+1]])\n",
    "        df[\"Technology\"][value[1][0]] = b\n",
    "        \n",
    "    for i in range(0, len(value[1])-1):\n",
    "        df = df.drop(index = [value[1][i+1]])\n",
    "#         print('Element = ', key , ' :: Repeated Count = ', value[0] , ' :: Index Positions =  ', value[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6ooy5XgHJNl"
   },
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2e5wb9xYHJNl"
   },
   "outputs": [],
   "source": [
    "# Applying Regex to filter out Invalid Words\n",
    "\n",
    "def get_exact_match(txt, tech):\n",
    "    try:\n",
    "        patt = '|'.join(['\\\\b'+elem+'\\\\b' for elem in tech])\n",
    "        matched_patt = re.findall(patt,txt)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        matched_patt = []\n",
    "    return matched_patt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHjZJCS-HJNm"
   },
   "outputs": [],
   "source": [
    "# new_tech = []\n",
    "# new_summary = []\n",
    "# new_id = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JseAkiPaHJNm"
   },
   "outputs": [],
   "source": [
    "# for ind in df.index:\n",
    "    \n",
    "#     for j in range(0, len(df)):\n",
    "#         txt = df[\"summaries\"][i]\n",
    "#         tech_txt = df[\"Technology\"][j]\n",
    "#         match = get_exact_match(txt, tech_txt)\n",
    "        \n",
    "#         new_tech.append(match)\n",
    "#         new_summary.append(txt)\n",
    "#         new_id.append(df[\"id\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "75SnUiPEHJNm"
   },
   "outputs": [],
   "source": [
    "df['exact_matched_patt'] = df.apply(lambda x: get_exact_match(x[\"summaries\"], x[\"Technology\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZrEmK-bmHJNm"
   },
   "outputs": [],
   "source": [
    "# Applying Regex to filter out Invalid Words\n",
    "\n",
    "def get_exact_match_2(txt, tech):\n",
    "    try:\n",
    "        patt = '|'.join(['\\\\s'+elem+'\\\\s' for elem in tech])\n",
    "        matched_patt = re.findall(patt,txt[0])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        matched_patt = []\n",
    "    return matched_patt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pY0RNTMjHJNm"
   },
   "outputs": [],
   "source": [
    "df['matched_NER_final'] = df.apply(lambda x: get_exact_match_2(x[\"summaries\"], x[\"exact_matched_patt\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjMa698KHJNn",
    "outputId": "b5f44cec-d80e-4dfa-d6c8-db0edcd75cc2"
   },
   "outputs": [],
   "source": [
    "df.head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGyROnqsHJNn"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1L376SdUHJNn"
   },
   "outputs": [],
   "source": [
    "for ind in df.index:\n",
    "    res = list(OrderedDict.fromkeys(df[\"exact_matched_patt\"][ind]))\n",
    "    df[\"exact_matched_patt\"][ind] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LRH_-1GKpxgX"
   },
   "outputs": [],
   "source": [
    "# if need to remove words like manager, hr manager, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PtsEfnu3HJNo"
   },
   "outputs": [],
   "source": [
    "r = pd.read_csv(\"Remove.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NpWUz_lbHJNo"
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(r)):\n",
    "    r[\"Remove\"][i] = r[\"Remove\"][i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XYbof893HJNo"
   },
   "outputs": [],
   "source": [
    "remove_list = r[\"Remove\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NoKNitzsHJNo"
   },
   "outputs": [],
   "source": [
    "remove_list.append(\"ve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_Vd6yHMHJNo",
    "outputId": "39c4ec59-3d40-44e9-c6e1-b2438aa569d4"
   },
   "outputs": [],
   "source": [
    "remove_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k9D6-0V-HJNp",
    "outputId": "5f0989fc-27e9-43f2-8ba2-5f3b549e40c3"
   },
   "outputs": [],
   "source": [
    "df[\"exact_matched_patt\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pqmPxSUHJNq"
   },
   "outputs": [],
   "source": [
    "for i in range(0, 100):\n",
    "    for word in list(df[\"Technology\"][i]):\n",
    "        if word in remove_list:\n",
    "            df[\"Technology\"][i].remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xprrY9E5HJNq"
   },
   "outputs": [],
   "source": [
    "for i in range(0, 100):\n",
    "    for word in list(df[\"exact_matched_patt\"][i]):\n",
    "        if word in remove_list:\n",
    "            df[\"exact_matched_patt\"][i].remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6g8J0im8HJNq",
    "outputId": "2a09ae93-bbb6-4ee8-e383-afd61fc07f96"
   },
   "outputs": [],
   "source": [
    "df[\"exact_matched_patt\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wndi6ApjHJNq"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"Train_Data/Accuracy_Data/Dataset_to_run_on_all/Output/KMP_string_Match_newer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TxU734cjHJNr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wHPfgjKHJNn"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"KMP_string_Match_newer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPJlBkj9HJNr"
   },
   "outputs": [],
   "source": [
    "# df.to_csv(\"Dataset/Output/op_string/KMP_Latest-Regex_17_k_profiles_latest.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTYEH1ggHJNr"
   },
   "outputs": [],
   "source": [
    "# sorting\n",
    "# df_cm = pd.read_csv(\"Dataset/Output/op_string/KMP_Latest-Regex_17_k_profiles_latest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtRNI1EnHJNr"
   },
   "outputs": [],
   "source": [
    "# Python code to sort a list without \n",
    "# creating another list Use of sort() \n",
    "def Sorting(lst): \n",
    "\tlst.sort(key=len, reverse = True) \n",
    "\treturn lst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZj3RbmtHJNs"
   },
   "outputs": [],
   "source": [
    "# for i in range(0, len(df)-1):\n",
    "#     print(i)\n",
    "    \n",
    "#     if df[\"exact_matched_patt\"][i] == '[]':\n",
    "        \n",
    "#         res = ast.literal_eval(df[\"exact_matched_patt\"][i])\n",
    "#         df[\"exact_matched_patt\"][i] = res\n",
    "        \n",
    "#     else:\n",
    "#         x = []\n",
    "#         x.insert(0, df[\"exact_matched_patt\"][i])\n",
    "#         df[\"exact_matched_patt\"][i] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWOWZAF_HJNs"
   },
   "outputs": [],
   "source": [
    "for ind in df.index:\n",
    "    df[\"exact_matched_patt\"][ind] = Sorting(df[\"exact_matched_patt\"][ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kgHt5LzvHJNs"
   },
   "outputs": [],
   "source": [
    "count = []\n",
    "id_elem = []\n",
    "elem = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x5i-1lSHHJNs"
   },
   "outputs": [],
   "source": [
    "for ind in df.index:\n",
    "    d = df[\"exact_matched_patt\"][ind]\n",
    "    for j in range(0, len(d)-1):\n",
    "        search_elem = df[\"exact_matched_patt\"][ind][j]\n",
    "        i = d.count(search_elem)\n",
    "        count.append(i)\n",
    "        elem.append(search_elem)\n",
    "        id_elem.append(df[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "itLuvr1gHJNs"
   },
   "outputs": [],
   "source": [
    "df_final_v2 = pd.DataFrame(list(zip(elem, count)), \n",
    "               columns =['Technology', \"Count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JpArAfOPHJNs"
   },
   "outputs": [],
   "source": [
    "df_final_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RIjDTMUKHJNt"
   },
   "outputs": [],
   "source": [
    "# Count vs Technology Sheet\n",
    "save = df_final_v2.groupby([\"Technology\"]).sum()\n",
    "save.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UdjckSyPHJNt"
   },
   "outputs": [],
   "source": [
    "save.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4_Lrh9HYHJNt"
   },
   "outputs": [],
   "source": [
    "save.to_csv(\"Tech_Count_17k_groupby.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjVErXw_HJNt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(Pydictionary)KMP_string_match-1lakh_run.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
