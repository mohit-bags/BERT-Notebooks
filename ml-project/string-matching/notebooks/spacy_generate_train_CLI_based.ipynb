{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "local-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import json\n",
    "import re\n",
    "# import swifter\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from PyDictionary import PyDictionary # for dictionary splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "behind-malaysia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading dataframes\n",
    "\n",
    "def read_file(summary_file_path, tech_file_path, output_file_path):\n",
    "\n",
    "    df_summary = pd.read_csv(summary_file_path)\n",
    "    df_tech = pd.read_csv(tech_file_path)\n",
    "    df_output = pd.read_csv(output_file_path)\n",
    "    \n",
    "    return df_summary, df_tech, df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "burning-reservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shubhamsunwalka/Desktop/Slintel_2/training_spacy\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "stock-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_file_path = \"../tech_sort1k.csv\"\n",
    "tech_file_path = \"../Technology Summary Matching Project - technologies-post-removing.csv\"\n",
    "# tech_file_path = \"../Tech_pydictionary.csv\"\n",
    "output_file_path = \"../Dataset/output - output.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fluid-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary, tech, output = read_file(summary_file_path, tech_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "consolidated-death",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Summary Data \n",
      "                             id exact_matched_patt_contextual  \\\n",
      "0  zsDSYc5UzpyXekOABZBfnQ_0000                           NaN   \n",
      "1  zs1YNrrCeorFkGLEXSSp-A_0000                           NaN   \n",
      "2  zowirq8ZhxhchApaRMhNSA_0000                           NaN   \n",
      "3  zoQVkPCfXB9n3AaPGHHwzg_0000                           NaN   \n",
      "4  zmIr2glBZ3Ef8CSS0jw1og_0000                           NaN   \n",
      "\n",
      "                                           summaries Note  \n",
      "0  senior director of clinical services housing a...  NaN  \n",
      "1  i believe that passions are meant to be shared...  NaN  \n",
      "2  bill bryant is founder and chairman of bryant ...  NaN  \n",
      "3  undertaking a trilingual masters degree in eur...  NaN  \n",
      "4  career objective a role within marketing and n...  NaN  \n",
      "\n",
      " Technology Sheet Data \n",
      "   List of Technologies\n",
      "0             .NETCore\n",
      "1      [24]7 Live Chat\n",
      "2        @hand SAPHRON\n",
      "3                @RISK\n",
      "4          @Value 2016\n",
      "\n",
      " output Data \n",
      " Empty DataFrame\n",
      "Columns: [id, summaries, Technology_Names]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Summary Data \\n\", summary.head())\n",
    "print(\"\\n Technology Sheet Data \\n\", tech.head())\n",
    "print(\"\\n output Data \\n\", output.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "innovative-bachelor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing garbage words from tech sheet\n",
    "r = pd.read_csv(\"../Remove.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "israeli-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(r)):\n",
    "    r[\"Remove\"][i] = r[\"Remove\"][i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "north-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_list = r[\"Remove\"].tolist()\n",
    "remove_list.append(\"ve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "laden-merchant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29318"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-recipe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-monte",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "impressive-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting by id\n",
    "summary = summary.sort_values(by=['id'], ascending=False)\n",
    "summary.reset_index(inplace = True, drop = True)\n",
    "summary.drop(columns = [\"Note\"], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cultural-guyana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29318 1001\n"
     ]
    }
   ],
   "source": [
    "print(len(tech), len(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "blocked-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking 500 entries from sheet\n",
    "# summary = summary.iloc[0:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "opposed-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech.columns = [\"title\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "regional-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tech.columns = [\"index\", \"title\"]\n",
    "# tech.drop(columns = [\"index\"], axis =1 , inplace = True)\n",
    "tech.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "broken-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_list = []\n",
    "summary_list = []\n",
    "id_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "corporate-butter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'senior director of clinical services housing assistance and hiv aids services with focus in clinical supervision trauma informed care trainer and consultant program development and leadership building behavior support specialist behavior therapist lcsw/ provide supervision to therapist obtaining credentials former management of autism circles of treatment support grant consultation in the area of intellectual disabilities and mental health needs expertise in the area and advocate of social and sexual awareness and needs for individuals participated and trained as a volunteer for the kentucky crisis response team volunteered for american red cross to debrief victims of katrina, flood and tropical storm disasters presentations in a variety of areas to assist clients and staff in behavioral and mental health needs former member of steering committee for trauma informed care and development of training, senior director of clinical services\\nhousing programs with focus in clinical services\\ntrauma informed care trainer and consultant \\nprogram development and leadership building\\nbehavior support specialist\\nbehavior therapist\\nlcsw/ provide supervision to therapist obtaining credentials \\nformer management of autism circles of treatment support grant\\nconsultation in the area of intellectual disabilities and mental health needs\\nexpertise in the area and advocate of social and sexual awareness and needs for individuals\\nparticipated and trained as a volunteer for the kentucky crisis response team\\nvolunteered for american red cross to debrief victims of katrina, flood and tropical storm disasters\\npresentations in a variety of areas to assist clients and staff in behavioral and mental health needs\\nformer member of steering committee for trauma informed care and development of training, senior director of clinical services at volunteers of america of kentucky, senior director at volunteers of america mid-states'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[\"summaries\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "durable-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting string of list data that is being dumped from source here to list properly to iterate easily later on\n",
    "\n",
    "def dump_format_change(df, col_name):\n",
    "    \n",
    "    for i in range(0, len(df)):\n",
    "        print(i)\n",
    "        if df[col_name][i] is not np.nan:\n",
    "            demo = df[col_name][i]\n",
    "            res = demo.strip('][')\n",
    "            resl = []\n",
    "            resl.append(res)\n",
    "            df[col_name][i] = resl\n",
    "        \n",
    "        else:\n",
    "            df[col_name][i] = '[]'\n",
    "            demo = df[col_name][i]\n",
    "            res = demo.strip('][')\n",
    "            resl = []\n",
    "            resl.append(res)\n",
    "            df[col_name][i] = resl\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "developmental-realtor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "summary = dump_format_change(summary, \"summaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "caring-neutral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['microsoft office', 'adobe']\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[\"exact_matched_patt_contextual\"][33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "solved-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary['exact_matched_patt_contextual'] = [ '[]' if x is np.NaN else x for x in summary['exact_matched_patt_contextual'] ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "critical-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting dumped data into proper format i.e string into list\n",
    "\n",
    "# Pass the matched technology column that we got\n",
    "def convert_data_format(df,column_name):\n",
    "    \n",
    "    for i in range(0, len(df)):\n",
    "        \n",
    "        if df[column_name][i][0] == '[':\n",
    "            res = ast.literal_eval(df[column_name][i])\n",
    "            df[column_name][i] = res\n",
    "            \n",
    "        else:\n",
    "            x = []\n",
    "            x.insert(0, df[column_name][i])\n",
    "            df[column_name][i] = x\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "growing-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = convert_data_format(summary, \"exact_matched_patt_contextual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "western-border",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['senior director of clinical services housing assistance and hiv aids services with focus in clinical supervision trauma informed care trainer and consultant program development and leadership building behavior support specialist behavior therapist lcsw/ provide supervision to therapist obtaining credentials former management of autism circles of treatment support grant consultation in the area of intellectual disabilities and mental health needs expertise in the area and advocate of social and sexual awareness and needs for individuals participated and trained as a volunteer for the kentucky crisis response team volunteered for american red cross to debrief victims of katrina, flood and tropical storm disasters presentations in a variety of areas to assist clients and staff in behavioral and mental health needs former member of steering committee for trauma informed care and development of training, senior director of clinical services\\nhousing programs with focus in clinical services\\ntrauma informed care trainer and consultant \\nprogram development and leadership building\\nbehavior support specialist\\nbehavior therapist\\nlcsw/ provide supervision to therapist obtaining credentials \\nformer management of autism circles of treatment support grant\\nconsultation in the area of intellectual disabilities and mental health needs\\nexpertise in the area and advocate of social and sexual awareness and needs for individuals\\nparticipated and trained as a volunteer for the kentucky crisis response team\\nvolunteered for american red cross to debrief victims of katrina, flood and tropical storm disasters\\npresentations in a variety of areas to assist clients and staff in behavioral and mental health needs\\nformer member of steering committee for trauma informed care and development of training, senior director of clinical services at volunteers of america of kentucky, senior director at volunteers of america mid-states']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[\"summaries\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "another-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying joblib for paraller processing\n",
    "#Import package\n",
    "from joblib import Parallel, delayed\n",
    "from joblib import Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "intense-carolina",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = 'multiprocessing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "grave-equipment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.NETCore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[24]7 Live Chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@hand SAPHRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@RISK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Value 2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title\n",
       "0         .NETCore\n",
       "1  [24]7 Live Chat\n",
       "2    @hand SAPHRON\n",
       "3            @RISK\n",
       "4      @Value 2016"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "synthetic-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tech=tech.iloc[:,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "looking-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tech.columns = [\"title\"]\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "military-nurse",
   "metadata": {},
   "outputs": [],
   "source": [
    "tech['title'] = tech['title'].astype(str)\n",
    "all_tech_words = list(tech['title'].str.lower())\n",
    "summary[\"summaries_matching\"]=summary[\"summaries\"].astype(str)\n",
    "all_strings = list(summary[\"summaries_matching\"].str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "threaded-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=1\n",
    "# tech_keys=[]\n",
    "# spacy_keys = []\n",
    "# for item in all_strings:\n",
    "#     print(\"***\",\"TEST No,\",i,\"***\")\n",
    "#     i=i+1\n",
    "#     tech_row=[]\n",
    "#     spacy_row = []\n",
    "#     for k in all_tech_words:\n",
    "#         if k in item and len(k)>2:\n",
    "#             tech_row.append(k)\n",
    "#             k=k.strip()\n",
    "#             k.replace(\" \",\"_\")\n",
    "#             spacy_row.append([k,item.index(k),item.index(k) + len(k),\"ORG\"])\n",
    "        \n",
    "#     tech_keys.append(tech_row)\n",
    "#     spacy_keys.append(spacy_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "eastern-violin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TEST No, 1 ***\n",
      "*** TEST No, 2 ***\n",
      "*** TEST No, 3 ***\n",
      "*** TEST No, 4 ***\n",
      "*** TEST No, 5 ***\n",
      "*** TEST No, 6 ***\n",
      "*** TEST No, 7 ***\n",
      "*** TEST No, 8 ***\n",
      "*** TEST No, 9 ***\n",
      "*** TEST No, 10 ***\n",
      "*** TEST No, 11 ***\n",
      "*** TEST No, 12 ***\n",
      "*** TEST No, 13 ***\n",
      "*** TEST No, 14 ***\n",
      "*** TEST No, 15 ***\n",
      "*** TEST No, 16 ***\n",
      "*** TEST No, 17 ***\n",
      "*** TEST No, 18 ***\n",
      "*** TEST No, 19 ***\n",
      "*** TEST No, 20 ***\n",
      "*** TEST No, 21 ***\n",
      "*** TEST No, 22 ***\n",
      "*** TEST No, 23 ***\n",
      "*** TEST No, 24 ***\n",
      "*** TEST No, 25 ***\n",
      "*** TEST No, 26 ***\n",
      "*** TEST No, 27 ***\n",
      "*** TEST No, 28 ***\n",
      "*** TEST No, 29 ***\n",
      "*** TEST No, 30 ***\n",
      "*** TEST No, 31 ***\n",
      "*** TEST No, 32 ***\n",
      "*** TEST No, 33 ***\n",
      "*** TEST No, 34 ***\n",
      "*** TEST No, 35 ***\n",
      "*** TEST No, 36 ***\n",
      "*** TEST No, 37 ***\n",
      "*** TEST No, 38 ***\n",
      "*** TEST No, 39 ***\n",
      "*** TEST No, 40 ***\n",
      "*** TEST No, 41 ***\n",
      "*** TEST No, 42 ***\n",
      "*** TEST No, 43 ***\n",
      "*** TEST No, 44 ***\n",
      "*** TEST No, 45 ***\n",
      "*** TEST No, 46 ***\n",
      "*** TEST No, 47 ***\n",
      "*** TEST No, 48 ***\n",
      "*** TEST No, 49 ***\n",
      "*** TEST No, 50 ***\n",
      "*** TEST No, 51 ***\n",
      "*** TEST No, 52 ***\n",
      "*** TEST No, 53 ***\n",
      "*** TEST No, 54 ***\n",
      "*** TEST No, 55 ***\n",
      "*** TEST No, 56 ***\n",
      "*** TEST No, 57 ***\n",
      "*** TEST No, 58 ***\n",
      "*** TEST No, 59 ***\n",
      "*** TEST No, 60 ***\n",
      "*** TEST No, 61 ***\n",
      "*** TEST No, 62 ***\n",
      "*** TEST No, 63 ***\n",
      "*** TEST No, 64 ***\n",
      "*** TEST No, 65 ***\n",
      "*** TEST No, 66 ***\n",
      "*** TEST No, 67 ***\n",
      "*** TEST No, 68 ***\n",
      "*** TEST No, 69 ***\n",
      "*** TEST No, 70 ***\n",
      "*** TEST No, 71 ***\n",
      "*** TEST No, 72 ***\n",
      "*** TEST No, 73 ***\n",
      "*** TEST No, 74 ***\n",
      "*** TEST No, 75 ***\n",
      "*** TEST No, 76 ***\n",
      "*** TEST No, 77 ***\n",
      "*** TEST No, 78 ***\n",
      "*** TEST No, 79 ***\n",
      "*** TEST No, 80 ***\n",
      "*** TEST No, 81 ***\n",
      "*** TEST No, 82 ***\n",
      "*** TEST No, 83 ***\n",
      "*** TEST No, 84 ***\n",
      "*** TEST No, 85 ***\n",
      "*** TEST No, 86 ***\n",
      "*** TEST No, 87 ***\n",
      "*** TEST No, 88 ***\n",
      "*** TEST No, 89 ***\n",
      "*** TEST No, 90 ***\n",
      "*** TEST No, 91 ***\n",
      "*** TEST No, 92 ***\n",
      "*** TEST No, 93 ***\n",
      "*** TEST No, 94 ***\n",
      "*** TEST No, 95 ***\n",
      "*** TEST No, 96 ***\n",
      "*** TEST No, 97 ***\n",
      "*** TEST No, 98 ***\n",
      "*** TEST No, 99 ***\n",
      "*** TEST No, 100 ***\n",
      "*** TEST No, 101 ***\n",
      "*** TEST No, 102 ***\n",
      "*** TEST No, 103 ***\n",
      "*** TEST No, 104 ***\n",
      "*** TEST No, 105 ***\n",
      "*** TEST No, 106 ***\n",
      "*** TEST No, 107 ***\n",
      "*** TEST No, 108 ***\n",
      "*** TEST No, 109 ***\n",
      "*** TEST No, 110 ***\n",
      "*** TEST No, 111 ***\n",
      "*** TEST No, 112 ***\n",
      "*** TEST No, 113 ***\n",
      "*** TEST No, 114 ***\n",
      "*** TEST No, 115 ***\n",
      "*** TEST No, 116 ***\n",
      "*** TEST No, 117 ***\n",
      "*** TEST No, 118 ***\n",
      "*** TEST No, 119 ***\n",
      "*** TEST No, 120 ***\n",
      "*** TEST No, 121 ***\n",
      "*** TEST No, 122 ***\n",
      "*** TEST No, 123 ***\n",
      "*** TEST No, 124 ***\n",
      "*** TEST No, 125 ***\n",
      "*** TEST No, 126 ***\n",
      "*** TEST No, 127 ***\n",
      "*** TEST No, 128 ***\n",
      "*** TEST No, 129 ***\n",
      "*** TEST No, 130 ***\n",
      "*** TEST No, 131 ***\n",
      "*** TEST No, 132 ***\n",
      "*** TEST No, 133 ***\n",
      "*** TEST No, 134 ***\n",
      "*** TEST No, 135 ***\n",
      "*** TEST No, 136 ***\n",
      "*** TEST No, 137 ***\n",
      "*** TEST No, 138 ***\n",
      "*** TEST No, 139 ***\n",
      "*** TEST No, 140 ***\n",
      "*** TEST No, 141 ***\n",
      "*** TEST No, 142 ***\n",
      "*** TEST No, 143 ***\n",
      "*** TEST No, 144 ***\n",
      "*** TEST No, 145 ***\n",
      "*** TEST No, 146 ***\n",
      "*** TEST No, 147 ***\n",
      "*** TEST No, 148 ***\n",
      "*** TEST No, 149 ***\n",
      "*** TEST No, 150 ***\n",
      "*** TEST No, 151 ***\n",
      "*** TEST No, 152 ***\n",
      "*** TEST No, 153 ***\n",
      "*** TEST No, 154 ***\n",
      "*** TEST No, 155 ***\n",
      "*** TEST No, 156 ***\n",
      "*** TEST No, 157 ***\n",
      "*** TEST No, 158 ***\n",
      "*** TEST No, 159 ***\n",
      "*** TEST No, 160 ***\n",
      "*** TEST No, 161 ***\n",
      "*** TEST No, 162 ***\n",
      "*** TEST No, 163 ***\n",
      "*** TEST No, 164 ***\n",
      "*** TEST No, 165 ***\n",
      "*** TEST No, 166 ***\n",
      "*** TEST No, 167 ***\n",
      "*** TEST No, 168 ***\n",
      "*** TEST No, 169 ***\n",
      "*** TEST No, 170 ***\n",
      "*** TEST No, 171 ***\n",
      "*** TEST No, 172 ***\n",
      "*** TEST No, 173 ***\n",
      "*** TEST No, 174 ***\n",
      "*** TEST No, 175 ***\n",
      "*** TEST No, 176 ***\n",
      "*** TEST No, 177 ***\n",
      "*** TEST No, 178 ***\n",
      "*** TEST No, 179 ***\n",
      "*** TEST No, 180 ***\n",
      "*** TEST No, 181 ***\n",
      "*** TEST No, 182 ***\n",
      "*** TEST No, 183 ***\n",
      "*** TEST No, 184 ***\n",
      "*** TEST No, 185 ***\n",
      "*** TEST No, 186 ***\n",
      "*** TEST No, 187 ***\n",
      "*** TEST No, 188 ***\n",
      "*** TEST No, 189 ***\n",
      "*** TEST No, 190 ***\n",
      "*** TEST No, 191 ***\n",
      "*** TEST No, 192 ***\n",
      "*** TEST No, 193 ***\n",
      "*** TEST No, 194 ***\n",
      "*** TEST No, 195 ***\n",
      "*** TEST No, 196 ***\n",
      "*** TEST No, 197 ***\n",
      "*** TEST No, 198 ***\n",
      "*** TEST No, 199 ***\n",
      "*** TEST No, 200 ***\n",
      "*** TEST No, 201 ***\n",
      "*** TEST No, 202 ***\n",
      "*** TEST No, 203 ***\n",
      "*** TEST No, 204 ***\n",
      "*** TEST No, 205 ***\n",
      "*** TEST No, 206 ***\n",
      "*** TEST No, 207 ***\n",
      "*** TEST No, 208 ***\n",
      "*** TEST No, 209 ***\n",
      "*** TEST No, 210 ***\n",
      "*** TEST No, 211 ***\n",
      "*** TEST No, 212 ***\n",
      "*** TEST No, 213 ***\n",
      "*** TEST No, 214 ***\n",
      "*** TEST No, 215 ***\n",
      "*** TEST No, 216 ***\n",
      "*** TEST No, 217 ***\n",
      "*** TEST No, 218 ***\n",
      "*** TEST No, 219 ***\n",
      "*** TEST No, 220 ***\n",
      "*** TEST No, 221 ***\n",
      "*** TEST No, 222 ***\n",
      "*** TEST No, 223 ***\n",
      "*** TEST No, 224 ***\n",
      "*** TEST No, 225 ***\n",
      "*** TEST No, 226 ***\n",
      "*** TEST No, 227 ***\n",
      "*** TEST No, 228 ***\n",
      "*** TEST No, 229 ***\n",
      "*** TEST No, 230 ***\n",
      "*** TEST No, 231 ***\n",
      "*** TEST No, 232 ***\n",
      "*** TEST No, 233 ***\n",
      "*** TEST No, 234 ***\n",
      "*** TEST No, 235 ***\n",
      "*** TEST No, 236 ***\n",
      "*** TEST No, 237 ***\n",
      "*** TEST No, 238 ***\n",
      "*** TEST No, 239 ***\n",
      "*** TEST No, 240 ***\n",
      "*** TEST No, 241 ***\n",
      "*** TEST No, 242 ***\n",
      "*** TEST No, 243 ***\n",
      "*** TEST No, 244 ***\n",
      "*** TEST No, 245 ***\n",
      "*** TEST No, 246 ***\n",
      "*** TEST No, 247 ***\n",
      "*** TEST No, 248 ***\n",
      "*** TEST No, 249 ***\n",
      "*** TEST No, 250 ***\n",
      "*** TEST No, 251 ***\n",
      "*** TEST No, 252 ***\n",
      "*** TEST No, 253 ***\n",
      "*** TEST No, 254 ***\n",
      "*** TEST No, 255 ***\n",
      "*** TEST No, 256 ***\n",
      "*** TEST No, 257 ***\n",
      "*** TEST No, 258 ***\n",
      "*** TEST No, 259 ***\n",
      "*** TEST No, 260 ***\n",
      "*** TEST No, 261 ***\n",
      "*** TEST No, 262 ***\n",
      "*** TEST No, 263 ***\n",
      "*** TEST No, 264 ***\n",
      "*** TEST No, 265 ***\n",
      "*** TEST No, 266 ***\n",
      "*** TEST No, 267 ***\n",
      "*** TEST No, 268 ***\n",
      "*** TEST No, 269 ***\n",
      "*** TEST No, 270 ***\n",
      "*** TEST No, 271 ***\n",
      "*** TEST No, 272 ***\n",
      "*** TEST No, 273 ***\n",
      "*** TEST No, 274 ***\n",
      "*** TEST No, 275 ***\n",
      "*** TEST No, 276 ***\n",
      "*** TEST No, 277 ***\n",
      "*** TEST No, 278 ***\n",
      "*** TEST No, 279 ***\n",
      "*** TEST No, 280 ***\n",
      "*** TEST No, 281 ***\n",
      "*** TEST No, 282 ***\n",
      "*** TEST No, 283 ***\n",
      "*** TEST No, 284 ***\n",
      "*** TEST No, 285 ***\n",
      "*** TEST No, 286 ***\n",
      "*** TEST No, 287 ***\n",
      "*** TEST No, 288 ***\n",
      "*** TEST No, 289 ***\n",
      "*** TEST No, 290 ***\n",
      "*** TEST No, 291 ***\n",
      "*** TEST No, 292 ***\n",
      "*** TEST No, 293 ***\n",
      "*** TEST No, 294 ***\n",
      "*** TEST No, 295 ***\n",
      "*** TEST No, 296 ***\n",
      "*** TEST No, 297 ***\n",
      "*** TEST No, 298 ***\n",
      "*** TEST No, 299 ***\n",
      "*** TEST No, 300 ***\n",
      "*** TEST No, 301 ***\n",
      "*** TEST No, 302 ***\n",
      "*** TEST No, 303 ***\n",
      "*** TEST No, 304 ***\n",
      "*** TEST No, 305 ***\n",
      "*** TEST No, 306 ***\n",
      "*** TEST No, 307 ***\n",
      "*** TEST No, 308 ***\n",
      "*** TEST No, 309 ***\n",
      "*** TEST No, 310 ***\n",
      "*** TEST No, 311 ***\n",
      "*** TEST No, 312 ***\n",
      "*** TEST No, 313 ***\n",
      "*** TEST No, 314 ***\n",
      "*** TEST No, 315 ***\n",
      "*** TEST No, 316 ***\n",
      "*** TEST No, 317 ***\n",
      "*** TEST No, 318 ***\n",
      "*** TEST No, 319 ***\n",
      "*** TEST No, 320 ***\n",
      "*** TEST No, 321 ***\n",
      "*** TEST No, 322 ***\n",
      "*** TEST No, 323 ***\n",
      "*** TEST No, 324 ***\n",
      "*** TEST No, 325 ***\n",
      "*** TEST No, 326 ***\n",
      "*** TEST No, 327 ***\n",
      "*** TEST No, 328 ***\n",
      "*** TEST No, 329 ***\n",
      "*** TEST No, 330 ***\n",
      "*** TEST No, 331 ***\n",
      "*** TEST No, 332 ***\n",
      "*** TEST No, 333 ***\n",
      "*** TEST No, 334 ***\n",
      "*** TEST No, 335 ***\n",
      "*** TEST No, 336 ***\n",
      "*** TEST No, 337 ***\n",
      "*** TEST No, 338 ***\n",
      "*** TEST No, 339 ***\n",
      "*** TEST No, 340 ***\n",
      "*** TEST No, 341 ***\n",
      "*** TEST No, 342 ***\n",
      "*** TEST No, 343 ***\n",
      "*** TEST No, 344 ***\n",
      "*** TEST No, 345 ***\n",
      "*** TEST No, 346 ***\n",
      "*** TEST No, 347 ***\n",
      "*** TEST No, 348 ***\n",
      "*** TEST No, 349 ***\n",
      "*** TEST No, 350 ***\n",
      "*** TEST No, 351 ***\n",
      "*** TEST No, 352 ***\n",
      "*** TEST No, 353 ***\n",
      "*** TEST No, 354 ***\n",
      "*** TEST No, 355 ***\n",
      "*** TEST No, 356 ***\n",
      "*** TEST No, 357 ***\n",
      "*** TEST No, 358 ***\n",
      "*** TEST No, 359 ***\n",
      "*** TEST No, 360 ***\n",
      "*** TEST No, 361 ***\n",
      "*** TEST No, 362 ***\n",
      "*** TEST No, 363 ***\n",
      "*** TEST No, 364 ***\n",
      "*** TEST No, 365 ***\n",
      "*** TEST No, 366 ***\n",
      "*** TEST No, 367 ***\n",
      "*** TEST No, 368 ***\n",
      "*** TEST No, 369 ***\n",
      "*** TEST No, 370 ***\n",
      "*** TEST No, 371 ***\n",
      "*** TEST No, 372 ***\n",
      "*** TEST No, 373 ***\n",
      "*** TEST No, 374 ***\n",
      "*** TEST No, 375 ***\n",
      "*** TEST No, 376 ***\n",
      "*** TEST No, 377 ***\n",
      "*** TEST No, 378 ***\n",
      "*** TEST No, 379 ***\n",
      "*** TEST No, 380 ***\n",
      "*** TEST No, 381 ***\n",
      "*** TEST No, 382 ***\n",
      "*** TEST No, 383 ***\n",
      "*** TEST No, 384 ***\n",
      "*** TEST No, 385 ***\n",
      "*** TEST No, 386 ***\n",
      "*** TEST No, 387 ***\n",
      "*** TEST No, 388 ***\n",
      "*** TEST No, 389 ***\n",
      "*** TEST No, 390 ***\n",
      "*** TEST No, 391 ***\n",
      "*** TEST No, 392 ***\n",
      "*** TEST No, 393 ***\n",
      "*** TEST No, 394 ***\n",
      "*** TEST No, 395 ***\n",
      "*** TEST No, 396 ***\n",
      "*** TEST No, 397 ***\n",
      "*** TEST No, 398 ***\n",
      "*** TEST No, 399 ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TEST No, 400 ***\n",
      "*** TEST No, 401 ***\n",
      "*** TEST No, 402 ***\n",
      "*** TEST No, 403 ***\n",
      "*** TEST No, 404 ***\n",
      "*** TEST No, 405 ***\n",
      "*** TEST No, 406 ***\n",
      "*** TEST No, 407 ***\n",
      "*** TEST No, 408 ***\n",
      "*** TEST No, 409 ***\n",
      "*** TEST No, 410 ***\n",
      "*** TEST No, 411 ***\n",
      "*** TEST No, 412 ***\n",
      "*** TEST No, 413 ***\n",
      "*** TEST No, 414 ***\n",
      "*** TEST No, 415 ***\n",
      "*** TEST No, 416 ***\n",
      "*** TEST No, 417 ***\n",
      "*** TEST No, 418 ***\n",
      "*** TEST No, 419 ***\n",
      "*** TEST No, 420 ***\n",
      "*** TEST No, 421 ***\n",
      "*** TEST No, 422 ***\n",
      "*** TEST No, 423 ***\n",
      "*** TEST No, 424 ***\n",
      "*** TEST No, 425 ***\n",
      "*** TEST No, 426 ***\n",
      "*** TEST No, 427 ***\n",
      "*** TEST No, 428 ***\n",
      "*** TEST No, 429 ***\n",
      "*** TEST No, 430 ***\n",
      "*** TEST No, 431 ***\n",
      "*** TEST No, 432 ***\n",
      "*** TEST No, 433 ***\n",
      "*** TEST No, 434 ***\n",
      "*** TEST No, 435 ***\n",
      "*** TEST No, 436 ***\n",
      "*** TEST No, 437 ***\n",
      "*** TEST No, 438 ***\n",
      "*** TEST No, 439 ***\n",
      "*** TEST No, 440 ***\n",
      "*** TEST No, 441 ***\n",
      "*** TEST No, 442 ***\n",
      "*** TEST No, 443 ***\n",
      "*** TEST No, 444 ***\n",
      "*** TEST No, 445 ***\n",
      "*** TEST No, 446 ***\n",
      "*** TEST No, 447 ***\n",
      "*** TEST No, 448 ***\n",
      "*** TEST No, 449 ***\n",
      "*** TEST No, 450 ***\n",
      "*** TEST No, 451 ***\n",
      "*** TEST No, 452 ***\n",
      "*** TEST No, 453 ***\n",
      "*** TEST No, 454 ***\n",
      "*** TEST No, 455 ***\n",
      "*** TEST No, 456 ***\n",
      "*** TEST No, 457 ***\n",
      "*** TEST No, 458 ***\n",
      "*** TEST No, 459 ***\n",
      "*** TEST No, 460 ***\n",
      "*** TEST No, 461 ***\n",
      "*** TEST No, 462 ***\n",
      "*** TEST No, 463 ***\n",
      "*** TEST No, 464 ***\n",
      "*** TEST No, 465 ***\n",
      "*** TEST No, 466 ***\n",
      "*** TEST No, 467 ***\n",
      "*** TEST No, 468 ***\n",
      "*** TEST No, 469 ***\n",
      "*** TEST No, 470 ***\n",
      "*** TEST No, 471 ***\n",
      "*** TEST No, 472 ***\n",
      "*** TEST No, 473 ***\n",
      "*** TEST No, 474 ***\n",
      "*** TEST No, 475 ***\n",
      "*** TEST No, 476 ***\n",
      "*** TEST No, 477 ***\n",
      "*** TEST No, 478 ***\n",
      "*** TEST No, 479 ***\n",
      "*** TEST No, 480 ***\n",
      "*** TEST No, 481 ***\n",
      "*** TEST No, 482 ***\n",
      "*** TEST No, 483 ***\n",
      "*** TEST No, 484 ***\n",
      "*** TEST No, 485 ***\n",
      "*** TEST No, 486 ***\n",
      "*** TEST No, 487 ***\n",
      "*** TEST No, 488 ***\n",
      "*** TEST No, 489 ***\n",
      "*** TEST No, 490 ***\n",
      "*** TEST No, 491 ***\n",
      "*** TEST No, 492 ***\n",
      "*** TEST No, 493 ***\n",
      "*** TEST No, 494 ***\n",
      "*** TEST No, 495 ***\n",
      "*** TEST No, 496 ***\n",
      "*** TEST No, 497 ***\n",
      "*** TEST No, 498 ***\n",
      "*** TEST No, 499 ***\n",
      "*** TEST No, 500 ***\n",
      "*** TEST No, 501 ***\n",
      "*** TEST No, 502 ***\n",
      "*** TEST No, 503 ***\n",
      "*** TEST No, 504 ***\n",
      "*** TEST No, 505 ***\n",
      "*** TEST No, 506 ***\n",
      "*** TEST No, 507 ***\n",
      "*** TEST No, 508 ***\n",
      "*** TEST No, 509 ***\n",
      "*** TEST No, 510 ***\n",
      "*** TEST No, 511 ***\n",
      "*** TEST No, 512 ***\n",
      "*** TEST No, 513 ***\n",
      "*** TEST No, 514 ***\n",
      "*** TEST No, 515 ***\n",
      "*** TEST No, 516 ***\n",
      "*** TEST No, 517 ***\n",
      "*** TEST No, 518 ***\n",
      "*** TEST No, 519 ***\n",
      "*** TEST No, 520 ***\n",
      "*** TEST No, 521 ***\n",
      "*** TEST No, 522 ***\n",
      "*** TEST No, 523 ***\n",
      "*** TEST No, 524 ***\n",
      "*** TEST No, 525 ***\n",
      "*** TEST No, 526 ***\n",
      "*** TEST No, 527 ***\n",
      "*** TEST No, 528 ***\n",
      "*** TEST No, 529 ***\n",
      "*** TEST No, 530 ***\n",
      "*** TEST No, 531 ***\n",
      "*** TEST No, 532 ***\n",
      "*** TEST No, 533 ***\n",
      "*** TEST No, 534 ***\n",
      "*** TEST No, 535 ***\n",
      "*** TEST No, 536 ***\n",
      "*** TEST No, 537 ***\n",
      "*** TEST No, 538 ***\n",
      "*** TEST No, 539 ***\n",
      "*** TEST No, 540 ***\n",
      "*** TEST No, 541 ***\n",
      "*** TEST No, 542 ***\n",
      "*** TEST No, 543 ***\n",
      "*** TEST No, 544 ***\n",
      "*** TEST No, 545 ***\n",
      "*** TEST No, 546 ***\n",
      "*** TEST No, 547 ***\n",
      "*** TEST No, 548 ***\n",
      "*** TEST No, 549 ***\n",
      "*** TEST No, 550 ***\n",
      "*** TEST No, 551 ***\n",
      "*** TEST No, 552 ***\n",
      "*** TEST No, 553 ***\n",
      "*** TEST No, 554 ***\n",
      "*** TEST No, 555 ***\n",
      "*** TEST No, 556 ***\n",
      "*** TEST No, 557 ***\n",
      "*** TEST No, 558 ***\n",
      "*** TEST No, 559 ***\n",
      "*** TEST No, 560 ***\n",
      "*** TEST No, 561 ***\n",
      "*** TEST No, 562 ***\n",
      "*** TEST No, 563 ***\n",
      "*** TEST No, 564 ***\n",
      "*** TEST No, 565 ***\n",
      "*** TEST No, 566 ***\n",
      "*** TEST No, 567 ***\n",
      "*** TEST No, 568 ***\n",
      "*** TEST No, 569 ***\n",
      "*** TEST No, 570 ***\n",
      "*** TEST No, 571 ***\n",
      "*** TEST No, 572 ***\n",
      "*** TEST No, 573 ***\n",
      "*** TEST No, 574 ***\n",
      "*** TEST No, 575 ***\n",
      "*** TEST No, 576 ***\n",
      "*** TEST No, 577 ***\n",
      "*** TEST No, 578 ***\n",
      "*** TEST No, 579 ***\n",
      "*** TEST No, 580 ***\n",
      "*** TEST No, 581 ***\n",
      "*** TEST No, 582 ***\n",
      "*** TEST No, 583 ***\n",
      "*** TEST No, 584 ***\n",
      "*** TEST No, 585 ***\n",
      "*** TEST No, 586 ***\n",
      "*** TEST No, 587 ***\n",
      "*** TEST No, 588 ***\n",
      "*** TEST No, 589 ***\n",
      "*** TEST No, 590 ***\n",
      "*** TEST No, 591 ***\n",
      "*** TEST No, 592 ***\n",
      "*** TEST No, 593 ***\n",
      "*** TEST No, 594 ***\n",
      "*** TEST No, 595 ***\n",
      "*** TEST No, 596 ***\n",
      "*** TEST No, 597 ***\n",
      "*** TEST No, 598 ***\n",
      "*** TEST No, 599 ***\n",
      "*** TEST No, 600 ***\n",
      "*** TEST No, 601 ***\n",
      "*** TEST No, 602 ***\n",
      "*** TEST No, 603 ***\n",
      "*** TEST No, 604 ***\n",
      "*** TEST No, 605 ***\n",
      "*** TEST No, 606 ***\n",
      "*** TEST No, 607 ***\n",
      "*** TEST No, 608 ***\n",
      "*** TEST No, 609 ***\n",
      "*** TEST No, 610 ***\n",
      "*** TEST No, 611 ***\n",
      "*** TEST No, 612 ***\n",
      "*** TEST No, 613 ***\n",
      "*** TEST No, 614 ***\n",
      "*** TEST No, 615 ***\n",
      "*** TEST No, 616 ***\n",
      "*** TEST No, 617 ***\n",
      "*** TEST No, 618 ***\n",
      "*** TEST No, 619 ***\n",
      "*** TEST No, 620 ***\n",
      "*** TEST No, 621 ***\n",
      "*** TEST No, 622 ***\n",
      "*** TEST No, 623 ***\n",
      "*** TEST No, 624 ***\n",
      "*** TEST No, 625 ***\n",
      "*** TEST No, 626 ***\n",
      "*** TEST No, 627 ***\n",
      "*** TEST No, 628 ***\n",
      "*** TEST No, 629 ***\n",
      "*** TEST No, 630 ***\n",
      "*** TEST No, 631 ***\n",
      "*** TEST No, 632 ***\n",
      "*** TEST No, 633 ***\n",
      "*** TEST No, 634 ***\n",
      "*** TEST No, 635 ***\n",
      "*** TEST No, 636 ***\n",
      "*** TEST No, 637 ***\n",
      "*** TEST No, 638 ***\n",
      "*** TEST No, 639 ***\n",
      "*** TEST No, 640 ***\n",
      "*** TEST No, 641 ***\n",
      "*** TEST No, 642 ***\n",
      "*** TEST No, 643 ***\n",
      "*** TEST No, 644 ***\n",
      "*** TEST No, 645 ***\n",
      "*** TEST No, 646 ***\n",
      "*** TEST No, 647 ***\n",
      "*** TEST No, 648 ***\n",
      "*** TEST No, 649 ***\n",
      "*** TEST No, 650 ***\n",
      "*** TEST No, 651 ***\n",
      "*** TEST No, 652 ***\n",
      "*** TEST No, 653 ***\n",
      "*** TEST No, 654 ***\n",
      "*** TEST No, 655 ***\n",
      "*** TEST No, 656 ***\n",
      "*** TEST No, 657 ***\n",
      "*** TEST No, 658 ***\n",
      "*** TEST No, 659 ***\n",
      "*** TEST No, 660 ***\n",
      "*** TEST No, 661 ***\n",
      "*** TEST No, 662 ***\n",
      "*** TEST No, 663 ***\n",
      "*** TEST No, 664 ***\n",
      "*** TEST No, 665 ***\n",
      "*** TEST No, 666 ***\n",
      "*** TEST No, 667 ***\n",
      "*** TEST No, 668 ***\n",
      "*** TEST No, 669 ***\n",
      "*** TEST No, 670 ***\n",
      "*** TEST No, 671 ***\n",
      "*** TEST No, 672 ***\n",
      "*** TEST No, 673 ***\n",
      "*** TEST No, 674 ***\n",
      "*** TEST No, 675 ***\n",
      "*** TEST No, 676 ***\n",
      "*** TEST No, 677 ***\n",
      "*** TEST No, 678 ***\n",
      "*** TEST No, 679 ***\n",
      "*** TEST No, 680 ***\n",
      "*** TEST No, 681 ***\n",
      "*** TEST No, 682 ***\n",
      "*** TEST No, 683 ***\n",
      "*** TEST No, 684 ***\n",
      "*** TEST No, 685 ***\n",
      "*** TEST No, 686 ***\n",
      "*** TEST No, 687 ***\n",
      "*** TEST No, 688 ***\n",
      "*** TEST No, 689 ***\n",
      "*** TEST No, 690 ***\n",
      "*** TEST No, 691 ***\n",
      "*** TEST No, 692 ***\n",
      "*** TEST No, 693 ***\n",
      "*** TEST No, 694 ***\n",
      "*** TEST No, 695 ***\n",
      "*** TEST No, 696 ***\n",
      "*** TEST No, 697 ***\n",
      "*** TEST No, 698 ***\n",
      "*** TEST No, 699 ***\n",
      "*** TEST No, 700 ***\n",
      "*** TEST No, 701 ***\n",
      "*** TEST No, 702 ***\n",
      "*** TEST No, 703 ***\n",
      "*** TEST No, 704 ***\n",
      "*** TEST No, 705 ***\n",
      "*** TEST No, 706 ***\n",
      "*** TEST No, 707 ***\n",
      "*** TEST No, 708 ***\n",
      "*** TEST No, 709 ***\n",
      "*** TEST No, 710 ***\n",
      "*** TEST No, 711 ***\n",
      "*** TEST No, 712 ***\n",
      "*** TEST No, 713 ***\n",
      "*** TEST No, 714 ***\n",
      "*** TEST No, 715 ***\n",
      "*** TEST No, 716 ***\n",
      "*** TEST No, 717 ***\n",
      "*** TEST No, 718 ***\n",
      "*** TEST No, 719 ***\n",
      "*** TEST No, 720 ***\n",
      "*** TEST No, 721 ***\n",
      "*** TEST No, 722 ***\n",
      "*** TEST No, 723 ***\n",
      "*** TEST No, 724 ***\n",
      "*** TEST No, 725 ***\n",
      "*** TEST No, 726 ***\n",
      "*** TEST No, 727 ***\n",
      "*** TEST No, 728 ***\n",
      "*** TEST No, 729 ***\n",
      "*** TEST No, 730 ***\n",
      "*** TEST No, 731 ***\n",
      "*** TEST No, 732 ***\n",
      "*** TEST No, 733 ***\n",
      "*** TEST No, 734 ***\n",
      "*** TEST No, 735 ***\n",
      "*** TEST No, 736 ***\n",
      "*** TEST No, 737 ***\n",
      "*** TEST No, 738 ***\n",
      "*** TEST No, 739 ***\n",
      "*** TEST No, 740 ***\n",
      "*** TEST No, 741 ***\n",
      "*** TEST No, 742 ***\n",
      "*** TEST No, 743 ***\n",
      "*** TEST No, 744 ***\n",
      "*** TEST No, 745 ***\n",
      "*** TEST No, 746 ***\n",
      "*** TEST No, 747 ***\n",
      "*** TEST No, 748 ***\n",
      "*** TEST No, 749 ***\n",
      "*** TEST No, 750 ***\n",
      "*** TEST No, 751 ***\n",
      "*** TEST No, 752 ***\n",
      "*** TEST No, 753 ***\n",
      "*** TEST No, 754 ***\n",
      "*** TEST No, 755 ***\n",
      "*** TEST No, 756 ***\n",
      "*** TEST No, 757 ***\n",
      "*** TEST No, 758 ***\n",
      "*** TEST No, 759 ***\n",
      "*** TEST No, 760 ***\n",
      "*** TEST No, 761 ***\n",
      "*** TEST No, 762 ***\n",
      "*** TEST No, 763 ***\n",
      "*** TEST No, 764 ***\n",
      "*** TEST No, 765 ***\n",
      "*** TEST No, 766 ***\n",
      "*** TEST No, 767 ***\n",
      "*** TEST No, 768 ***\n",
      "*** TEST No, 769 ***\n",
      "*** TEST No, 770 ***\n",
      "*** TEST No, 771 ***\n",
      "*** TEST No, 772 ***\n",
      "*** TEST No, 773 ***\n",
      "*** TEST No, 774 ***\n",
      "*** TEST No, 775 ***\n",
      "*** TEST No, 776 ***\n",
      "*** TEST No, 777 ***\n",
      "*** TEST No, 778 ***\n",
      "*** TEST No, 779 ***\n",
      "*** TEST No, 780 ***\n",
      "*** TEST No, 781 ***\n",
      "*** TEST No, 782 ***\n",
      "*** TEST No, 783 ***\n",
      "*** TEST No, 784 ***\n",
      "*** TEST No, 785 ***\n",
      "*** TEST No, 786 ***\n",
      "*** TEST No, 787 ***\n",
      "*** TEST No, 788 ***\n",
      "*** TEST No, 789 ***\n",
      "*** TEST No, 790 ***\n",
      "*** TEST No, 791 ***\n",
      "*** TEST No, 792 ***\n",
      "*** TEST No, 793 ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TEST No, 794 ***\n",
      "*** TEST No, 795 ***\n",
      "*** TEST No, 796 ***\n",
      "*** TEST No, 797 ***\n",
      "*** TEST No, 798 ***\n",
      "*** TEST No, 799 ***\n",
      "*** TEST No, 800 ***\n",
      "*** TEST No, 801 ***\n",
      "*** TEST No, 802 ***\n",
      "*** TEST No, 803 ***\n",
      "*** TEST No, 804 ***\n",
      "*** TEST No, 805 ***\n",
      "*** TEST No, 806 ***\n",
      "*** TEST No, 807 ***\n",
      "*** TEST No, 808 ***\n",
      "*** TEST No, 809 ***\n",
      "*** TEST No, 810 ***\n",
      "*** TEST No, 811 ***\n",
      "*** TEST No, 812 ***\n",
      "*** TEST No, 813 ***\n",
      "*** TEST No, 814 ***\n",
      "*** TEST No, 815 ***\n",
      "*** TEST No, 816 ***\n",
      "*** TEST No, 817 ***\n",
      "*** TEST No, 818 ***\n",
      "*** TEST No, 819 ***\n",
      "*** TEST No, 820 ***\n",
      "*** TEST No, 821 ***\n",
      "*** TEST No, 822 ***\n",
      "*** TEST No, 823 ***\n",
      "*** TEST No, 824 ***\n",
      "*** TEST No, 825 ***\n",
      "*** TEST No, 826 ***\n",
      "*** TEST No, 827 ***\n",
      "*** TEST No, 828 ***\n",
      "*** TEST No, 829 ***\n",
      "*** TEST No, 830 ***\n",
      "*** TEST No, 831 ***\n",
      "*** TEST No, 832 ***\n",
      "*** TEST No, 833 ***\n",
      "*** TEST No, 834 ***\n",
      "*** TEST No, 835 ***\n",
      "*** TEST No, 836 ***\n",
      "*** TEST No, 837 ***\n",
      "*** TEST No, 838 ***\n",
      "*** TEST No, 839 ***\n",
      "*** TEST No, 840 ***\n",
      "*** TEST No, 841 ***\n",
      "*** TEST No, 842 ***\n",
      "*** TEST No, 843 ***\n",
      "*** TEST No, 844 ***\n",
      "*** TEST No, 845 ***\n",
      "*** TEST No, 846 ***\n",
      "*** TEST No, 847 ***\n",
      "*** TEST No, 848 ***\n",
      "*** TEST No, 849 ***\n",
      "*** TEST No, 850 ***\n",
      "*** TEST No, 851 ***\n",
      "*** TEST No, 852 ***\n",
      "*** TEST No, 853 ***\n",
      "*** TEST No, 854 ***\n",
      "*** TEST No, 855 ***\n",
      "*** TEST No, 856 ***\n",
      "*** TEST No, 857 ***\n",
      "*** TEST No, 858 ***\n",
      "*** TEST No, 859 ***\n",
      "*** TEST No, 860 ***\n",
      "*** TEST No, 861 ***\n",
      "*** TEST No, 862 ***\n",
      "*** TEST No, 863 ***\n",
      "*** TEST No, 864 ***\n",
      "*** TEST No, 865 ***\n",
      "*** TEST No, 866 ***\n",
      "*** TEST No, 867 ***\n",
      "*** TEST No, 868 ***\n",
      "*** TEST No, 869 ***\n",
      "*** TEST No, 870 ***\n",
      "*** TEST No, 871 ***\n",
      "*** TEST No, 872 ***\n",
      "*** TEST No, 873 ***\n",
      "*** TEST No, 874 ***\n",
      "*** TEST No, 875 ***\n",
      "*** TEST No, 876 ***\n",
      "*** TEST No, 877 ***\n",
      "*** TEST No, 878 ***\n",
      "*** TEST No, 879 ***\n",
      "*** TEST No, 880 ***\n",
      "*** TEST No, 881 ***\n",
      "*** TEST No, 882 ***\n",
      "*** TEST No, 883 ***\n",
      "*** TEST No, 884 ***\n",
      "*** TEST No, 885 ***\n",
      "*** TEST No, 886 ***\n",
      "*** TEST No, 887 ***\n",
      "*** TEST No, 888 ***\n",
      "*** TEST No, 889 ***\n",
      "*** TEST No, 890 ***\n",
      "*** TEST No, 891 ***\n",
      "*** TEST No, 892 ***\n",
      "*** TEST No, 893 ***\n",
      "*** TEST No, 894 ***\n",
      "*** TEST No, 895 ***\n",
      "*** TEST No, 896 ***\n",
      "*** TEST No, 897 ***\n",
      "*** TEST No, 898 ***\n",
      "*** TEST No, 899 ***\n",
      "*** TEST No, 900 ***\n",
      "*** TEST No, 901 ***\n",
      "*** TEST No, 902 ***\n",
      "*** TEST No, 903 ***\n",
      "*** TEST No, 904 ***\n",
      "*** TEST No, 905 ***\n",
      "*** TEST No, 906 ***\n",
      "*** TEST No, 907 ***\n",
      "*** TEST No, 908 ***\n",
      "*** TEST No, 909 ***\n",
      "*** TEST No, 910 ***\n",
      "*** TEST No, 911 ***\n",
      "*** TEST No, 912 ***\n",
      "*** TEST No, 913 ***\n",
      "*** TEST No, 914 ***\n",
      "*** TEST No, 915 ***\n",
      "*** TEST No, 916 ***\n",
      "*** TEST No, 917 ***\n",
      "*** TEST No, 918 ***\n",
      "*** TEST No, 919 ***\n",
      "*** TEST No, 920 ***\n",
      "*** TEST No, 921 ***\n",
      "*** TEST No, 922 ***\n",
      "*** TEST No, 923 ***\n",
      "*** TEST No, 924 ***\n",
      "*** TEST No, 925 ***\n",
      "*** TEST No, 926 ***\n",
      "*** TEST No, 927 ***\n",
      "*** TEST No, 928 ***\n",
      "*** TEST No, 929 ***\n",
      "*** TEST No, 930 ***\n",
      "*** TEST No, 931 ***\n",
      "*** TEST No, 932 ***\n",
      "*** TEST No, 933 ***\n",
      "*** TEST No, 934 ***\n",
      "*** TEST No, 935 ***\n",
      "*** TEST No, 936 ***\n",
      "*** TEST No, 937 ***\n",
      "*** TEST No, 938 ***\n",
      "*** TEST No, 939 ***\n",
      "*** TEST No, 940 ***\n",
      "*** TEST No, 941 ***\n",
      "*** TEST No, 942 ***\n",
      "*** TEST No, 943 ***\n",
      "*** TEST No, 944 ***\n",
      "*** TEST No, 945 ***\n",
      "*** TEST No, 946 ***\n",
      "*** TEST No, 947 ***\n",
      "*** TEST No, 948 ***\n",
      "*** TEST No, 949 ***\n",
      "*** TEST No, 950 ***\n",
      "*** TEST No, 951 ***\n",
      "*** TEST No, 952 ***\n",
      "*** TEST No, 953 ***\n",
      "*** TEST No, 954 ***\n",
      "*** TEST No, 955 ***\n",
      "*** TEST No, 956 ***\n",
      "*** TEST No, 957 ***\n",
      "*** TEST No, 958 ***\n",
      "*** TEST No, 959 ***\n",
      "*** TEST No, 960 ***\n",
      "*** TEST No, 961 ***\n",
      "*** TEST No, 962 ***\n",
      "*** TEST No, 963 ***\n",
      "*** TEST No, 964 ***\n",
      "*** TEST No, 965 ***\n",
      "*** TEST No, 966 ***\n",
      "*** TEST No, 967 ***\n",
      "*** TEST No, 968 ***\n",
      "*** TEST No, 969 ***\n",
      "*** TEST No, 970 ***\n",
      "*** TEST No, 971 ***\n",
      "*** TEST No, 972 ***\n",
      "*** TEST No, 973 ***\n",
      "*** TEST No, 974 ***\n",
      "*** TEST No, 975 ***\n",
      "*** TEST No, 976 ***\n",
      "*** TEST No, 977 ***\n",
      "*** TEST No, 978 ***\n",
      "*** TEST No, 979 ***\n",
      "*** TEST No, 980 ***\n",
      "*** TEST No, 981 ***\n",
      "*** TEST No, 982 ***\n",
      "*** TEST No, 983 ***\n",
      "*** TEST No, 984 ***\n",
      "*** TEST No, 985 ***\n",
      "*** TEST No, 986 ***\n",
      "*** TEST No, 987 ***\n",
      "*** TEST No, 988 ***\n",
      "*** TEST No, 989 ***\n",
      "*** TEST No, 990 ***\n",
      "*** TEST No, 991 ***\n",
      "*** TEST No, 992 ***\n",
      "*** TEST No, 993 ***\n",
      "*** TEST No, 994 ***\n",
      "*** TEST No, 995 ***\n",
      "*** TEST No, 996 ***\n",
      "*** TEST No, 997 ***\n",
      "*** TEST No, 998 ***\n",
      "*** TEST No, 999 ***\n",
      "*** TEST No, 1000 ***\n",
      "*** TEST No, 1001 ***\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "tech_keys=[]\n",
    "spacy_keys = []\n",
    "for item in all_strings:\n",
    "    print(\"***\",\"TEST No,\",i,\"***\")\n",
    "    i=i+1\n",
    "    tech_row=[]\n",
    "    spacy_row = []\n",
    "    for k in all_tech_words:\n",
    "        if k in item and len(k)>2:\n",
    "            tech_row.append(k)\n",
    "            k=k.strip()\n",
    "            k.replace(\" \",\"_\")\n",
    "            k.replace(\",\",\"\")\n",
    "            spacy_row.append([k,item.index(k)-2,item.index(k) + len(k)-2,\"ORG\"])\n",
    "        \n",
    "    tech_keys.append(tech_row)\n",
    "    spacy_keys.append(spacy_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "according-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary = dump_format_change(summary, \"summaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "annoying-sussex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "answering-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tech_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "industrial-shirt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>exact_matched_patt_contextual</th>\n",
       "      <th>summaries</th>\n",
       "      <th>summaries_matching</th>\n",
       "      <th>Tech_from_string_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zsDSYc5UzpyXekOABZBfnQ_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[senior director of clinical services housing ...</td>\n",
       "      <td>['senior director of clinical services housing...</td>\n",
       "      <td>[alis, and co, awareness, cat, circle, flo, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zs1YNrrCeorFkGLEXSSp-A_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i believe that passions are meant to be share...</td>\n",
       "      <td>['i believe that passions are meant to be shar...</td>\n",
       "      <td>[alis, and co, ark, brain, cat, cien, construc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zowirq8ZhxhchApaRMhNSA_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[bill bryant is founder and chairman of bryant...</td>\n",
       "      <td>[\"bill bryant is founder and chairman of bryan...</td>\n",
       "      <td>[air, candid, cat, chai, found, foundation, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zoQVkPCfXB9n3AaPGHHwzg_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[undertaking a trilingual masters degree in eu...</td>\n",
       "      <td>['undertaking a trilingual masters degree in e...</td>\n",
       "      <td>[alis, and co, ark, cat, emplo, enth, ics, ion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zmIr2glBZ3Ef8CSS0jw1og_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[career objective a role within marketing and ...</td>\n",
       "      <td>[\"career objective a role within marketing and...</td>\n",
       "      <td>[ami, and co, ark, cat, combin, front, ion, it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id exact_matched_patt_contextual  \\\n",
       "0  zsDSYc5UzpyXekOABZBfnQ_0000                            []   \n",
       "1  zs1YNrrCeorFkGLEXSSp-A_0000                            []   \n",
       "2  zowirq8ZhxhchApaRMhNSA_0000                            []   \n",
       "3  zoQVkPCfXB9n3AaPGHHwzg_0000                            []   \n",
       "4  zmIr2glBZ3Ef8CSS0jw1og_0000                            []   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  [senior director of clinical services housing ...   \n",
       "1  [i believe that passions are meant to be share...   \n",
       "2  [bill bryant is founder and chairman of bryant...   \n",
       "3  [undertaking a trilingual masters degree in eu...   \n",
       "4  [career objective a role within marketing and ...   \n",
       "\n",
       "                                  summaries_matching  \\\n",
       "0  ['senior director of clinical services housing...   \n",
       "1  ['i believe that passions are meant to be shar...   \n",
       "2  [\"bill bryant is founder and chairman of bryan...   \n",
       "3  ['undertaking a trilingual masters degree in e...   \n",
       "4  [\"career objective a role within marketing and...   \n",
       "\n",
       "                              Tech_from_string_match  \n",
       "0  [alis, and co, awareness, cat, circle, flo, in...  \n",
       "1  [alis, and co, ark, brain, cat, cien, construc...  \n",
       "2  [air, candid, cat, chai, found, foundation, in...  \n",
       "3  [alis, and co, ark, cat, emplo, enth, ics, ion...  \n",
       "4  [ami, and co, ark, cat, combin, front, ion, it...  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary['Tech_from_string_match']=tech_keys\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "sixth-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary[\"exact_matched_patt_contextual\"][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "partial-summary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>exact_matched_patt_contextual</th>\n",
       "      <th>summaries</th>\n",
       "      <th>summaries_matching</th>\n",
       "      <th>Tech_from_string_match</th>\n",
       "      <th>spacy_format_v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zsDSYc5UzpyXekOABZBfnQ_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[senior director of clinical services housing ...</td>\n",
       "      <td>['senior director of clinical services housing...</td>\n",
       "      <td>[alis, and co, awareness, cat, circle, flo, in...</td>\n",
       "      <td>[[alis, 223, 227, ORG], [and co, 142, 148, ORG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zs1YNrrCeorFkGLEXSSp-A_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i believe that passions are meant to be share...</td>\n",
       "      <td>['i believe that passions are meant to be shar...</td>\n",
       "      <td>[alis, and co, ark, brain, cat, cien, construc...</td>\n",
       "      <td>[[alis, 1135, 1139, ORG], [and co, 358, 364, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zowirq8ZhxhchApaRMhNSA_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[bill bryant is founder and chairman of bryant...</td>\n",
       "      <td>[\"bill bryant is founder and chairman of bryan...</td>\n",
       "      <td>[air, candid, cat, chai, found, foundation, in...</td>\n",
       "      <td>[[air, 29, 32, ORG], [candid, 695, 701, ORG], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zoQVkPCfXB9n3AaPGHHwzg_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[undertaking a trilingual masters degree in eu...</td>\n",
       "      <td>['undertaking a trilingual masters degree in e...</td>\n",
       "      <td>[alis, and co, ark, cat, emplo, enth, ics, ion...</td>\n",
       "      <td>[[alis, 94, 98, ORG], [and co, 434, 440, ORG],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zmIr2glBZ3Ef8CSS0jw1og_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[career objective a role within marketing and ...</td>\n",
       "      <td>[\"career objective a role within marketing and...</td>\n",
       "      <td>[ami, and co, ark, cat, combin, front, ion, it...</td>\n",
       "      <td>[[ami, 602, 605, ORG], [and co, 359, 365, ORG]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id exact_matched_patt_contextual  \\\n",
       "0  zsDSYc5UzpyXekOABZBfnQ_0000                            []   \n",
       "1  zs1YNrrCeorFkGLEXSSp-A_0000                            []   \n",
       "2  zowirq8ZhxhchApaRMhNSA_0000                            []   \n",
       "3  zoQVkPCfXB9n3AaPGHHwzg_0000                            []   \n",
       "4  zmIr2glBZ3Ef8CSS0jw1og_0000                            []   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  [senior director of clinical services housing ...   \n",
       "1  [i believe that passions are meant to be share...   \n",
       "2  [bill bryant is founder and chairman of bryant...   \n",
       "3  [undertaking a trilingual masters degree in eu...   \n",
       "4  [career objective a role within marketing and ...   \n",
       "\n",
       "                                  summaries_matching  \\\n",
       "0  ['senior director of clinical services housing...   \n",
       "1  ['i believe that passions are meant to be shar...   \n",
       "2  [\"bill bryant is founder and chairman of bryan...   \n",
       "3  ['undertaking a trilingual masters degree in e...   \n",
       "4  [\"career objective a role within marketing and...   \n",
       "\n",
       "                              Tech_from_string_match  \\\n",
       "0  [alis, and co, awareness, cat, circle, flo, in...   \n",
       "1  [alis, and co, ark, brain, cat, cien, construc...   \n",
       "2  [air, candid, cat, chai, found, foundation, in...   \n",
       "3  [alis, and co, ark, cat, emplo, enth, ics, ion...   \n",
       "4  [ami, and co, ark, cat, combin, front, ion, it...   \n",
       "\n",
       "                                     spacy_format_v1  \n",
       "0  [[alis, 223, 227, ORG], [and co, 142, 148, ORG...  \n",
       "1  [[alis, 1135, 1139, ORG], [and co, 358, 364, O...  \n",
       "2  [[air, 29, 32, ORG], [candid, 695, 701, ORG], ...  \n",
       "3  [[alis, 94, 98, ORG], [and co, 434, 440, ORG],...  \n",
       "4  [[ami, 602, 605, ORG], [and co, 359, 365, ORG]...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary['spacy_format_v1']=spacy_keys\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bright-correlation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['senior director of clinical services housing assistance and hiv aids services with focus in clinical supervision trauma informed care trainer and consultant program development and leadership building behavior support specialist behavior therapist lcsw/ provide supervision to therapist obtaining credentials former management of autism circles of treatment support grant consultation in the area of intellectual disabilities and mental health needs expertise in the area and advocate of social and sexual awareness and needs for individuals participated and trained as a volunteer for the kentucky crisis response team volunteered for american red cross to debrief victims of katrina, flood and tropical storm disasters presentations in a variety of areas to assist clients and staff in behavioral and mental health needs former member of steering committee for trauma informed care and development of training, senior director of clinical services\\nhousing programs with focus in clinical services\\ntrauma informed care trainer and consultant \\nprogram development and leadership building\\nbehavior support specialist\\nbehavior therapist\\nlcsw/ provide supervision to therapist obtaining credentials \\nformer management of autism circles of treatment support grant\\nconsultation in the area of intellectual disabilities and mental health needs\\nexpertise in the area and advocate of social and sexual awareness and needs for individuals\\nparticipated and trained as a volunteer for the kentucky crisis response team\\nvolunteered for american red cross to debrief victims of katrina, flood and tropical storm disasters\\npresentations in a variety of areas to assist clients and staff in behavioral and mental health needs\\nformer member of steering committee for trauma informed care and development of training, senior director of clinical services at volunteers of america of kentucky, senior director at volunteers of america mid-states']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[\"summaries\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "statewide-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "aquatic-ceremony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['senior director of clinical services housing assistance and hiv aids services with focus in clinical supervision trauma informed care trainer and consultant program development and leadership building behavior support specialist behavior therapist lcsw/ provide supervision to therapist obtaining credentials former management of autism circles of treatment support grant consultation in the area of intellectual disabilities and mental health needs expertise in the area and advocate of social and sexual awareness and needs for individuals participated and trained as a volunteer for the kentucky crisis response team volunteered for american red cross to debrief victims of katrina, flood and tropical storm disasters presentations in a variety of areas to assist clients and staff in behavioral and mental health needs former member of steering committee for trauma informed care and development of training, senior director of clinical services\\nhousing programs with focus in clinical services\\ntrauma informed care trainer and consultant \\nprogram development and leadership building\\nbehavior support specialist\\nbehavior therapist\\nlcsw/ provide supervision to therapist obtaining credentials \\nformer management of autism circles of treatment support grant\\nconsultation in the area of intellectual disabilities and mental health needs\\nexpertise in the area and advocate of social and sexual awareness and needs for individuals\\nparticipated and trained as a volunteer for the kentucky crisis response team\\nvolunteered for american red cross to debrief victims of katrina, flood and tropical storm disasters\\npresentations in a variety of areas to assist clients and staff in behavioral and mental health needs\\nformer member of steering committee for trauma informed care and development of training, senior director of clinical services at volunteers of america of kentucky, senior director at volunteers of america mid-states']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"summaries\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "wrong-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def final_run_string(summary_copy, tech):\n",
    "    \n",
    "#     tech_list = []\n",
    "#     summary_list = []\n",
    "#     id_list = []\n",
    "    \n",
    "#     start = time.time()\n",
    "\n",
    "#     for i in range(0, len(summary_copy)):\n",
    "#         print(i)\n",
    "#         string = summary_copy.loc[i, \"summaries\"][0]\n",
    "#         string = string.lower()\n",
    "\n",
    "#         for j in range(0, len(tech)):\n",
    "#             pat = tech.loc[j,\"title\"]\n",
    "#             pat = pat.lower()\n",
    "\n",
    "\n",
    "#             initial_index = KMP_String(pat, string)\n",
    "#             if len(initial_index)!=0:\n",
    "\n",
    "#                 tech_list.append(pat)    \n",
    "#                 summary_list.append(string)\n",
    "#                 id_list.append(summary_copy.loc[i,\"id\"])\n",
    "\n",
    "#     end = time.time() - start\n",
    "#     print(\"\\n Time Taken \\n\", end)\n",
    "#     return tech_list, summary_list, id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "conventional-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tech_list, summary_list, id_list = final_run_string(summary, tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "international-qatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tech_list_copy = tech_list\n",
    "# id_list_copy = id_list\n",
    "# summary_list_copy = summary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "british-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getDuplicatesWithInfo(listOfElems):\n",
    "#     ''' Get duplicate element in a list along with thier indices in list\n",
    "#      and frequency count'''\n",
    "#     dictOfElems = dict()\n",
    "#     index = 0\n",
    "#     # Iterate over each element in list and keep track of index\n",
    "#     for elem in listOfElems:\n",
    "#         # If element exists in dict then keep its index in list & increment its frequency\n",
    "#         if elem in dictOfElems:\n",
    "#             dictOfElems[elem][0] += 1\n",
    "#             dictOfElems[elem][1].append(index)\n",
    "#         else:\n",
    "#             # Add a new entry in dictionary \n",
    "#             dictOfElems[elem] = [1, [index]]\n",
    "#         index += 1    \n",
    " \n",
    "#     dictOfElems = { key:value for key, value in dictOfElems.items() if value[0] > 1}\n",
    "#     return dictOfElems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "naval-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of strings\n",
    "# listOfElems = id_list\n",
    "# dictOfElems = getDuplicatesWithInfo(listOfElems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "million-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(list(zip(id_list, summary_list, tech_list)), \n",
    "#                columns =['id', 'summaries', \"Tech_from_string_match\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "narrative-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, value in dictOfElems.items():\n",
    "# #     print(\"******************\")\n",
    "# #     print(\"\\n ID is..\", key )\n",
    "#     a = df[\"Tech_from_string_match\"][value[1][0]] #this needs to be changed\n",
    "#     b = []\n",
    "#     b.insert(0,a)\n",
    "# #     print(\"List at first index\", b)\n",
    "#     for i in range(0, len(value[1])-1):\n",
    "#         b.append(df[\"Tech_from_string_match\"][value[1][i+1]])\n",
    "#         df[\"Tech_from_string_match\"][value[1][0]] = b\n",
    "        \n",
    "#     for i in range(0, len(value[1])-1):\n",
    "#         df = df.drop(index = [value[1][i+1]])\n",
    "# #         print('Element = ', key , ' :: Repeated Count = ', value[0] , ' :: Index Positions =  ', value[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "extraordinary-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "instrumental-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Regex to filter out Invalid Words\n",
    "\n",
    "def get_exact_match(txt, tech):\n",
    "    try:\n",
    "        patt = '|'.join(['\\\\b'+elem+'\\\\b' for elem in tech])\n",
    "        matched_patt = re.findall(patt,txt)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        matched_patt = []\n",
    "    return matched_patt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "lovely-privilege",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple repeat at position 20\n",
      "multiple repeat at position 50\n",
      "multiple repeat at position 20\n",
      "multiple repeat at position 47\n",
      "multiple repeat at position 40\n",
      "multiple repeat at position 102\n",
      "multiple repeat at position 55\n",
      "multiple repeat at position 35\n",
      "multiple repeat at position 71\n",
      "multiple repeat at position 67\n",
      "multiple repeat at position 20\n",
      "multiple repeat at position 51\n",
      "multiple repeat at position 78\n",
      "multiple repeat at position 21\n",
      "multiple repeat at position 20\n"
     ]
    }
   ],
   "source": [
    "df['exact_matched_patt'] = df.apply(lambda x: get_exact_match(x[\"summaries\"][0], x[\"Tech_from_string_match\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "continued-chair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>exact_matched_patt_contextual</th>\n",
       "      <th>summaries</th>\n",
       "      <th>summaries_matching</th>\n",
       "      <th>Tech_from_string_match</th>\n",
       "      <th>spacy_format_v1</th>\n",
       "      <th>exact_matched_patt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zsDSYc5UzpyXekOABZBfnQ_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[senior director of clinical services housing ...</td>\n",
       "      <td>['senior director of clinical services housing...</td>\n",
       "      <td>[alis, and co, awareness, cat, circle, flo, in...</td>\n",
       "      <td>[[alis, 223, 227, ORG], [and co, 142, 148, ORG...</td>\n",
       "      <td>[awareness, tropical, storm, awareness, tropic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zs1YNrrCeorFkGLEXSSp-A_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i believe that passions are meant to be share...</td>\n",
       "      <td>['i believe that passions are meant to be shar...</td>\n",
       "      <td>[alis, and co, ark, brain, cat, cien, construc...</td>\n",
       "      <td>[[alis, 1135, 1139, ORG], [and co, 358, 364, O...</td>\n",
       "      <td>[storyteller, brain, brain, grow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zowirq8ZhxhchApaRMhNSA_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[bill bryant is founder and chairman of bryant...</td>\n",
       "      <td>[\"bill bryant is founder and chairman of bryan...</td>\n",
       "      <td>[air, candid, cat, chai, found, foundation, in...</td>\n",
       "      <td>[[air, 29, 32, ORG], [candid, 695, 701, ORG], ...</td>\n",
       "      <td>[foundation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zoQVkPCfXB9n3AaPGHHwzg_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[undertaking a trilingual masters degree in eu...</td>\n",
       "      <td>['undertaking a trilingual masters degree in e...</td>\n",
       "      <td>[alis, and co, ark, cat, emplo, enth, ics, ion...</td>\n",
       "      <td>[[alis, 94, 98, ORG], [and co, 434, 440, ORG],...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zmIr2glBZ3Ef8CSS0jw1og_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[career objective a role within marketing and ...</td>\n",
       "      <td>[\"career objective a role within marketing and...</td>\n",
       "      <td>[ami, and co, ark, cat, combin, front, ion, it...</td>\n",
       "      <td>[[ami, 602, 605, ORG], [and co, 359, 365, ORG]...</td>\n",
       "      <td>[speak, front]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id exact_matched_patt_contextual  \\\n",
       "0  zsDSYc5UzpyXekOABZBfnQ_0000                            []   \n",
       "1  zs1YNrrCeorFkGLEXSSp-A_0000                            []   \n",
       "2  zowirq8ZhxhchApaRMhNSA_0000                            []   \n",
       "3  zoQVkPCfXB9n3AaPGHHwzg_0000                            []   \n",
       "4  zmIr2glBZ3Ef8CSS0jw1og_0000                            []   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  [senior director of clinical services housing ...   \n",
       "1  [i believe that passions are meant to be share...   \n",
       "2  [bill bryant is founder and chairman of bryant...   \n",
       "3  [undertaking a trilingual masters degree in eu...   \n",
       "4  [career objective a role within marketing and ...   \n",
       "\n",
       "                                  summaries_matching  \\\n",
       "0  ['senior director of clinical services housing...   \n",
       "1  ['i believe that passions are meant to be shar...   \n",
       "2  [\"bill bryant is founder and chairman of bryan...   \n",
       "3  ['undertaking a trilingual masters degree in e...   \n",
       "4  [\"career objective a role within marketing and...   \n",
       "\n",
       "                              Tech_from_string_match  \\\n",
       "0  [alis, and co, awareness, cat, circle, flo, in...   \n",
       "1  [alis, and co, ark, brain, cat, cien, construc...   \n",
       "2  [air, candid, cat, chai, found, foundation, in...   \n",
       "3  [alis, and co, ark, cat, emplo, enth, ics, ion...   \n",
       "4  [ami, and co, ark, cat, combin, front, ion, it...   \n",
       "\n",
       "                                     spacy_format_v1  \\\n",
       "0  [[alis, 223, 227, ORG], [and co, 142, 148, ORG...   \n",
       "1  [[alis, 1135, 1139, ORG], [and co, 358, 364, O...   \n",
       "2  [[air, 29, 32, ORG], [candid, 695, 701, ORG], ...   \n",
       "3  [[alis, 94, 98, ORG], [and co, 434, 440, ORG],...   \n",
       "4  [[ami, 602, 605, ORG], [and co, 359, 365, ORG]...   \n",
       "\n",
       "                                  exact_matched_patt  \n",
       "0  [awareness, tropical, storm, awareness, tropic...  \n",
       "1                  [storyteller, brain, brain, grow]  \n",
       "2                                       [foundation]  \n",
       "3                                                 []  \n",
       "4                                     [speak, front]  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "stock-little",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['alis', 223, 227, 'ORG'],\n",
       " ['and co', 142, 148, 'ORG'],\n",
       " ['awareness', 506, 515, 'ORG'],\n",
       " ['cat', 480, 483, 'ORG'],\n",
       " ['circle', 337, 343, 'ORG'],\n",
       " ['flo', 686, 689, 'ORG'],\n",
       " ['inform', 120, 126, 'ORG'],\n",
       " ['intel', 400, 405, 'ORG'],\n",
       " ['intellect', 400, 409, 'ORG'],\n",
       " ['ion', 109, 112, 'ORG'],\n",
       " ['nex', 1346, 1349, 'ORG'],\n",
       " ['ning', 292, 296, 'ORG'],\n",
       " ['ora', 794, 797, 'ORG'],\n",
       " ['rain', 135, 139, 'ORG'],\n",
       " ['soci', 488, 492, 'ORG'],\n",
       " ['staf', 779, 783, 'ORG'],\n",
       " ['steer', 840, 845, 'ORG'],\n",
       " ['storm', 705, 710, 'ORG'],\n",
       " ['tia', 303, 306, 'ORG'],\n",
       " ['tor', 12, 15, 'ORG'],\n",
       " ['tropical', 696, 704, 'ORG'],\n",
       " ['vision', 106, 112, 'ORG'],\n",
       " ['vocate', 478, 484, 'ORG']]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"spacy_format_v1\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "nervous-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Regex to filter out Invalid Words\n",
    "\n",
    "def get_exact_match_2(txt, tech):\n",
    "    try:\n",
    "        patt = '|'.join(['\\\\s'+elem+'\\\\s' for elem in tech])\n",
    "        matched_patt = re.findall(patt,txt[0])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        matched_patt = []\n",
    "    return matched_patt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "celtic-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['matched_NER_final'] = df.apply(lambda x: get_exact_match_2(x[\"summaries\"][0], x[\"exact_matched_patt\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "accepting-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "smooth-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in df.index:\n",
    "    res = list(OrderedDict.fromkeys(df[\"exact_matched_patt\"][ind]))\n",
    "    df[\"exact_matched_patt\"][ind] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "complete-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(df)):\n",
    "    for word in list(df[\"exact_matched_patt\"][i]):\n",
    "        if word in remove_list:\n",
    "            df[\"exact_matched_patt\"][i].remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "baking-conducting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>exact_matched_patt_contextual</th>\n",
       "      <th>summaries</th>\n",
       "      <th>summaries_matching</th>\n",
       "      <th>Tech_from_string_match</th>\n",
       "      <th>spacy_format_v1</th>\n",
       "      <th>exact_matched_patt</th>\n",
       "      <th>matched_NER_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zsDSYc5UzpyXekOABZBfnQ_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[senior director of clinical services housing ...</td>\n",
       "      <td>['senior director of clinical services housing...</td>\n",
       "      <td>[alis, and co, awareness, cat, circle, flo, in...</td>\n",
       "      <td>[[alis, 223, 227, ORG], [and co, 142, 148, ORG...</td>\n",
       "      <td>[awareness, tropical, storm]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zs1YNrrCeorFkGLEXSSp-A_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i believe that passions are meant to be share...</td>\n",
       "      <td>['i believe that passions are meant to be shar...</td>\n",
       "      <td>[alis, and co, ark, brain, cat, cien, construc...</td>\n",
       "      <td>[[alis, 1135, 1139, ORG], [and co, 358, 364, O...</td>\n",
       "      <td>[storyteller, brain, grow]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zowirq8ZhxhchApaRMhNSA_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[bill bryant is founder and chairman of bryant...</td>\n",
       "      <td>[\"bill bryant is founder and chairman of bryan...</td>\n",
       "      <td>[air, candid, cat, chai, found, foundation, in...</td>\n",
       "      <td>[[air, 29, 32, ORG], [candid, 695, 701, ORG], ...</td>\n",
       "      <td>[foundation]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zoQVkPCfXB9n3AaPGHHwzg_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[undertaking a trilingual masters degree in eu...</td>\n",
       "      <td>['undertaking a trilingual masters degree in e...</td>\n",
       "      <td>[alis, and co, ark, cat, emplo, enth, ics, ion...</td>\n",
       "      <td>[[alis, 94, 98, ORG], [and co, 434, 440, ORG],...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zmIr2glBZ3Ef8CSS0jw1og_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[career objective a role within marketing and ...</td>\n",
       "      <td>[\"career objective a role within marketing and...</td>\n",
       "      <td>[ami, and co, ark, cat, combin, front, ion, it...</td>\n",
       "      <td>[[ami, 602, 605, ORG], [and co, 359, 365, ORG]...</td>\n",
       "      <td>[speak, front]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id exact_matched_patt_contextual  \\\n",
       "0  zsDSYc5UzpyXekOABZBfnQ_0000                            []   \n",
       "1  zs1YNrrCeorFkGLEXSSp-A_0000                            []   \n",
       "2  zowirq8ZhxhchApaRMhNSA_0000                            []   \n",
       "3  zoQVkPCfXB9n3AaPGHHwzg_0000                            []   \n",
       "4  zmIr2glBZ3Ef8CSS0jw1og_0000                            []   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  [senior director of clinical services housing ...   \n",
       "1  [i believe that passions are meant to be share...   \n",
       "2  [bill bryant is founder and chairman of bryant...   \n",
       "3  [undertaking a trilingual masters degree in eu...   \n",
       "4  [career objective a role within marketing and ...   \n",
       "\n",
       "                                  summaries_matching  \\\n",
       "0  ['senior director of clinical services housing...   \n",
       "1  ['i believe that passions are meant to be shar...   \n",
       "2  [\"bill bryant is founder and chairman of bryan...   \n",
       "3  ['undertaking a trilingual masters degree in e...   \n",
       "4  [\"career objective a role within marketing and...   \n",
       "\n",
       "                              Tech_from_string_match  \\\n",
       "0  [alis, and co, awareness, cat, circle, flo, in...   \n",
       "1  [alis, and co, ark, brain, cat, cien, construc...   \n",
       "2  [air, candid, cat, chai, found, foundation, in...   \n",
       "3  [alis, and co, ark, cat, emplo, enth, ics, ion...   \n",
       "4  [ami, and co, ark, cat, combin, front, ion, it...   \n",
       "\n",
       "                                     spacy_format_v1  \\\n",
       "0  [[alis, 223, 227, ORG], [and co, 142, 148, ORG...   \n",
       "1  [[alis, 1135, 1139, ORG], [and co, 358, 364, O...   \n",
       "2  [[air, 29, 32, ORG], [candid, 695, 701, ORG], ...   \n",
       "3  [[alis, 94, 98, ORG], [and co, 434, 440, ORG],...   \n",
       "4  [[ami, 602, 605, ORG], [and co, 359, 365, ORG]...   \n",
       "\n",
       "             exact_matched_patt matched_NER_final  \n",
       "0  [awareness, tropical, storm]                []  \n",
       "1    [storyteller, brain, grow]                []  \n",
       "2                  [foundation]                []  \n",
       "3                            []              [, ]  \n",
       "4                [speak, front]                []  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cloudy-nelson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['alis', 223, 227, 'ORG'],\n",
       " ['and co', 142, 148, 'ORG'],\n",
       " ['awareness', 506, 515, 'ORG'],\n",
       " ['cat', 480, 483, 'ORG'],\n",
       " ['circle', 337, 343, 'ORG'],\n",
       " ['flo', 686, 689, 'ORG'],\n",
       " ['inform', 120, 126, 'ORG'],\n",
       " ['intel', 400, 405, 'ORG'],\n",
       " ['intellect', 400, 409, 'ORG'],\n",
       " ['ion', 109, 112, 'ORG'],\n",
       " ['nex', 1346, 1349, 'ORG'],\n",
       " ['ning', 292, 296, 'ORG'],\n",
       " ['ora', 794, 797, 'ORG'],\n",
       " ['rain', 135, 139, 'ORG'],\n",
       " ['soci', 488, 492, 'ORG'],\n",
       " ['staf', 779, 783, 'ORG'],\n",
       " ['steer', 840, 845, 'ORG'],\n",
       " ['storm', 705, 710, 'ORG'],\n",
       " ['tia', 303, 306, 'ORG'],\n",
       " ['tor', 12, 15, 'ORG'],\n",
       " ['tropical', 696, 704, 'ORG'],\n",
       " ['vision', 106, 112, 'ORG'],\n",
       " ['vocate', 478, 484, 'ORG']]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"spacy_format_v1\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "pointed-pitch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[\"exact_matched_patt_contextual\"].fillna('[]')\n",
    "df[\"exact_matched_patt\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "round-payday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['microsoft office', 'adobe']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"exact_matched_patt_contextual\"][33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "palestinian-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['exact_matched_patt_contextual'] = [ [] if x is np.NaN else x for x in df['exact_matched_patt_contextual'] ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "anonymous-rouge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>exact_matched_patt_contextual</th>\n",
       "      <th>summaries</th>\n",
       "      <th>summaries_matching</th>\n",
       "      <th>Tech_from_string_match</th>\n",
       "      <th>spacy_format_v1</th>\n",
       "      <th>exact_matched_patt</th>\n",
       "      <th>matched_NER_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zsDSYc5UzpyXekOABZBfnQ_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[senior director of clinical services housing ...</td>\n",
       "      <td>['senior director of clinical services housing...</td>\n",
       "      <td>[alis, and co, awareness, cat, circle, flo, in...</td>\n",
       "      <td>[[alis, 223, 227, ORG], [and co, 142, 148, ORG...</td>\n",
       "      <td>[awareness, tropical, storm]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zs1YNrrCeorFkGLEXSSp-A_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i believe that passions are meant to be share...</td>\n",
       "      <td>['i believe that passions are meant to be shar...</td>\n",
       "      <td>[alis, and co, ark, brain, cat, cien, construc...</td>\n",
       "      <td>[[alis, 1135, 1139, ORG], [and co, 358, 364, O...</td>\n",
       "      <td>[storyteller, brain, grow]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zowirq8ZhxhchApaRMhNSA_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[bill bryant is founder and chairman of bryant...</td>\n",
       "      <td>[\"bill bryant is founder and chairman of bryan...</td>\n",
       "      <td>[air, candid, cat, chai, found, foundation, in...</td>\n",
       "      <td>[[air, 29, 32, ORG], [candid, 695, 701, ORG], ...</td>\n",
       "      <td>[foundation]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zoQVkPCfXB9n3AaPGHHwzg_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[undertaking a trilingual masters degree in eu...</td>\n",
       "      <td>['undertaking a trilingual masters degree in e...</td>\n",
       "      <td>[alis, and co, ark, cat, emplo, enth, ics, ion...</td>\n",
       "      <td>[[alis, 94, 98, ORG], [and co, 434, 440, ORG],...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zmIr2glBZ3Ef8CSS0jw1og_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[career objective a role within marketing and ...</td>\n",
       "      <td>[\"career objective a role within marketing and...</td>\n",
       "      <td>[ami, and co, ark, cat, combin, front, ion, it...</td>\n",
       "      <td>[[ami, 602, 605, ORG], [and co, 359, 365, ORG]...</td>\n",
       "      <td>[speak, front]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-EQeYEq-03cWVCkfnsUgow_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[eric is an experienced risk, insurance, and p...</td>\n",
       "      <td>['eric is an experienced risk, insurance, and ...</td>\n",
       "      <td>[ami, ark, ava, big picture, cat, communicator...</td>\n",
       "      <td>[[ami, 454, 457, ORG], [ark, 671, 674, ORG], [...</td>\n",
       "      <td>[communicator, big picture]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-EJPzKCOhrcLUKsIiC35Ow_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[team manager with 8 years of experience enabl...</td>\n",
       "      <td>['team manager with 8 years of experience enab...</td>\n",
       "      <td>[ace, ami, cat, chai, devi, directly, ecos, em...</td>\n",
       "      <td>[[ace, 318, 321, ORG], [ami, 344, 347, ORG], [...</td>\n",
       "      <td>[stay, lob, later]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-BSYFSH4GWqbTH-JhxVExA_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i am currently a junior at cal poly san luis ...</td>\n",
       "      <td>[\"i am currently a junior at cal poly san luis...</td>\n",
       "      <td>[ace, actor, ark, astro, cat, continu, esign, ...</td>\n",
       "      <td>[[ace, 1719, 1722, ORG], [actor, 2430, 2435, O...</td>\n",
       "      <td>[gain, astro, honestly]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-4ldAQ53se0hp9GU5FgnIQ_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[an extremely driven professional within the b...</td>\n",
       "      <td>['an extremely driven professional within the ...</td>\n",
       "      <td>[ace, and co, assess, attend, batch, cat, cien...</td>\n",
       "      <td>[[ace, 192, 195, ORG], [and co, 765, 771, ORG]...</td>\n",
       "      <td>[batch, attend, daily]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>-18msGiQiE2XLdy6XWGAEQ_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[10+ years of leveraged finance and investment...</td>\n",
       "      <td>['10+ years of leveraged finance and investmen...</td>\n",
       "      <td>[ami, ark, asset, inv, ion, lever, lua, omp, p...</td>\n",
       "      <td>[[ami, 800, 803, ORG], [ark, 566, 569, ORG], [...</td>\n",
       "      <td>[asset]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1001 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id exact_matched_patt_contextual  \\\n",
       "0     zsDSYc5UzpyXekOABZBfnQ_0000                            []   \n",
       "1     zs1YNrrCeorFkGLEXSSp-A_0000                            []   \n",
       "2     zowirq8ZhxhchApaRMhNSA_0000                            []   \n",
       "3     zoQVkPCfXB9n3AaPGHHwzg_0000                            []   \n",
       "4     zmIr2glBZ3Ef8CSS0jw1og_0000                            []   \n",
       "...                           ...                           ...   \n",
       "996   -EQeYEq-03cWVCkfnsUgow_0000                            []   \n",
       "997   -EJPzKCOhrcLUKsIiC35Ow_0000                            []   \n",
       "998   -BSYFSH4GWqbTH-JhxVExA_0000                            []   \n",
       "999   -4ldAQ53se0hp9GU5FgnIQ_0000                            []   \n",
       "1000  -18msGiQiE2XLdy6XWGAEQ_0000                            []   \n",
       "\n",
       "                                              summaries  \\\n",
       "0     [senior director of clinical services housing ...   \n",
       "1     [i believe that passions are meant to be share...   \n",
       "2     [bill bryant is founder and chairman of bryant...   \n",
       "3     [undertaking a trilingual masters degree in eu...   \n",
       "4     [career objective a role within marketing and ...   \n",
       "...                                                 ...   \n",
       "996   [eric is an experienced risk, insurance, and p...   \n",
       "997   [team manager with 8 years of experience enabl...   \n",
       "998   [i am currently a junior at cal poly san luis ...   \n",
       "999   [an extremely driven professional within the b...   \n",
       "1000  [10+ years of leveraged finance and investment...   \n",
       "\n",
       "                                     summaries_matching  \\\n",
       "0     ['senior director of clinical services housing...   \n",
       "1     ['i believe that passions are meant to be shar...   \n",
       "2     [\"bill bryant is founder and chairman of bryan...   \n",
       "3     ['undertaking a trilingual masters degree in e...   \n",
       "4     [\"career objective a role within marketing and...   \n",
       "...                                                 ...   \n",
       "996   ['eric is an experienced risk, insurance, and ...   \n",
       "997   ['team manager with 8 years of experience enab...   \n",
       "998   [\"i am currently a junior at cal poly san luis...   \n",
       "999   ['an extremely driven professional within the ...   \n",
       "1000  ['10+ years of leveraged finance and investmen...   \n",
       "\n",
       "                                 Tech_from_string_match  \\\n",
       "0     [alis, and co, awareness, cat, circle, flo, in...   \n",
       "1     [alis, and co, ark, brain, cat, cien, construc...   \n",
       "2     [air, candid, cat, chai, found, foundation, in...   \n",
       "3     [alis, and co, ark, cat, emplo, enth, ics, ion...   \n",
       "4     [ami, and co, ark, cat, combin, front, ion, it...   \n",
       "...                                                 ...   \n",
       "996   [ami, ark, ava, big picture, cat, communicator...   \n",
       "997   [ace, ami, cat, chai, devi, directly, ecos, em...   \n",
       "998   [ace, actor, ark, astro, cat, continu, esign, ...   \n",
       "999   [ace, and co, assess, attend, batch, cat, cien...   \n",
       "1000  [ami, ark, asset, inv, ion, lever, lua, omp, p...   \n",
       "\n",
       "                                        spacy_format_v1  \\\n",
       "0     [[alis, 223, 227, ORG], [and co, 142, 148, ORG...   \n",
       "1     [[alis, 1135, 1139, ORG], [and co, 358, 364, O...   \n",
       "2     [[air, 29, 32, ORG], [candid, 695, 701, ORG], ...   \n",
       "3     [[alis, 94, 98, ORG], [and co, 434, 440, ORG],...   \n",
       "4     [[ami, 602, 605, ORG], [and co, 359, 365, ORG]...   \n",
       "...                                                 ...   \n",
       "996   [[ami, 454, 457, ORG], [ark, 671, 674, ORG], [...   \n",
       "997   [[ace, 318, 321, ORG], [ami, 344, 347, ORG], [...   \n",
       "998   [[ace, 1719, 1722, ORG], [actor, 2430, 2435, O...   \n",
       "999   [[ace, 192, 195, ORG], [and co, 765, 771, ORG]...   \n",
       "1000  [[ami, 800, 803, ORG], [ark, 566, 569, ORG], [...   \n",
       "\n",
       "                exact_matched_patt matched_NER_final  \n",
       "0     [awareness, tropical, storm]                []  \n",
       "1       [storyteller, brain, grow]                []  \n",
       "2                     [foundation]                []  \n",
       "3                               []              [, ]  \n",
       "4                   [speak, front]                []  \n",
       "...                            ...               ...  \n",
       "996    [communicator, big picture]                []  \n",
       "997             [stay, lob, later]                []  \n",
       "998        [gain, astro, honestly]                []  \n",
       "999         [batch, attend, daily]                []  \n",
       "1000                       [asset]                []  \n",
       "\n",
       "[1001 rows x 8 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "dramatic-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove invalid entries from spacy format column\n",
    "\n",
    "def remove_invalid(final_tech, spacy_format):\n",
    "    \n",
    "    for i in list(spacy_format):\n",
    "        if i[0] not in final_tech:\n",
    "            spacy_format.remove(i)\n",
    "\n",
    "    return spacy_format          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "hispanic-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"spacy_format_manual_tag\"] = df.apply(lambda x: remove_invalid(x[\"exact_matched_patt_contextual\"], x[\"spacy_format_v1\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fleet-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"lookup_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-insert",
   "metadata": {},
   "source": [
    "# Commenting removing technology name function for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "correct-picture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>exact_matched_patt_contextual</th>\n",
       "      <th>summaries</th>\n",
       "      <th>summaries_matching</th>\n",
       "      <th>Tech_from_string_match</th>\n",
       "      <th>spacy_format_v1</th>\n",
       "      <th>exact_matched_patt</th>\n",
       "      <th>matched_NER_final</th>\n",
       "      <th>spacy_format_manual_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zsDSYc5UzpyXekOABZBfnQ_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[senior director of clinical services housing ...</td>\n",
       "      <td>['senior director of clinical services housing...</td>\n",
       "      <td>[alis, and co, awareness, cat, circle, flo, in...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[awareness, tropical, storm]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zs1YNrrCeorFkGLEXSSp-A_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[i believe that passions are meant to be share...</td>\n",
       "      <td>['i believe that passions are meant to be shar...</td>\n",
       "      <td>[alis, and co, ark, brain, cat, cien, construc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[storyteller, brain, grow]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zowirq8ZhxhchApaRMhNSA_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[bill bryant is founder and chairman of bryant...</td>\n",
       "      <td>[\"bill bryant is founder and chairman of bryan...</td>\n",
       "      <td>[air, candid, cat, chai, found, foundation, in...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[foundation]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zoQVkPCfXB9n3AaPGHHwzg_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[undertaking a trilingual masters degree in eu...</td>\n",
       "      <td>['undertaking a trilingual masters degree in e...</td>\n",
       "      <td>[alis, and co, ark, cat, emplo, enth, ics, ion...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[, ]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zmIr2glBZ3Ef8CSS0jw1og_0000</td>\n",
       "      <td>[]</td>\n",
       "      <td>[career objective a role within marketing and ...</td>\n",
       "      <td>[\"career objective a role within marketing and...</td>\n",
       "      <td>[ami, and co, ark, cat, combin, front, ion, it...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[speak, front]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id exact_matched_patt_contextual  \\\n",
       "0  zsDSYc5UzpyXekOABZBfnQ_0000                            []   \n",
       "1  zs1YNrrCeorFkGLEXSSp-A_0000                            []   \n",
       "2  zowirq8ZhxhchApaRMhNSA_0000                            []   \n",
       "3  zoQVkPCfXB9n3AaPGHHwzg_0000                            []   \n",
       "4  zmIr2glBZ3Ef8CSS0jw1og_0000                            []   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  [senior director of clinical services housing ...   \n",
       "1  [i believe that passions are meant to be share...   \n",
       "2  [bill bryant is founder and chairman of bryant...   \n",
       "3  [undertaking a trilingual masters degree in eu...   \n",
       "4  [career objective a role within marketing and ...   \n",
       "\n",
       "                                  summaries_matching  \\\n",
       "0  ['senior director of clinical services housing...   \n",
       "1  ['i believe that passions are meant to be shar...   \n",
       "2  [\"bill bryant is founder and chairman of bryan...   \n",
       "3  ['undertaking a trilingual masters degree in e...   \n",
       "4  [\"career objective a role within marketing and...   \n",
       "\n",
       "                              Tech_from_string_match spacy_format_v1  \\\n",
       "0  [alis, and co, awareness, cat, circle, flo, in...              []   \n",
       "1  [alis, and co, ark, brain, cat, cien, construc...              []   \n",
       "2  [air, candid, cat, chai, found, foundation, in...              []   \n",
       "3  [alis, and co, ark, cat, emplo, enth, ics, ion...              []   \n",
       "4  [ami, and co, ark, cat, combin, front, ion, it...              []   \n",
       "\n",
       "             exact_matched_patt matched_NER_final spacy_format_manual_tag  \n",
       "0  [awareness, tropical, storm]                []                      []  \n",
       "1    [storyteller, brain, grow]                []                      []  \n",
       "2                  [foundation]                []                      []  \n",
       "3                            []              [, ]                      []  \n",
       "4                [speak, front]                []                      []  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "understanding-juvenile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"exact_matched_patt\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "decent-radical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "index_drop = []\n",
    "for i in range(0, len(df)):\n",
    "    print(i)\n",
    "    if len(df[\"spacy_format_manual_tag\"][i])==0:\n",
    "        index_drop.append(i)\n",
    "df = df.drop(labels = index_drop, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "handy-seminar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "racial-status",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>exact_matched_patt_contextual</th>\n",
       "      <th>summaries</th>\n",
       "      <th>summaries_matching</th>\n",
       "      <th>Tech_from_string_match</th>\n",
       "      <th>spacy_format_v1</th>\n",
       "      <th>exact_matched_patt</th>\n",
       "      <th>matched_NER_final</th>\n",
       "      <th>spacy_format_manual_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zlBvzxx47BewWlO67-zK3Q_0000</td>\n",
       "      <td>[republic]</td>\n",
       "      <td>[i am a 19 year old entrepreneur and manager o...</td>\n",
       "      <td>[\"i am a 19 year old entrepreneur and manager ...</td>\n",
       "      <td>[ada, and co, construct, countr, ebs, found, g...</td>\n",
       "      <td>[[republic, 196, 204, ORG]]</td>\n",
       "      <td>[republic, turn, grow]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[republic, 196, 204, ORG]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zekuTL0ONYTX2XawUBa-9A_0000</td>\n",
       "      <td>[dell]</td>\n",
       "      <td>[i am a self motivated professional with 13+ y...</td>\n",
       "      <td>['i am a self motivated professional with 13+ ...</td>\n",
       "      <td>[ada, ark, cat, d custom, dell, emplo, ento, g...</td>\n",
       "      <td>[[dell, 2431, 2435, ORG]]</td>\n",
       "      <td>[grow, dell]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[dell, 2431, 2435, ORG]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>zaByWGsar5hVdBWLEYykcg_0000</td>\n",
       "      <td>[wordpress, joomla, drupal]</td>\n",
       "      <td>[as owner and director of projects at metro in...</td>\n",
       "      <td>['as owner and director of projects at metro i...</td>\n",
       "      <td>[accurate, amo, and co, ark, blis, cat, ddi, d...</td>\n",
       "      <td>[[drupal, 940, 946, ORG], [joomla, 921, 927, O...</td>\n",
       "      <td>[promote, accurate, medium, portal, joomla, wo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[drupal, 940, 946, ORG], [joomla, 921, 927, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>zPnnWGWHb2gSYnd98GKaag_0000</td>\n",
       "      <td>[unity]</td>\n",
       "      <td>[15+ years within the recruiting industry comb...</td>\n",
       "      <td>['15+ years within the recruiting industry com...</td>\n",
       "      <td>[candid, capabiliti, cat, combin, ento, forge,...</td>\n",
       "      <td>[[unity, 3286, 3291, ORG]]</td>\n",
       "      <td>[here, guru, unicorn, purple, hunter, snap, un...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[unity, 3286, 3291, ORG]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>z5LcE0BcZevf5WmwL8nunQ_0000</td>\n",
       "      <td>[microsoft office, juniper, workday, python, l...</td>\n",
       "      <td>[bachelor of science (b.s) degree in \" telecom...</td>\n",
       "      <td>['bachelor of science (b.s) degree in \" teleco...</td>\n",
       "      <td>[alis, ava, cat, cien, electron, eploy, format...</td>\n",
       "      <td>[[juniper, 955, 962, ORG], [linux, 992, 997, O...</td>\n",
       "      <td>[route, switch, link, juniper, linux, python, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[juniper, 955, 962, ORG], [linux, 992, 997, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>-nbbpInS-iD0thomdMs6BQ_0000</td>\n",
       "      <td>[zoom]</td>\n",
       "      <td>[i am a self-motivated sales &amp; marketing profe...</td>\n",
       "      <td>[\"i am a self-motivated sales &amp; marketing prof...</td>\n",
       "      <td>[air, ami, ark, cat, construct, continu, ddi, ...</td>\n",
       "      <td>[[zoom, 689, 693, ORG]]</td>\n",
       "      <td>[rapport, zoom, stay, promote, wing, flight]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[zoom, 689, 693, ORG]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>-jsY6ula0lsaOQ5rBHxHLg_0000</td>\n",
       "      <td>[invision, pixate, xcode, html]</td>\n",
       "      <td>[www.lisawilkins.com specialties: visual/ui/ux...</td>\n",
       "      <td>[\"www.lisawilkins.com specialties: visual/ui/u...</td>\n",
       "      <td>[accept, aps, ava, cod, connect, construct, de...</td>\n",
       "      <td>[[html, 382, 386, ORG], [invision, 341, 349, O...</td>\n",
       "      <td>[invisible, invision, pixate, soon, html, unif...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[html, 382, 386, ORG], [invision, 341, 349, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>-iRef22R0w52UJT280zoxQ_0000</td>\n",
       "      <td>[bootstrap, sitecore, asp.net, jquery]</td>\n",
       "      <td>[senior software engineer with 6+ years in ana...</td>\n",
       "      <td>['senior software engineer with 6+ years in an...</td>\n",
       "      <td>[ami, amo, apt, asp.net, bootstrap, cat, esign...</td>\n",
       "      <td>[[asp.net, 288, 295, ORG], [bootstrap, 395, 40...</td>\n",
       "      <td>[asp.net, jquery, bootstrap, less, proved, sol...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[asp.net, 288, 295, ORG], [bootstrap, 395, 40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>-bBI1d6Emr0wtwLVEvrssw_0000</td>\n",
       "      <td>[groupe]</td>\n",
       "      <td>[managing director, ceo, strategic business un...</td>\n",
       "      <td>['managing director, ceo, strategic business u...</td>\n",
       "      <td>[ark, construct, electron, esign, groupe, grow...</td>\n",
       "      <td>[[groupe, 1678, 1684, ORG]]</td>\n",
       "      <td>[sigma, groupe]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[groupe, 1678, 1684, ORG]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>-XuwuUKT3N67akPl8CI8rw_0000</td>\n",
       "      <td>[microsoft word]</td>\n",
       "      <td>[i'm assisting in the expansion of our company...</td>\n",
       "      <td>[\"i'm assisting in the expansion of our compan...</td>\n",
       "      <td>[alis, apt, ark, capture, ets, flo, front, gro...</td>\n",
       "      <td>[[microsoft word, 1638, 1652, ORG]]</td>\n",
       "      <td>[front, shift, soon, capture, paid, grow, shar...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[microsoft word, 1638, 1652, ORG]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  \\\n",
       "6    zlBvzxx47BewWlO67-zK3Q_0000   \n",
       "7    zekuTL0ONYTX2XawUBa-9A_0000   \n",
       "8    zaByWGsar5hVdBWLEYykcg_0000   \n",
       "9    zPnnWGWHb2gSYnd98GKaag_0000   \n",
       "12   z5LcE0BcZevf5WmwL8nunQ_0000   \n",
       "..                           ...   \n",
       "984  -nbbpInS-iD0thomdMs6BQ_0000   \n",
       "985  -jsY6ula0lsaOQ5rBHxHLg_0000   \n",
       "986  -iRef22R0w52UJT280zoxQ_0000   \n",
       "990  -bBI1d6Emr0wtwLVEvrssw_0000   \n",
       "991  -XuwuUKT3N67akPl8CI8rw_0000   \n",
       "\n",
       "                         exact_matched_patt_contextual  \\\n",
       "6                                           [republic]   \n",
       "7                                               [dell]   \n",
       "8                          [wordpress, joomla, drupal]   \n",
       "9                                              [unity]   \n",
       "12   [microsoft office, juniper, workday, python, l...   \n",
       "..                                                 ...   \n",
       "984                                             [zoom]   \n",
       "985                    [invision, pixate, xcode, html]   \n",
       "986             [bootstrap, sitecore, asp.net, jquery]   \n",
       "990                                           [groupe]   \n",
       "991                                   [microsoft word]   \n",
       "\n",
       "                                             summaries  \\\n",
       "6    [i am a 19 year old entrepreneur and manager o...   \n",
       "7    [i am a self motivated professional with 13+ y...   \n",
       "8    [as owner and director of projects at metro in...   \n",
       "9    [15+ years within the recruiting industry comb...   \n",
       "12   [bachelor of science (b.s) degree in \" telecom...   \n",
       "..                                                 ...   \n",
       "984  [i am a self-motivated sales & marketing profe...   \n",
       "985  [www.lisawilkins.com specialties: visual/ui/ux...   \n",
       "986  [senior software engineer with 6+ years in ana...   \n",
       "990  [managing director, ceo, strategic business un...   \n",
       "991  [i'm assisting in the expansion of our company...   \n",
       "\n",
       "                                    summaries_matching  \\\n",
       "6    [\"i am a 19 year old entrepreneur and manager ...   \n",
       "7    ['i am a self motivated professional with 13+ ...   \n",
       "8    ['as owner and director of projects at metro i...   \n",
       "9    ['15+ years within the recruiting industry com...   \n",
       "12   ['bachelor of science (b.s) degree in \" teleco...   \n",
       "..                                                 ...   \n",
       "984  [\"i am a self-motivated sales & marketing prof...   \n",
       "985  [\"www.lisawilkins.com specialties: visual/ui/u...   \n",
       "986  ['senior software engineer with 6+ years in an...   \n",
       "990  ['managing director, ceo, strategic business u...   \n",
       "991  [\"i'm assisting in the expansion of our compan...   \n",
       "\n",
       "                                Tech_from_string_match  \\\n",
       "6    [ada, and co, construct, countr, ebs, found, g...   \n",
       "7    [ada, ark, cat, d custom, dell, emplo, ento, g...   \n",
       "8    [accurate, amo, and co, ark, blis, cat, ddi, d...   \n",
       "9    [candid, capabiliti, cat, combin, ento, forge,...   \n",
       "12   [alis, ava, cat, cien, electron, eploy, format...   \n",
       "..                                                 ...   \n",
       "984  [air, ami, ark, cat, construct, continu, ddi, ...   \n",
       "985  [accept, aps, ava, cod, connect, construct, de...   \n",
       "986  [ami, amo, apt, asp.net, bootstrap, cat, esign...   \n",
       "990  [ark, construct, electron, esign, groupe, grow...   \n",
       "991  [alis, apt, ark, capture, ets, flo, front, gro...   \n",
       "\n",
       "                                       spacy_format_v1  \\\n",
       "6                          [[republic, 196, 204, ORG]]   \n",
       "7                            [[dell, 2431, 2435, ORG]]   \n",
       "8    [[drupal, 940, 946, ORG], [joomla, 921, 927, O...   \n",
       "9                           [[unity, 3286, 3291, ORG]]   \n",
       "12   [[juniper, 955, 962, ORG], [linux, 992, 997, O...   \n",
       "..                                                 ...   \n",
       "984                            [[zoom, 689, 693, ORG]]   \n",
       "985  [[html, 382, 386, ORG], [invision, 341, 349, O...   \n",
       "986  [[asp.net, 288, 295, ORG], [bootstrap, 395, 40...   \n",
       "990                        [[groupe, 1678, 1684, ORG]]   \n",
       "991                [[microsoft word, 1638, 1652, ORG]]   \n",
       "\n",
       "                                    exact_matched_patt matched_NER_final  \\\n",
       "6                               [republic, turn, grow]                []   \n",
       "7                                         [grow, dell]                []   \n",
       "8    [promote, accurate, medium, portal, joomla, wo...                []   \n",
       "9    [here, guru, unicorn, purple, hunter, snap, un...                []   \n",
       "12   [route, switch, link, juniper, linux, python, ...                []   \n",
       "..                                                 ...               ...   \n",
       "984       [rapport, zoom, stay, promote, wing, flight]                []   \n",
       "985  [invisible, invision, pixate, soon, html, unif...                []   \n",
       "986  [asp.net, jquery, bootstrap, less, proved, sol...                []   \n",
       "990                                    [sigma, groupe]                []   \n",
       "991  [front, shift, soon, capture, paid, grow, shar...                []   \n",
       "\n",
       "                               spacy_format_manual_tag  \n",
       "6                          [[republic, 196, 204, ORG]]  \n",
       "7                            [[dell, 2431, 2435, ORG]]  \n",
       "8    [[drupal, 940, 946, ORG], [joomla, 921, 927, O...  \n",
       "9                           [[unity, 3286, 3291, ORG]]  \n",
       "12   [[juniper, 955, 962, ORG], [linux, 992, 997, O...  \n",
       "..                                                 ...  \n",
       "984                            [[zoom, 689, 693, ORG]]  \n",
       "985  [[html, 382, 386, ORG], [invision, 341, 349, O...  \n",
       "986  [[asp.net, 288, 295, ORG], [bootstrap, 395, 40...  \n",
       "990                        [[groupe, 1678, 1684, ORG]]  \n",
       "991                [[microsoft word, 1638, 1652, ORG]]  \n",
       "\n",
       "[288 rows x 9 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "traditional-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "viral-irrigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"lookup_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "peaceful-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_name(spacy_format_final):\n",
    "    for i in range(0, len(list(spacy_format_final))):\n",
    "        name = spacy_format_final[i][0]\n",
    "        spacy_format_final[i].remove(name)\n",
    "        \n",
    "    return spacy_format_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "introductory-initial",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"spacy_format_manual_tag\"] = df.apply(lambda x: remove_name(x[\"spacy_format_manual_tag\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "awful-karen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>exact_matched_patt_contextual</th>\n",
       "      <th>summaries</th>\n",
       "      <th>summaries_matching</th>\n",
       "      <th>Tech_from_string_match</th>\n",
       "      <th>spacy_format_v1</th>\n",
       "      <th>exact_matched_patt</th>\n",
       "      <th>matched_NER_final</th>\n",
       "      <th>spacy_format_manual_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zlBvzxx47BewWlO67-zK3Q_0000</td>\n",
       "      <td>[republic]</td>\n",
       "      <td>[i am a 19 year old entrepreneur and manager o...</td>\n",
       "      <td>[\"i am a 19 year old entrepreneur and manager ...</td>\n",
       "      <td>[ada, and co, construct, countr, ebs, found, g...</td>\n",
       "      <td>[[196, 204, ORG]]</td>\n",
       "      <td>[republic, turn, grow]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[196, 204, ORG]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zekuTL0ONYTX2XawUBa-9A_0000</td>\n",
       "      <td>[dell]</td>\n",
       "      <td>[i am a self motivated professional with 13+ y...</td>\n",
       "      <td>['i am a self motivated professional with 13+ ...</td>\n",
       "      <td>[ada, ark, cat, d custom, dell, emplo, ento, g...</td>\n",
       "      <td>[[2431, 2435, ORG]]</td>\n",
       "      <td>[grow, dell]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[2431, 2435, ORG]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zaByWGsar5hVdBWLEYykcg_0000</td>\n",
       "      <td>[wordpress, joomla, drupal]</td>\n",
       "      <td>[as owner and director of projects at metro in...</td>\n",
       "      <td>['as owner and director of projects at metro i...</td>\n",
       "      <td>[accurate, amo, and co, ark, blis, cat, ddi, d...</td>\n",
       "      <td>[[940, 946, ORG], [921, 927, ORG], [929, 938, ...</td>\n",
       "      <td>[promote, accurate, medium, portal, joomla, wo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[940, 946, ORG], [921, 927, ORG], [929, 938, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zPnnWGWHb2gSYnd98GKaag_0000</td>\n",
       "      <td>[unity]</td>\n",
       "      <td>[15+ years within the recruiting industry comb...</td>\n",
       "      <td>['15+ years within the recruiting industry com...</td>\n",
       "      <td>[candid, capabiliti, cat, combin, ento, forge,...</td>\n",
       "      <td>[[3286, 3291, ORG]]</td>\n",
       "      <td>[here, guru, unicorn, purple, hunter, snap, un...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[3286, 3291, ORG]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z5LcE0BcZevf5WmwL8nunQ_0000</td>\n",
       "      <td>[microsoft office, juniper, workday, python, l...</td>\n",
       "      <td>[bachelor of science (b.s) degree in \" telecom...</td>\n",
       "      <td>['bachelor of science (b.s) degree in \" teleco...</td>\n",
       "      <td>[alis, ava, cat, cien, electron, eploy, format...</td>\n",
       "      <td>[[955, 962, ORG], [992, 997, ORG], [2336, 2352...</td>\n",
       "      <td>[route, switch, link, juniper, linux, python, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[955, 962, ORG], [992, 997, ORG], [2336, 2352...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  \\\n",
       "0  zlBvzxx47BewWlO67-zK3Q_0000   \n",
       "1  zekuTL0ONYTX2XawUBa-9A_0000   \n",
       "2  zaByWGsar5hVdBWLEYykcg_0000   \n",
       "3  zPnnWGWHb2gSYnd98GKaag_0000   \n",
       "4  z5LcE0BcZevf5WmwL8nunQ_0000   \n",
       "\n",
       "                       exact_matched_patt_contextual  \\\n",
       "0                                         [republic]   \n",
       "1                                             [dell]   \n",
       "2                        [wordpress, joomla, drupal]   \n",
       "3                                            [unity]   \n",
       "4  [microsoft office, juniper, workday, python, l...   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  [i am a 19 year old entrepreneur and manager o...   \n",
       "1  [i am a self motivated professional with 13+ y...   \n",
       "2  [as owner and director of projects at metro in...   \n",
       "3  [15+ years within the recruiting industry comb...   \n",
       "4  [bachelor of science (b.s) degree in \" telecom...   \n",
       "\n",
       "                                  summaries_matching  \\\n",
       "0  [\"i am a 19 year old entrepreneur and manager ...   \n",
       "1  ['i am a self motivated professional with 13+ ...   \n",
       "2  ['as owner and director of projects at metro i...   \n",
       "3  ['15+ years within the recruiting industry com...   \n",
       "4  ['bachelor of science (b.s) degree in \" teleco...   \n",
       "\n",
       "                              Tech_from_string_match  \\\n",
       "0  [ada, and co, construct, countr, ebs, found, g...   \n",
       "1  [ada, ark, cat, d custom, dell, emplo, ento, g...   \n",
       "2  [accurate, amo, and co, ark, blis, cat, ddi, d...   \n",
       "3  [candid, capabiliti, cat, combin, ento, forge,...   \n",
       "4  [alis, ava, cat, cien, electron, eploy, format...   \n",
       "\n",
       "                                     spacy_format_v1  \\\n",
       "0                                  [[196, 204, ORG]]   \n",
       "1                                [[2431, 2435, ORG]]   \n",
       "2  [[940, 946, ORG], [921, 927, ORG], [929, 938, ...   \n",
       "3                                [[3286, 3291, ORG]]   \n",
       "4  [[955, 962, ORG], [992, 997, ORG], [2336, 2352...   \n",
       "\n",
       "                                  exact_matched_patt matched_NER_final  \\\n",
       "0                             [republic, turn, grow]                []   \n",
       "1                                       [grow, dell]                []   \n",
       "2  [promote, accurate, medium, portal, joomla, wo...                []   \n",
       "3  [here, guru, unicorn, purple, hunter, snap, un...                []   \n",
       "4  [route, switch, link, juniper, linux, python, ...                []   \n",
       "\n",
       "                             spacy_format_manual_tag  \n",
       "0                                  [[196, 204, ORG]]  \n",
       "1                                [[2431, 2435, ORG]]  \n",
       "2  [[940, 946, ORG], [921, 927, ORG], [929, 938, ...  \n",
       "3                                [[3286, 3291, ORG]]  \n",
       "4  [[955, 962, ORG], [992, 997, ORG], [2336, 2352...  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df.loc[(df[\"exact_matched_patt\"]) == '[]']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "compliant-mileage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "unique-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_arrange(summaries, spacy_format_final):\n",
    "    \n",
    "    d = {}\n",
    "    for i in spacy_format_final:\n",
    "        i = tuple(i)\n",
    "        d.setdefault(\"entities\", [])\n",
    "        d[\"entities\"].append(i)    \n",
    "    summary_tuple = (summaries[0], d)\n",
    "\n",
    "    return summary_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "intimate-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"spacy_format_manual_tag\"] = df.apply(lambda x: format_arrange(x[\"summaries\"], x[\"spacy_format_manual_tag\"]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "unlike-offset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>exact_matched_patt_contextual</th>\n",
       "      <th>summaries</th>\n",
       "      <th>summaries_matching</th>\n",
       "      <th>Tech_from_string_match</th>\n",
       "      <th>spacy_format_v1</th>\n",
       "      <th>exact_matched_patt</th>\n",
       "      <th>matched_NER_final</th>\n",
       "      <th>spacy_format_manual_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zlBvzxx47BewWlO67-zK3Q_0000</td>\n",
       "      <td>[republic]</td>\n",
       "      <td>[i am a 19 year old entrepreneur and manager o...</td>\n",
       "      <td>[\"i am a 19 year old entrepreneur and manager ...</td>\n",
       "      <td>[ada, and co, construct, countr, ebs, found, g...</td>\n",
       "      <td>[[196, 204, ORG]]</td>\n",
       "      <td>[republic, turn, grow]</td>\n",
       "      <td>[]</td>\n",
       "      <td>(i am a 19 year old entrepreneur and manager o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zekuTL0ONYTX2XawUBa-9A_0000</td>\n",
       "      <td>[dell]</td>\n",
       "      <td>[i am a self motivated professional with 13+ y...</td>\n",
       "      <td>['i am a self motivated professional with 13+ ...</td>\n",
       "      <td>[ada, ark, cat, d custom, dell, emplo, ento, g...</td>\n",
       "      <td>[[2431, 2435, ORG]]</td>\n",
       "      <td>[grow, dell]</td>\n",
       "      <td>[]</td>\n",
       "      <td>(i am a self motivated professional with 13+ y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zaByWGsar5hVdBWLEYykcg_0000</td>\n",
       "      <td>[wordpress, joomla, drupal]</td>\n",
       "      <td>[as owner and director of projects at metro in...</td>\n",
       "      <td>['as owner and director of projects at metro i...</td>\n",
       "      <td>[accurate, amo, and co, ark, blis, cat, ddi, d...</td>\n",
       "      <td>[[940, 946, ORG], [921, 927, ORG], [929, 938, ...</td>\n",
       "      <td>[promote, accurate, medium, portal, joomla, wo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>(as owner and director of projects at metro in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zPnnWGWHb2gSYnd98GKaag_0000</td>\n",
       "      <td>[unity]</td>\n",
       "      <td>[15+ years within the recruiting industry comb...</td>\n",
       "      <td>['15+ years within the recruiting industry com...</td>\n",
       "      <td>[candid, capabiliti, cat, combin, ento, forge,...</td>\n",
       "      <td>[[3286, 3291, ORG]]</td>\n",
       "      <td>[here, guru, unicorn, purple, hunter, snap, un...</td>\n",
       "      <td>[]</td>\n",
       "      <td>(15+ years within the recruiting industry comb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z5LcE0BcZevf5WmwL8nunQ_0000</td>\n",
       "      <td>[microsoft office, juniper, workday, python, l...</td>\n",
       "      <td>[bachelor of science (b.s) degree in \" telecom...</td>\n",
       "      <td>['bachelor of science (b.s) degree in \" teleco...</td>\n",
       "      <td>[alis, ava, cat, cien, electron, eploy, format...</td>\n",
       "      <td>[[955, 962, ORG], [992, 997, ORG], [2336, 2352...</td>\n",
       "      <td>[route, switch, link, juniper, linux, python, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>(bachelor of science (b.s) degree in \" telecom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  \\\n",
       "0  zlBvzxx47BewWlO67-zK3Q_0000   \n",
       "1  zekuTL0ONYTX2XawUBa-9A_0000   \n",
       "2  zaByWGsar5hVdBWLEYykcg_0000   \n",
       "3  zPnnWGWHb2gSYnd98GKaag_0000   \n",
       "4  z5LcE0BcZevf5WmwL8nunQ_0000   \n",
       "\n",
       "                       exact_matched_patt_contextual  \\\n",
       "0                                         [republic]   \n",
       "1                                             [dell]   \n",
       "2                        [wordpress, joomla, drupal]   \n",
       "3                                            [unity]   \n",
       "4  [microsoft office, juniper, workday, python, l...   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  [i am a 19 year old entrepreneur and manager o...   \n",
       "1  [i am a self motivated professional with 13+ y...   \n",
       "2  [as owner and director of projects at metro in...   \n",
       "3  [15+ years within the recruiting industry comb...   \n",
       "4  [bachelor of science (b.s) degree in \" telecom...   \n",
       "\n",
       "                                  summaries_matching  \\\n",
       "0  [\"i am a 19 year old entrepreneur and manager ...   \n",
       "1  ['i am a self motivated professional with 13+ ...   \n",
       "2  ['as owner and director of projects at metro i...   \n",
       "3  ['15+ years within the recruiting industry com...   \n",
       "4  ['bachelor of science (b.s) degree in \" teleco...   \n",
       "\n",
       "                              Tech_from_string_match  \\\n",
       "0  [ada, and co, construct, countr, ebs, found, g...   \n",
       "1  [ada, ark, cat, d custom, dell, emplo, ento, g...   \n",
       "2  [accurate, amo, and co, ark, blis, cat, ddi, d...   \n",
       "3  [candid, capabiliti, cat, combin, ento, forge,...   \n",
       "4  [alis, ava, cat, cien, electron, eploy, format...   \n",
       "\n",
       "                                     spacy_format_v1  \\\n",
       "0                                  [[196, 204, ORG]]   \n",
       "1                                [[2431, 2435, ORG]]   \n",
       "2  [[940, 946, ORG], [921, 927, ORG], [929, 938, ...   \n",
       "3                                [[3286, 3291, ORG]]   \n",
       "4  [[955, 962, ORG], [992, 997, ORG], [2336, 2352...   \n",
       "\n",
       "                                  exact_matched_patt matched_NER_final  \\\n",
       "0                             [republic, turn, grow]                []   \n",
       "1                                       [grow, dell]                []   \n",
       "2  [promote, accurate, medium, portal, joomla, wo...                []   \n",
       "3  [here, guru, unicorn, purple, hunter, snap, un...                []   \n",
       "4  [route, switch, link, juniper, linux, python, ...                []   \n",
       "\n",
       "                             spacy_format_manual_tag  \n",
       "0  (i am a 19 year old entrepreneur and manager o...  \n",
       "1  (i am a self motivated professional with 13+ y...  \n",
       "2  (as owner and director of projects at metro in...  \n",
       "3  (15+ years within the recruiting industry comb...  \n",
       "4  (bachelor of science (b.s) degree in \" telecom...  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "defensive-share",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bachelor of science (b.s) degree in \" telecommunications networks and software \" program at politehnica university - electronics ,telecommunications and information technology faculty master of science ( m.s.) degree in \" management of networks and services \" program at politehnica university - electronics ,telecommunications and information technology faculty routing and switching skills cisco ccna ( 640-802 certification ) cisco ccnp route ( 642-902 certification : implementing cisco ip routing ) cisco ccnp switch ( 642-813 certification: implementing cisco ip switched networks ) cisco ccnp tshoot ( 642-832 certification: troubleshooting and maintaining cisco ip networks ) experience in troubleshooting and deploying networks using major l2/l3 protocols and platforms: - routing protocols (rip, ospf, eigrp,is-is,bgp) - data link protocols (stp, rstp,mstp) - first hop redundancy protocols: hsrp, vrrp, glbp - mpls fundamentals - cisco, nexus, juniper, alcatel sr platforms - unix/linux - basic, master of science ( m.s.) degree in \" management of networks and services \" - politehnica university - electronics ,telecommunications and information technology faculty bachelor of science (b.s) in \" telecommunications networks and software \" - politehnica university - electronics ,telecommunications and information technology faculty experience in operation and maintenance, planning and deploying large scale networks using high availability / routing and switching technologies in the likes of: hsrp / vrrp, ospf, bgp, mpls, ldp experience in working with network automation and deployment tools and scripts using versioned repositories (git), jinja templates, bash/python scripts. cisco certified network professional routing and switching (ccnp routing and switching), \\'politehnica\\' university of bucharest graduate in 2011, electronics, telecommunications and information technology faculty\\n \\nmaster in networks and services management at the same faculty, diploma obtained in july 2013.\\n\\nbachelor degree in telecommunications software and networks\\n\\n\\n- routing protocols (rip, ospf, eigrp,is-is,bgp)\\n- data link protocols (stp, rstp,mstp,cdp,ppp)\\n- first hop redundancy protocols: hsrp, vrrp, glbp\\n- mpls fundamentals\\n- cisco, nexus, juniper, alcatel sr platforms\\n- unix/linux - basic\\n- good knowledge of microsoft office suite: word, excel, power point, visio\\n\\nspecialties\\n-cisco routing and switching\\n-cisco ccna certified\\n-cisco ccnp route diploma\\n-sdh/dwdm - basic level, mihnea tudor. network development engineer - internet services at amazon ... bachelor of science (b.s) degree in &quot; telecommunications networks and software &quot; program at politehnica university - electronics ... cisco, nexus, juniper, alcatel sr platforms .... network engineer at workday ... linkedin members in ireland:., senior network analyst at continent 8 technologies, network specialist at asavie',\n",
       " {'entities': [(955, 962, 'ORG'),\n",
       "   (992, 997, 'ORG'),\n",
       "   (2336, 2352, 'ORG'),\n",
       "   (1679, 1685, 'ORG'),\n",
       "   (2802, 2809, 'ORG')]})"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"spacy_format_manual_tag\"][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "static-spice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>exact_matched_patt_contextual</th>\n",
       "      <th>summaries</th>\n",
       "      <th>summaries_matching</th>\n",
       "      <th>Tech_from_string_match</th>\n",
       "      <th>spacy_format_v1</th>\n",
       "      <th>exact_matched_patt</th>\n",
       "      <th>matched_NER_final</th>\n",
       "      <th>spacy_format_manual_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zlBvzxx47BewWlO67-zK3Q_0000</td>\n",
       "      <td>[republic]</td>\n",
       "      <td>[i am a 19 year old entrepreneur and manager o...</td>\n",
       "      <td>[\"i am a 19 year old entrepreneur and manager ...</td>\n",
       "      <td>[ada, and co, construct, countr, ebs, found, g...</td>\n",
       "      <td>[[196, 204, ORG]]</td>\n",
       "      <td>[republic, turn, grow]</td>\n",
       "      <td>[]</td>\n",
       "      <td>(i am a 19 year old entrepreneur and manager o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zekuTL0ONYTX2XawUBa-9A_0000</td>\n",
       "      <td>[dell]</td>\n",
       "      <td>[i am a self motivated professional with 13+ y...</td>\n",
       "      <td>['i am a self motivated professional with 13+ ...</td>\n",
       "      <td>[ada, ark, cat, d custom, dell, emplo, ento, g...</td>\n",
       "      <td>[[2431, 2435, ORG]]</td>\n",
       "      <td>[grow, dell]</td>\n",
       "      <td>[]</td>\n",
       "      <td>(i am a self motivated professional with 13+ y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zaByWGsar5hVdBWLEYykcg_0000</td>\n",
       "      <td>[wordpress, joomla, drupal]</td>\n",
       "      <td>[as owner and director of projects at metro in...</td>\n",
       "      <td>['as owner and director of projects at metro i...</td>\n",
       "      <td>[accurate, amo, and co, ark, blis, cat, ddi, d...</td>\n",
       "      <td>[[940, 946, ORG], [921, 927, ORG], [929, 938, ...</td>\n",
       "      <td>[promote, accurate, medium, portal, joomla, wo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>(as owner and director of projects at metro in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zPnnWGWHb2gSYnd98GKaag_0000</td>\n",
       "      <td>[unity]</td>\n",
       "      <td>[15+ years within the recruiting industry comb...</td>\n",
       "      <td>['15+ years within the recruiting industry com...</td>\n",
       "      <td>[candid, capabiliti, cat, combin, ento, forge,...</td>\n",
       "      <td>[[3286, 3291, ORG]]</td>\n",
       "      <td>[here, guru, unicorn, purple, hunter, snap, un...</td>\n",
       "      <td>[]</td>\n",
       "      <td>(15+ years within the recruiting industry comb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z5LcE0BcZevf5WmwL8nunQ_0000</td>\n",
       "      <td>[microsoft office, juniper, workday, python, l...</td>\n",
       "      <td>[bachelor of science (b.s) degree in \" telecom...</td>\n",
       "      <td>['bachelor of science (b.s) degree in \" teleco...</td>\n",
       "      <td>[alis, ava, cat, cien, electron, eploy, format...</td>\n",
       "      <td>[[955, 962, ORG], [992, 997, ORG], [2336, 2352...</td>\n",
       "      <td>[route, switch, link, juniper, linux, python, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>(bachelor of science (b.s) degree in \" telecom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  \\\n",
       "0  zlBvzxx47BewWlO67-zK3Q_0000   \n",
       "1  zekuTL0ONYTX2XawUBa-9A_0000   \n",
       "2  zaByWGsar5hVdBWLEYykcg_0000   \n",
       "3  zPnnWGWHb2gSYnd98GKaag_0000   \n",
       "4  z5LcE0BcZevf5WmwL8nunQ_0000   \n",
       "\n",
       "                       exact_matched_patt_contextual  \\\n",
       "0                                         [republic]   \n",
       "1                                             [dell]   \n",
       "2                        [wordpress, joomla, drupal]   \n",
       "3                                            [unity]   \n",
       "4  [microsoft office, juniper, workday, python, l...   \n",
       "\n",
       "                                           summaries  \\\n",
       "0  [i am a 19 year old entrepreneur and manager o...   \n",
       "1  [i am a self motivated professional with 13+ y...   \n",
       "2  [as owner and director of projects at metro in...   \n",
       "3  [15+ years within the recruiting industry comb...   \n",
       "4  [bachelor of science (b.s) degree in \" telecom...   \n",
       "\n",
       "                                  summaries_matching  \\\n",
       "0  [\"i am a 19 year old entrepreneur and manager ...   \n",
       "1  ['i am a self motivated professional with 13+ ...   \n",
       "2  ['as owner and director of projects at metro i...   \n",
       "3  ['15+ years within the recruiting industry com...   \n",
       "4  ['bachelor of science (b.s) degree in \" teleco...   \n",
       "\n",
       "                              Tech_from_string_match  \\\n",
       "0  [ada, and co, construct, countr, ebs, found, g...   \n",
       "1  [ada, ark, cat, d custom, dell, emplo, ento, g...   \n",
       "2  [accurate, amo, and co, ark, blis, cat, ddi, d...   \n",
       "3  [candid, capabiliti, cat, combin, ento, forge,...   \n",
       "4  [alis, ava, cat, cien, electron, eploy, format...   \n",
       "\n",
       "                                     spacy_format_v1  \\\n",
       "0                                  [[196, 204, ORG]]   \n",
       "1                                [[2431, 2435, ORG]]   \n",
       "2  [[940, 946, ORG], [921, 927, ORG], [929, 938, ...   \n",
       "3                                [[3286, 3291, ORG]]   \n",
       "4  [[955, 962, ORG], [992, 997, ORG], [2336, 2352...   \n",
       "\n",
       "                                  exact_matched_patt matched_NER_final  \\\n",
       "0                             [republic, turn, grow]                []   \n",
       "1                                       [grow, dell]                []   \n",
       "2  [promote, accurate, medium, portal, joomla, wo...                []   \n",
       "3  [here, guru, unicorn, purple, hunter, snap, un...                []   \n",
       "4  [route, switch, link, juniper, linux, python, ...                []   \n",
       "\n",
       "                             spacy_format_manual_tag  \n",
       "0  (i am a 19 year old entrepreneur and manager o...  \n",
       "1  (i am a self motivated professional with 13+ y...  \n",
       "2  (as owner and director of projects at metro in...  \n",
       "3  (15+ years within the recruiting industry comb...  \n",
       "4  (bachelor of science (b.s) degree in \" telecom...  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "secret-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = []\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    \n",
    "    TRAIN_DATA.append(df[\"spacy_format_manual_tag\"][i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "devoted-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-friend",
   "metadata": {},
   "source": [
    "# Checking training lg model STARTS HERE..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "sticky-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# import spacy\n",
    "# from spacy.training import Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "saved-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load('en_core_web_lg')  # load existing spaCy model\n",
    "# ner = nlp.get_pipe('ner')\n",
    "# ner.add_label(\"ORG\")\n",
    "# print(ner.move_names) # Here I see, that the new label was added\n",
    "# optimizer = nlp.create_optimizer()\n",
    "# # get names of other pipes to disable them during training\n",
    "# other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "# with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "#     for itn in range(2):\n",
    "#         random.shuffle(TRAIN_DATA)\n",
    "#         losses = {}\n",
    "#         for text, annotations in TRAIN_DATA:\n",
    "#             doc = nlp.make_doc(text)\n",
    "#             example = Example.from_dict(doc, annotations)\n",
    "            \n",
    "#             nlp.update([example], drop=0.35, sgd=optimizer, losses=losses)\n",
    "#         print(losses)\n",
    "# # test the trained model # add some dummy sentences with many NERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "impaired-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test the trained model # add some dummy sentences with many NERs\n",
    "\n",
    "# test_text = 'Do you like horses?'\n",
    "# doc = nlp(test_text)\n",
    "# print(\"Entities in '%s'\" % test_text)\n",
    "# for ent in doc.ents:\n",
    "#     print(ent.label_, \" -- \", ent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-heath",
   "metadata": {},
   "source": [
    "# Checking training lg model ENDS HERE..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "strange-exchange",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "finnish-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA = TRAIN_DATA[:200]\n",
    "TEST_DATA = TRAIN_DATA[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "wicked-memory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 88\n"
     ]
    }
   ],
   "source": [
    "print(len(TRAINING_DATA), len(TEST_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "buried-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    with open(file, \"r\", encoding = \"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "active-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(file, data):\n",
    "    with open(file, \"w\", encoding = \"utf-8\") as f:\n",
    "        json.dump(data, f, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "wooden-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"KMP_string_Match_newer_1000.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "amended-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(\"spacy_dataset/training_data_spacy.json\", TRAINING_DATA)\n",
    "save_data(\"spacy_dataset/validation_data_spacy.json\", TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "bigger-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_data(\"spacy_dataset/training_data_spacy.json\")\n",
    "valid = load_data(\"spacy_dataset/validation_data_spacy.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "compatible-baseline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"highly organized, creative, want to be involved in an inspiring project where i can utilize skill and creatively involved with system that effectively contributes to the growth of the project and putting a smile on my customers faces.\\n\\nmy work experience has provided me with the skills to take charge in all facets of planning and coordinating events, activities, tasks, contract negotiation and also use my creative skills to design any printed materials such as brochures, flyers and posters, ..., etc as per the event requirements. \\n\\non the other hand, my administrative expertise allowed me to build on my skills in managing multiple task and being adaptable to unpredictable scenarios and challenges. i also possess considerable knowledge in working with computer software programs such as microsoft office and adobe.\\n\\ni enjoy a demanding and variable work environments and am open to work on new and challenging tasks to enhance my knowledge and career., i have many years of experience as a communications specialist, my strength lies in my strong interpersonal, communication and creative support, leadership, computer and research competency, and the ability to work independently and with others from all levels of the organization. i am an ambitious and goal-oriented person, currently seeking an opportunity to implement gained skills and experience in your organisation. i have excellent communication skills, sharp organizational skills, attention to detail and excellent ability to work with speed and accuracy. i master creating plans, solutions and artwork when needed. i instinctively understand others' needs and a i possess a strong ability and desire to bring out the most in others. i put a high value on organization, productivity, and meeting deadlines., an account executive with a demonstrated history of working in the public relations and communications industry. skilled in creativity skills, arabic copywriting, media relations with a bachelor's degree focused in multimedia design from american university of sharjah., freelance graphic designer and event coordinator, communicator specialist / freelance designer\",\n",
       " {'entities': [[821, 826, 'ORG'], [800, 816, 'ORG']]}]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-memorial",
   "metadata": {},
   "source": [
    "# Training_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "warming-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bigger-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.blank(\"en\") # load a new spacy model\n",
    "# db = DocBin() # create a DocBin object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "advisory-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for text, annot in tqdm(TRAIN_DATA): # data in previous format\n",
    "#     doc = nlp.make_doc(text) # create doc object from text\n",
    "#     ents = []\n",
    "#     try:\n",
    "#         for start, end, label in annot[\"entities\"]: # add character indexes\n",
    "# #             print(\"\\n start \\n\", start, \"\\n end \\n\", end, \"\\n label \\n\", label)\n",
    "#             span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "# #             print(\"\\n span \\n\", span)\n",
    "#             if span is None:\n",
    "#                 print(\"Skipping entity\")\n",
    "#             else:\n",
    "#                 ents.append(span)\n",
    "#         doc.ents = ents # label the text with the ents\n",
    "#         db.add(doc)\n",
    "#     except Exception as e:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "strategic-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in train:\n",
    "#     print(i)\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-suffering",
   "metadata": {},
   "source": [
    "# All is correct but spans are generated in a wrong way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "straight-carnival",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 21/200 [00:00<00:01, 107.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 54/200 [00:00<00:01, 142.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 102/200 [00:00<00:00, 153.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 138/200 [00:00<00:00, 139.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 173/200 [00:01<00:00, 152.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 200/200 [00:01<00:00, 146.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\") # load a new spacy model\n",
    "db = DocBin() # create a DocBin object\n",
    "check_ents = []\n",
    "for text, annot in tqdm(train):\n",
    "#     print(\"\\nannot\\n\", annot)# data in previous format\n",
    "    doc = nlp.make_doc(text) # create doc object from text\n",
    "#     print(\"\\ndoc\\n\", doc)\n",
    "    ents = []\n",
    "    try:\n",
    "        for start, end, label in annot[\"entities\"]: # add character indexes\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"strict\")\n",
    "#             print(\"\\nspan\\n\",span,\"\\nannot\\n\", annot)\n",
    "            if span is None:\n",
    "                print(\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents # label the text with the ents\n",
    "        check_ents.append(ents)\n",
    "#         doc.ents = [e for e in doc.ents if not e.text.isspace()]\n",
    "        db.add(doc)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "# print(check_ents)\n",
    "db.to_disk(\"/Users/shubhamsunwalka/Desktop/Slintel_2/training_spacy/train_2.spacy\") # save the docbin object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "israeli-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training import Example\n",
    "from spacy.tokens import DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ongoing-humor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shubhamsunwalka/Desktop/Slintel_2/training_spacy\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "subsequent-vulnerability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "editorial-championship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================ Data file validation ============================\u001b[0m\n",
      "\u001b[38;5;2m Corpus is loadable\u001b[0m\n",
      "\u001b[38;5;2m Pipeline can be initialized with data\u001b[0m\n",
      "\u001b[1m\n",
      "=============================== Training stats ===============================\u001b[0m\n",
      "Language: en\n",
      "Training pipeline: tok2vec, ner\n",
      "195 training docs\n",
      "195 evaluation docs\n",
      "\u001b[38;5;3m 195 training examples also in evaluation data\u001b[0m\n",
      "\u001b[38;5;3m Low number of examples to train a new pipeline (195)\u001b[0m\n",
      "It's recommended to use at least 2000 examples (minimum 100)\n",
      "\u001b[1m\n",
      "============================== Vocab & Vectors ==============================\u001b[0m\n",
      "\u001b[38;5;4m 81046 total word(s) in the data (6841 unique)\u001b[0m\n",
      "10 most common words: ',' (7056), 'and' (3440), '.' (2811), 'in' (1684), '-'\n",
      "(1655), 'of' (1422), 'to' (1175), 'the' (1105), 'a' (955), 'i' (921)\n",
      "\u001b[38;5;4m No word vectors present in the package\u001b[0m\n",
      "\u001b[1m\n",
      "========================== Named Entity Recognition ==========================\u001b[0m\n",
      "\u001b[38;5;4m 0 new label(s), 1 existing label(s)\u001b[0m\n",
      "0 missing value(s) (tokens with '-' label)\n",
      "Existing: 'ORG'\n",
      "\u001b[38;5;3m 1 entity span(s) with punctuation\u001b[0m\n",
      "\u001b[38;5;2m Good amount of examples for all labels\u001b[0m\n",
      "\u001b[38;5;2m Examples without occurrences available for all labels\u001b[0m\n",
      "\u001b[38;5;2m No entities consisting of or starting/ending with whitespace\u001b[0m\n",
      "Entity spans consisting of or starting/ending with punctuation can not be\n",
      "trained with a noise level > 0.\n",
      "\u001b[1m\n",
      "================================== Summary ==================================\u001b[0m\n",
      "\u001b[38;5;2m 5 checks passed\u001b[0m\n",
      "\u001b[38;5;3m 3 warnings\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!spacy debug data -V config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "agricultural-hebrew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2021-06-07 16:40:47,736] [INFO] Set up nlp object from config\n",
      "[2021-06-07 16:40:47,752] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2021-06-07 16:40:47,757] [INFO] Created vocabulary\n",
      "[2021-06-07 16:40:47,758] [INFO] Finished initializing nlp object\n",
      "[2021-06-07 16:40:50,304] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4m Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4m Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00    146.33    0.04    0.02    0.65    0.00\n",
      "  1     200         34.52   2707.80    1.92   50.00    0.98    0.02\n",
      "  2     400         66.25    598.75    0.00    0.00    0.00    0.00\n",
      "  3     600         83.19    547.17   35.29   53.29   26.38    0.35\n",
      "  4     800        114.39    541.45   43.05   53.92   35.83    0.43\n",
      "  5    1000        181.54    495.80   56.54   56.72   56.35    0.57\n",
      "  6    1200        152.79    426.90   60.43   61.99   58.96    0.60\n",
      "  7    1400       2430.38    499.85   60.00   73.24   50.81    0.60\n",
      "  8    1600       1761.11    371.20   65.84   56.87   78.18    0.66\n",
      "  9    1800        230.61    360.15   67.30   65.63   69.06    0.67\n",
      " 10    2000     120269.02    544.39   63.86   83.25   51.79    0.64\n",
      " 11    2200        294.89    350.14   66.35   65.00   67.75    0.66\n",
      " 12    2400        287.65    339.80   67.24   60.15   76.22    0.67\n",
      " 13    2600       2996.81    257.96   71.45   61.11   85.99    0.71\n",
      " 14    2800        383.93    332.64   66.27   52.15   90.88    0.66\n",
      " 15    3000        314.15    341.63   72.83   65.45   82.08    0.73\n",
      " 16    3200        294.15    306.89   70.78   79.92   63.52    0.71\n",
      " 17    3400        269.41    290.18   68.95   83.03   58.96    0.69\n",
      " 18    3600        260.70    246.94   70.05   57.38   89.90    0.70\n",
      " 19    3800        282.86    276.79   69.48   84.58   58.96    0.69\n",
      " 20    4000        252.87    217.75   71.17   62.62   82.41    0.71\n",
      " 21    4200       2737.43    343.02   73.14   61.80   89.58    0.73\n",
      " 22    4400        324.03    276.25   73.03   64.20   84.69    0.73\n",
      " 23    4600        798.97    270.31   74.34   71.13   77.85    0.74\n",
      " 24    4800        268.53    242.08   71.92   66.12   78.83    0.72\n",
      " 25    5000        290.28    254.65   73.09   82.72   65.47    0.73\n",
      " 26    5200        288.68    259.44   71.71   92.31   58.63    0.72\n",
      " 27    5400        398.58    225.89   74.86   65.53   87.30    0.75\n",
      " 28    5600        239.35    226.91   75.49   83.73   68.73    0.75\n",
      " 29    5800        475.11    263.57   73.58   78.31   69.38    0.74\n",
      " 30    6000        230.98    194.66   75.92   82.44   70.36    0.76\n",
      " 31    6200        284.36    225.89   76.75   76.62   76.87    0.77\n",
      " 32    6400        238.05    230.48   73.89   74.50   73.29    0.74\n",
      " 33    6600        240.27    219.46   74.69   81.78   68.73    0.75\n",
      " 34    6800       1340.10    197.80   77.58   70.89   85.67    0.78\n",
      " 35    7000        171.76    211.00   77.16   68.34   88.60    0.77\n",
      " 36    7200        355.10    210.93   76.25   78.35   74.27    0.76\n",
      " 37    7400        333.79    210.43   74.03   91.39   62.21    0.74\n",
      " 38    7600        427.92    218.87   75.93   63.92   93.49    0.76\n",
      " 40    7800       1053.54    216.27   77.46   79.45   75.57    0.77\n",
      " 41    8000        549.31    197.66   77.00   82.77   71.99    0.77\n",
      " 42    8200        262.14    208.42   77.34   75.31   79.48    0.77\n",
      " 43    8400        284.17    187.20   76.08   90.18   65.80    0.76\n",
      "\u001b[38;5;2m Saved pipeline to output directory\u001b[0m\n",
      "output/model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --output ./output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-editing",
   "metadata": {},
   "source": [
    "# TEsting the train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "potential-suicide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORG : joomla\n",
      "ORG : wordpress\n",
      "ORG : drupal\n",
      "ORG : joomla\n",
      "ORG : wordpress\n",
      "ORG : drupal\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlp1 = spacy.load(\"../training_spacy/output/model-best\") #load the best model\n",
    "doc1 = nlp1(\"as owner and director of projects at metro infodesign, i proudly promote our unrivaled web design, internet marketing and technical communications services that are ideal for information-intensive businesses that require the fastest, most accurate and scalable means for publishing over the internet and managing large amounts of data, information and content. in addition to serving the small-to-medium size business community, metro infodesign is very supportive to and intimate with web-based cultural and community development projects, in addition to community technology access initiatives. specialties: web design, web development, project management, web portal administration, content development, content management, internet marketing, web promotion, seo, sem, search engine optimization, technical communications, personal branding, clerical methods analysis, business process analysis, meta-data management, joomla, wordpress, drupal, cms, curriculum development, photography, multimedia production., as owner and director of projects at metro infodesign, i proudly promote our unrivaled web development and technical communications services that are ideal for information-intensive businesses that require speed, accuracy, scalability and a means for publishing over the internet and managing large amounts of content. in addition to serving the small-to-medium size business community, metro infodesign is very supportive to and intimate with web-based cultural and community development projects, in addition to community technology access initiatives. specialties: web design, web development, project management, web portal administration, content development, content management, web promotion, technical communications, personal branding, clerical methods analysis, business process analysis, meta-data management, joomla, wordpress, drupal, cms, curriculum development, photography, multimedia production., director of projects and lead photographer at displaymode media | sr. project manager at metro infodesign, director of projects at displaymode media & metro infodesign\") # input sample text\n",
    "for ent in doc1.ents:\n",
    "    print(ent.label_, ':', ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-plate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
